---
title: Practice DirectX 12 - Programming Model and Hardware Capabilities [@Thomas2016]
---
# Practice DirectX 12

# アジェンダ[Agenda]

- DX12ベストプラクティス
- DX12ハードウェア能力
- 質問

# 期待されること[Expectations]

- DX12は誰のため？
    - 最大限のGPU&CPUパフォーマンスを達成することを目的とする
    - エンジニアリング時間を投資できる
    - 万人向けではない！

# エンジンの懸念事項[Engine Considerations]

- IHV固有パスの必要性
    - できなければDX11を使う
- アプリケーションはドライバやランタイムの部分を置き換える
    - ひとつのコードがすべてのコンソールで正常に動作するとは思えないし、PCでも似たようなもの
    - アーキテクチャ固有パスを検討する
- <font color="Green">NVIDIA</font>と<font color="Red">AMD</font>固有のものに注意

# ワークサブミッション[Work Submission]

- マルチスレッディング
- コマンドリスト
- バンドル
- コマンドキュー

# マルチスレッディング[Multi-Threading]

- DX11ドライバ:
    - レンダリングスレッド(プロデューサー)
    - ドライバスレッド(コンシューマー)
- DX12ドライバ:
    - ワーカースレッドをスピンしない
    - コマンドリストインターフェイスを介して直接的にコマンドバッファを構築する
- すべてのコアに渡ってエンジンがスケールすることを確認する
    - タスクグラフアーキテクチャがもっとも上手く動作する
    - コマンドリストをサブミットする1つのレンダリングスレッド
    - 並列にコマンドリストを構築する複数のワーカースレッド

# コマンドリスト[Command Lists]

- コマンドリストは他がサブミットされてても構築できる
    - サブミッションやプレゼント中にアイドリングしない
    - コマンドリストの再利用が許可されているが、アプリケーションは同時利用をやめる責任がある
- あまり多くのコマンドリストにワークを分割しすぎない
- 目星(フレーム毎):
    - 15〜30のコマンドリスト
    - 5〜10の`ExecuteCommandLists`呼び出し

# コマンドリストその2[Command Lists #2]

- 各`ExecuteCommandLists`は固定のCPUオーバーヘッドを持つ
    - この呼び出しの内部でフラッシュが誘発する
    - なので、コマンドリストをバッチ処理する
- 各`ExecuteCommandLists`に少なくとも200us、できれば500usのGPUワークを配置してみる
- OSのスケジューリングレイテンシーを隠蔽するのに十分なワークをサブミットする
    - `ExecuteCommandLists`呼び出しが少ないと、OSのスケジューラーが新しいものをサブミットできるようになるよりも早くに完了する

# コマンドリストその3[Command Lists #3]

- 例:
    - 十分でないワークがサブミットされる場合何が起こる？
        - 強調した`ExecuteCommandLists`は実行するのに約20usかかる
        - OSはやって来るワークをスケジュールするのに約60usかかる
        - == 40usのアイドル時間

# バンドル[Bundles]

- そのフレーム内で早期にワークをサブミットする良い方法
- GPUにおいてバンドルで本質的に速くなることはない
    - これらを賢く使おう！
- コマンドリストの呼び出しから状態を継承する --- 長所を生かす
    - ただし、引き継いだ状態のすり合わせはCPUかGPUのコストがかかるかも
- 良好なCPUブーストをもたらす
    - <font color="Green">NVIDIA:</font> 5つ以上の同じドロー/ディスパッチを繰り返すなら、バンドルを使う
    - <font color="Red">AMD:</font> CPU側でもがき苦しんでいる場合にのみバンドルを用いる

# マルチエンジン[Multi-Engine]

- 3Dキュー
- コンピュートキュー
- コピーキュー

# コンピュートキューその1[Compute Queue #1]

- 細心の注意を払って用いること！
    - 正しく用いれば、現時点で最大10%の得が見込める
- これがパーフォーマンス的に得であることを常にチェックする
    - 非同期でないコンピュートパスを維持する
    - 雑にスケジュールされたコンピュートタスクは最終的にロスになり得る
- ハイパースレッディングって覚えてる？　あれと似たようなルールが適用される
    - 2つのデータヘビーなテクニックは、例えば、キャッシュのような、リソースを抑圧する
- ペアリングに適したテクニックがGPUを十分に活用しない場合、まずは「なぜ利用率がクソなのか」を問おう
    - 非同期コンピュートに移行する *前に* まずコンピュートジョブを最適化する

# コンピュートキューその2[Compute Queue #2]

- 良いペアリング
    - グラフィクス: シャドウレンダリング(I/Oに制限される)
    - コンピュート: ライトカリング(ALUヘビー)
- 悪いペアリング
    - グラフィクス: Gバッファ(帯域に制限される)
    - コンピュート: SSAO(帯域に制限される)

(テクニックペアリングは1対1にしなければならないことはない)

# コンピュートキューその3[Compute Queue #3]

- 無制限にスケジューリングを行うと、残念なテクニックペアリングが行われることがある
    - 利点
        - 実装が単純
    - 欠点
        - フレーム間の非決定論
        - ペアリング制御の不足

# コンピュートキューその4[Compute Queue #4]

- フェンスの賢い使用を通じた非同期コンピュートタスクの明示的なスケジューリングのほうが良い
    - 利点
        - フレーム間の決定論
        - アプリケーションがテクニックペアリング全体を制御する！
    - 欠点
        - 実装するのに多少長めの時間がかかる

# コピーキュー[Copy Queue]

TODO
