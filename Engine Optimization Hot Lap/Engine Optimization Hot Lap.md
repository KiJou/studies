---
title: Engine Optimization Hot Lap [@Lottes2018]
---
# Engine Optimization Hot Lap

# このトークの目標

- ハードウェアレベルにより近い所でのGPUの動作の仕方について更に教示する
- GPUワークロードやエンジン設計についての理由付けを行うのを助けるために
- 様々な最適化の結果を提示する
- <font color="red">そして、究極的にはGPUがスケールし続けるたびにビジュアルおよびパフォーマンス目標をさらに良く理解するのを助ける</font>

# GCN再掲

- SIMD(VALU) = 16幅ベクトルALUは4クロックに渡って64幅のwaveを実行する
    - 最大占有率 8 waves/SIMD (Polaris)、または、一般には10 waves/SIMD (Polaris以外)
- CU = Compute Unitは4SIMDを含む(1wave/clockのピークVALU実行スループット)
- SALU = Scalar ALU
- LDS = Local Data Store
- V\$ = ベクトルL1キャッシュ (VMEM)
- I\$ = 命令L1キャッシュ
- K\$ = スカラL1キャッシュ (SMEM)

# 描画の外側を考える

- しばしば最適化の努力は最も高価なシェーダを最適化することに注力[narrowly focused]される
- このトークは全体論的な視点を取る: **すべての描画/ディスパッチの内外のフレーム全体の実行時間に注目する**

# AMD内で使われる解析用ツールのイントロダクション

- 外部ツール
    - Radeon GPU Profiler (RGP)
- AMD内部ツール
    - VK_GPA_interface
    - ドライバ修正
    - 命令トレースリポート
        - → wave実行の詳細
        - → waveの寿命
        - → CU命令のまとめ
            - 緑 = SIMDあたりのVALUの発行
            - 橙 = VMEMの発行

# 核となる原則

# AMDAHLの法則

- 並列処理の観点でマシンがスケールするごとに可能なパフォーマンス改善は並列処理の量に比例する
- 例えば、GHzだと[at the GHz wall]、仕事の75%を並列に走らせただけで、ベストケースの実行時間は並列でないマシンの25%にまで下がるだろう
- Takeaway: **パイプライン化された並列な仕事でGPUを満杯にし続ける**

# GCNのベクトルメモリアクセスの理解

- 平均レイテンシーはGPU/ワークロード/他によって変化し得る
- 人工のシェーダレイテンシーのテスト結果からパフォーマンスの急上昇[cliff]を推定できる
    - L1ヒットで約114クロック(peak 16 clock/VMEM return rate for image ops) (1 clock/VALU)
    - L2ヒットで約190クロック(L1ヒットと比べて平均で約76クロックの追加レイテンシー ... 76/16 = 4.75のイメージL1\$ヒット)
    - L2ミスで約350クロック(L1ヒットと比べて平均で約236クロックの追加レイテンシー ... 236/16 = 14.75のイメージL1\$ヒット)
- メモリスループットを減らすもの
    - リクエストキューがdrainingしない程度に高速なVMEM操作を維持しないこと
        - **メモリリクエストの通常フローを維持してみる(wave占有率の不規則さを探す、など)**
    - L1キャッシュミスやL2キャッシュミスによって引き起こされるメモリバブル
        - **空間的および時間的にデータ局所性を改善して、L1ヒット率を上げてみる**

# Idle Bound

# Idle Boundの例 --- スライド1

GPU Draining
アイドル込みのバリア
直列の依存性＋小さなジョブ

# Idle Boundの例 --- スライド2

単純なジオメトリではGPUは飽和しない
GPU Draining
SIMULTANEOUS_USE_BITのコマンドバッファは並列性を妨げる

# 1/4解像度パスのDrainとFillに関する数

最初のPSのwaveへのフロントエンドのタイムスタンプでは2.2us(ここにはVSからPSへの遅延が含まれる)
PSのfill時間では1.2us(50%以下がアクティブ)
PSのdrain時間は5.9us(約50%がアクティブ)
バリアに2.6us(キャッシュのフラッシュを含む)
計59.9usのうち51.5usがアクティブ
↑このポストパスではGPUの最低でも14%のVALUがアイドル

独立した第2、第3のPS描画を伴う並列でのPSクリア(48us中35usのVALU処理)
100%として数える(実際にはこうはならないだろう)
vkCmdClearAttachmentsはVS+PSクリアを生成、VSからPSへの遅延に注意
最小のオーバーラップ、帯域幅boundのPSクリア(VALUなし)が第2PSの起動を遅らせる
↑このポストパス＋クリアではGPUの最低でも26%のVALUがアイドル

# GPUを埋める --- コールドキャッシュの話

- 64のCU(Vega) = 2560のwavesを起動できる(ピーク占有時なら約160Kiのwork items)
- "First-Fill Waves" = コールドキャッシュ条件で始まるwaves
    - 2560x1440のフルスクリーンパスの最大4.4%がfirst-fill wavesである
    - 1/4領域のポストパスの最大17%がfirst-fill wavesである(DOF/MB/他で一般的)
    - 1/16領域のポストパスの71%はfirst-fill wavesである(リダクションパスで一般的)
- GPU時間の大半がコールドキャッシュに費やされる可能性がある
    - CSのディスパッチ: wave起動率、Iキャッシュミス、Kキャッシュミス、従属的フェッチ[dependent fetches]
        - = **アイドル状態のマシンにおける隠蔽できない長いレイテンシー連鎖**

# RGPに戻って、それに関するコールドキャッシュの話

- AMD内部の命令トレース
    - Iキャッシュミス
    - ほぼアイドル
    - GPU満杯
    - GPUが満杯になって少し経ってから効率的な実行に達する
- RGPからの見え方
    - バリアのアイドル時間
    - GPU満杯
    - GPUが満杯になって少し経ってから効率的な実行に達する

# アイドルbound --- Takeaway

- 実践でのAmdahlの法則
- 描画外の時間
- 描画のシリアライズ = GPUサイズでスケールを止めるパフォーマンス
- パイプラインへの時間

# DCC & CS VS PS

# 低速クリアを回避する

- CSパスで書かれるイメージへのクリアを避ける
- フルスクリーントライアングルされる(イメージの大多数を上書きする)イメージへのクリアを避ける
- 圧縮済みサーフェスに対する、すべてを0.0か1.0でクリアすることによるアドバンテージ

VS処理はクリアと並列に動作できるが、PSはクリアの終わりまでブロックされる

低速クリア
圧縮されたクリア
低速クリア
VALUはほぼアイドル状態
クリアの終わり

# GCNにおけるPSとCS

- PS --- 一般的に次のVキャッシュに移動する前にVキャッシュあたり1から4の間のwavesを起動する --- Ordered export
    - DCC|Z圧縮出力をサポートする(圧縮はロードのレイテンシーを増加させる可能性があることに注意)
    - キャッシュは前のパスで書かれたレンダターゲットを読むためにフラッシュされる
    - VSからPSへの遅延はVSが長いレイテンシー連鎖やコールドキャッシュを持つときに実体化する可能性がある

CPマーカー(描画開始)と第1PS waveの起動の間はほぼ4000クロック

キャッシュミスが少ない = VSからPSへの遅延が小さい

- CS --- 次のVキャッシュに移動する前にVキャッシュあたりひとつのworkgroupを起動する --- exportなし(順不同)
    - PSパスで書かれた圧縮イメージを読むことができるが、DCC|Z圧縮イメージを格納できない
    - シェーダ読み込みからシェーダ書き込みへの遷移におけるキャッシュのフラッシュを必要としない
    - グラフィクスキューでパイプライン化させて、または、CSキューで非同期に実行し易い

# Delta Color Compression (DCC)のON/OFF

- PCのGPUでのDCCは利点にも欠点にもなり得る
    - レイテンシーの増加に対して、帯域幅が減少する可能性(メタデータをフェッチする必要がある)
- **DCCを使う時と使わない時を選ぶためにプロファイルするのに最適なこと**
    - STORAGEかUAVのusageフラグを用いることでレンダターゲットでのDCCを無効化できる
    - ONかOFFの二者択一ではなく個々のレンダターゲットで試すのがより良い
- あるゲームパスに対してDCCを有効化した場合のパフォーマンス差の例(Vegaの数値)
    - ディファードシェーディングで-5.0% (より遅い)
    - Screen Space Reflectionで-3.1%
    - Screen Space Occlusionで1.8%
    - 合成パスで2.2%
    - ポストプロセッシングで3.8 (より速い)

# イベント付きパイプライン化

# 理想のトライアングルベースエンジンの著者の見解

- ジオメトリをレンダリングするときはVS+PSのみ、その他ではCS
- **CSは容易にパイプライン化する能力を最大化する**

# パイプライン化

- 前の仕事のdrainを穴埋めしながらコールドキャッシュのレイテンシーを隠蔽する
- まずパイプラインのAPIイリーガルなテクニックを探す: バリアを外して、データ競合をテストする
    - ハードウェアを理解するのに有用
    - APIリーガルなソリューションに対してテストするためにパフォーマンス上限を推定するのに役立つ
    - ある種の実行依存性が必須であることを証明するにの役立つ
- APIリーガルなソリューションは後述する

# 単純なデータ競合テスター

# 単純なデータ競合テスター: データ競合は起こり得るという結果に

- RX 580で様々なイメージサイズを動作させた結果
    - 競合なし: 256x256以上
    - 競合あり: 128x128以下 --- ある形式の実行依存性が実際には必要であるという評価結果
- あるケースでは要素の組み合わせがデータ競合を不確実にする
    - コヒーレントでない(GLC=0)ストアは依然としてコヒーレントなL2キャッシュにwrite-throughする
    - Step#2のwavesはStep#3のwavesの前に起動する必要がある(APIのサブミッション順序で起動、順不同に完了)
    - GPUのlooseなworkgroupの起動はディスパッチ順(大まかに右から左、その後、上から下)

ロードの開始前にストアが見える

この挙動に依存できない
GPUサイズやワークロードがデータ競合の発生確率を調整する可能性がある

# GLSLにおけるcoherentメモリ修飾子の活用

- coherentはGCNにおけるGLC=1のストアに翻訳される。これは、L1キャッシュを迂回し、コヒーレントなL2キャッシュに格納される
    - 例: `layout(set=0, binding=5, rgba8) uniform coherent image2D imgA;`
- ARB_shader_image_load_store --- *"[coherent]変数を通してアクセスされるバッファオブジェクトまたはテクスチャイメージメモリは、他のいかなるシェーダinvocationによって発行されるストアによってキャッシュが自動的に更新される場合に限り、キャッシュされてもよい。"
    - コヒーレントなストアはコヒーレントでないキャッシュを迂回する必要があると明言されている
- **重大な観察結果** : ロードはcoherent修飾子を使う必要がなく、以下の使い方のモデルの下でキャッシュさせることができる
    - 新鮮なキャッシュを保証するためのフレームの開始/終了のキャッシュフラッシュ
    - いずれかのリードの前のコヒーレントなストアで一度だけキャッシュラインに書き込む(実行依存性を必要とするのみ、いわゆるVkEvent)
    - 何回もコヒーレントでないキャッシュ(いわゆる最高のパフォーマンス)を介してキャッシュラインを読み出す

The Perfect Tool For Pipelining In Vulkan(R)

# イベントによるパイプライン化の機構

- 手動でひとつのディスパッチを2つに分ける
    - 分割は最大フィルタカーネル窓に基づいて変えなければならないだろう

# いずれかの読み込みの前の一度だけコヒーレントな書き込み、そして、キャッシュ済み読み込み

- APIはGPUのキャッシュラインの大きさを開示していおらず、ハードウェアはキャッシュラインの大きさを自由に変えられる
- 2018年3月現在、"安全な"分割ライン粒度[split line grahularity]を報告するAPIインターフェイスは存在しない
    - 分割がキャッシュラインの境界をまたがないことを確実にするため
- 現在のワークアラウンドは必要なアラインメントを大きく過剰に推定すること
    - 分割オフセットは大きな2の累乗の値にすべき
    - 64バイトキャッシュラインでのひとつのハードウェアswizzleパターンで混ぜられる32ビット/テクセルは4テクセルのアラインメントを必要とするかもしれない
    - 128バイトキャッシュラインを持つマシンでの16ビット/テクセルのイメージは8テクセルのアラインメントを必要とするかもしれない
    - **おそらく64テクセルのアラインメントにパッドするのが良い --- キャッシュラインサイズとswizzleパターンにおける変更に対する柔軟性を確保する**

# 単純なデータ競合テスター: Vegaにおける1152x1152の評価結果

- 1.00 time: データ競合テスター(APIリーガルではない)
    - 手動パイプライン化の上限の限界の可能性
- 1.31 time: バリアの再導入
    - APIリーガルの一般的なプラクティス(timeはバリアを含む)
    - 過度に保守的なドライバはL2キャッシュをフラッシュさせる
        - または、L2キャッシュのフラッシュを必要とする使い方を持ったバリアかも
- **1.03 time: イベントによる手動分割パイプライン**
    - イメージバリアではなく"coherent"なGLC=1のストアを使う
    - オススメの"安全"でAPIリーガルなソリューション

# CXとGFXキューの間の違い

- グラフィクスキューはフロントエンドの操作をパイプライン化するのに優れている(しばしば並列に40超の描画が確認される)
    - しばしばグラフィクスキューで小さなジョブをパイプライン化するのに優れる
- コンピュートキューはフロントエンドのオーバーヘッドを隠すためにより長く動作するwavesを必要とする

限られたwavesの起動
GPUの非パイプライン化

シグナル化したVkEventの待機はメモリのフェッチを必要とする(隠すにはより長いwavesが必要)

長く動作するwavesが良い(待機のフェッチを上手く隠す)

# パイプライン化された世界で隔離したタイミング計測

TODO
