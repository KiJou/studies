---
title: >
    BREAKING DOWN BARRIERS --- PART 2: SYNCHRONIZING GPU THREADS
---
# BREAKING DOWN BARRIERS --- PART 2: SYNCHRONIZING GPU THREADS

## PROGRAMMING THE MJP-3000

GPUスレッド同期の基礎を説明するため、MJP-3000という架空のアーキテクチャを例を取って話を進めていこうと思う。これは実際のグラフィクスハードウェアよりさらに簡単にできており、込み入ったこと抜きに高次の概念を説明しやすくするだろう。私の説明が実際のGPUが行っていることとまったく同じであるとは考えないで欲しいが、まったく異なるとこの例が役に立たなくなってしまうので、そうならないように、コマンドや挙動は大まかに現実世界のGPUに基づいている。

![](images/gpu_overview1.png)

**コマンドプロセッサ**はサブミットされた順に一度にひとつずつの**コマンドバッファ**からコマンドを読み取り、適当なコマンドに遭遇したら、**スレッドキュー**にスレッだのグループを追加する。**シェーダコア**はFIFOスキームで**スレッドキュー**からスレッドを引き出し、各々独立してシェーダプログラムを実行する。また、シェーダコアはデバイスメモリの任意の位置で読み書きを行うことができる。**Current Cycle Count**は特定の例のために実行したGPUサイクル数を示す。

いくつかの理由から、MJP-3000の設計者らは彼らのハードウェアがコンピュートシェーダのみを実行可能であると決定した。これは、彼らが複雑なラスタライゼーションパイプラインに頼らない1つのシェーダステージのみに注力する方が物事をもっと単純にするだろうと感じたから、と私は考えている。そのため、コマンドプロセッサはシェーダコアを走らせるためにスレッドを実際に開始させる**DISPATCH**コマンド1つのみを持つ。DISPATCHコマンドは、実行すべきスレッド数とシェーダプログラムを指定する。DISPATCHコマンドがコマンドプロセッサと遭遇すると、ディスパッチによるスレッドは即座にスレッドキューへ置かれ、待機中のシェーダコアに捕らえられる。コマンドプロセッサは1サイクルでDISPATCHコマンドをパースし、そのスレッドをキューに入れることができる。シェーダコアは1サイクルでスレッドキューからスレッド1つを取り出すことができる。

## DISPATCHES AND FLUSHES

デバイスメモリに位置する別個のバッファ要素になにかを書き込む32つのスレッドをディスパッチする単純な例をやってみよう。このディスパッチは完了に100サイクルかかるシェーダプログラム"A"を実行しようとする。コアはが16つあるので、我々は開始から終了までに約200サイクルかかると予測するだろう。

![](images/single_dispatch_0000_layer-1.png)

いくつかの同期を導入しよう。例として、バッファの24つの要素に結果をまとめて書き込むプログラムAのスレッドを24つ走らせるとする。プログラムAの完了後、元々出力バッファだったものからこれら24つの要素を読み出し、別のバッファに書き込む新しい結果を計算するために使われるプログラムBを24つ走らせたい。

![](images/dispatch_overlap_0000_layer-1.png)

3ステップ目を見て欲しい。ディスパッチAは16の倍数ではないので、下8つのシェーダコアはアイドル状態にならないようにディスパッチBから引き出した。これにより2つのディスパッチが*オーバーラップ*した。これは競合状態、つまり、ディスパッチAのスレッドが終わる前にディスパッチBのスレッドがディスパッチAの出力バッファを読み出すかもしれない状態にあるため非常にまずい。ではここでFLUSHコマンドを導入しよう。コマンドプロセッサがフラッシュに当たると、すべてのシェーダコアがさらなるコマンドを処理する前にアイドル状態になるまで待機する。"フラッシュ"という用語は、実行するのを待っているすべての待機中の作業を"流し出す"ことを暗示するので、この種の操作に対して一般的である。

![](images/flush_between dispatches_0000_layer-1.png)

これはディスパッチBがディスパッチAと一切オーバーラップしないことを保証する。

TODO
