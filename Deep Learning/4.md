# 数値計算

機械学習アルゴリズムは通常、大量の数値計算を必要とする。これは一般に、正しい解のための記号的な式をもたらすために数式を解析的に導出するのではなく、反復的な過程を通して解の推定値を更新する手法によって数学的問題を解くアルゴリズムを参照する。一般的な操作には最適化（関数を最小化または最大化する引数の値を求めること）や一次方程式の系を解くことが含まれる。ディジタルなコンピュータ上で数学的な関数を計算することだけでも、その関数が実数値を伴うとき、有限のメモリ量を用いて正確に表現できないので、困難である可能性がある。

## オーバーフローとアンダーフロー

ディジタルなコンピュータ上で連続的な数学を処理することの根本的な困難さは、有限のビットパターンで無限に多い実数値を表現する必要があることにある。これは、ほぼすべての実数値に対して、コンピュータで値を表現するとき、いくらかの近似誤差が発生することを意味する。多くの場合、これは単なる丸め誤差である。丸め誤差は、特に多数の操作に渡って構成されるときに問題となり、丸め誤差の蓄積を最小化するよう設計されていない場合に理論ではうまく機能するアルゴリズムが実践ではうまく機能しなくなることが起こり得る。
特に壊滅的な丸め誤差の一種をアンダーフロー[underflow]という。アンダーフローはゼロに近い値がゼロに丸められるときに発生する。多くの関数は、その引数が小さな正の数ではなくゼロであるとき、性質上異なる振る舞いを見せる。例えば、我々は通常ではゼロによる除算（あるソフトウェア環境はこれが発生したときに例外を投げるだろうし、その他は代用として非数の値で結果を返すだろう）やゼロの対数を取ること（これは通常では$-\infty$として扱われ、さらなる算術演算で使われると非数になる）を避けたい。
もうひとつの非常に有害な数値誤差の一種はオーバーフロー[overflow]である。オーバーフローは大きな絶対値を持つ値が$\infty$または$-\infty$として近似されるときに発生する。さらなる算術は通常ではこれらの無限大の値を非数に変化させるだろう。
アンダーフローやオーバーフローに対して安定化させなければならない関数の一例としてsoftmax関数がある。softmax関数はしばしばmultinoulli分布に関連付けられる確率を予測するのに使われる。softmax関数は以下のように定義される。

$$
\text{softmax}(\boldsymbol{x})_i = \frac{\exp(x_i)}{\sum_{j=1}^n \exp(x_j)}
$$

すべての$x_i$がある定数$c$に等しいとき何が起こるかを考えよう。解析的には、すべての出力が$\frac{1}{n}$に等しいはずであることが分かる。数値的には、これは$c$が大きな絶対値を持つときには起こらないかもしれない。$c$が非常に大きな負数である場合、$\exp(c)$はアンダーフローを起こすだろう。これはsoftmaxの分母が$0$になるであろうことを意味する。つまり、最終結果は未定義である。$c$が非常に大きな正数であるとき、$\exp(c)$はオーバーフローを起こし、同様に、式全体が未定義となるだろう。これら両方の困難さは$\boldsymbol{z} = \boldsymbol{x} - \max_i x_i$とする$\text{softmax}(\boldsymbol{z})$を代わりに計算することで解決することができる。単純な代数学は、softmax関数の値が入力ベクトルからスカラを足したり引いたりすることによって解析的に変化しないことを示す。$\max_i x_i$を引くことは$\exp$のlargest argumentを$0$にすることになる。これは、オーバーフローの可能性を排除する[rule out]。同様に、少なくとも1つの分母の項が$1$の値を持つ。これは、ゼロによる除算をもたらす分母におけるアンダーフローの可能性を排除する。
1つの小さな問題が依然として存在する。分子におけるアンダーフローは依然として式全体をゼロにしてしまう可能性がある。これは、はじめにsoftmaxのサブルーチンを実行し、その後に$\log$関数へその結果を渡すことで$\log \text{softmax}(\boldsymbol{x})$を実装すれば、誤って$-\infty$を得ることができてしまうであろうことを意味する。代わりに、我々は数値的に安定な方法で$\log \text{softmax}$を計算する別個の関数を実装しなければならない。$\log \text{softmax}$関数はsoftmax関数を安定化するのに使ったのと同じトリックを用いて安定化することができる。
ほとんどの部分で、我々は本書で述べられる様々なアルゴリズムを実装する際に伴う数値的な懸念事項のすべてを明示的に詳述したりはしない。低レベルライブラリの開発者は深層学習アルゴリズムを実装するときに数値的な問題を気に留めておくべきである。ほとんどの本書の読者は安定的な実装を提供する低レベルライブラリに単純に頼ることができる。ある場合には、新しいアルゴリズムを実装し、自動的に安定化された新しい実装を得ることができる。Theano[@Bergstra2010; @Bastien2012]は深層学習の文脈で発生する多数の一般的な数値的に不安定な式を自動的に検出して安定化するソフトウェアパッケージの一例である。

## 悪条件

条件[conditioning]は関数がその入力における小さな変化に関してどれだけ急激に変化するかを示す。入力がわずかに摂動するときに急激に変化する関数は、入力における丸め誤差が出力の大きな変化になる可能性があるので、科学計算にとって問題となり得る。
関数$f(\boldsymbol{x}) = \boldsymbol{A}^{-1} \boldsymbol{x}$を考えよう。$\boldsymbol{A} \in \mathbb{R}^{n \times n}$が固有値分解を持つとき、その条件数[condition number]は以下となる。

$$
\max_{i,j} \left| \frac{\lambda_i}{\lambda_j} \right|
$$

これは最大および最小の固有値の大きさの比である。この値が大きいとき、逆行列は入力における誤差に特に鋭敏である。
この感度は行列それ自体の生来の特性であり、逆行列を求める最中の丸め誤差の結果ではない。悪条件[poorly conditioned]の行列は、真の逆行列で乗算するとき、既存の誤差を増幅する。実際には、その誤差は逆行列を求めること自体の数値誤差によって更に悪化するだろう。

## 勾配ベースの最適化

ほとんどの深層学習アルゴリズムはある種の最適化を伴う。最適化とは、$\boldsymbol{x}$を代替することによってある関数$f(\boldsymbol{x})$を最小化または最大化のいずれかを行う作業を指す。我々は通常、$f(\boldsymbol{x})$の最小化に関するほとんどの最適化問題を表現するのに使う。最大化は$-f(\boldsymbol{x})$を最小化することで最小化アルゴリズムを介して達成できるだろう。
最小化または最大化したい関数は目的関数[objective function]とかcriterionと呼ばれる。これを最小化するとき、これをコスト関数[cost function]とか損失関数[loss function]とか誤差関数[error function]とも呼ぶかもしれない。本書では、ある機械学習の文献がこれらの用語のいくつかに特別な意味を割り当てているとしても、これらの用語を同義的に用いる。
我々はしばしば上付き文字$*$で関数を最小化または最大化する値を表記する。例えば、$\boldsymbol{x}^* = \argmin f(\boldsymbol{x})$と言えるだろう。
我々は読者がすでに微分積分学[calculus]に親しみがあると想定しているが、ここでは、微分積分学の概念がどのように最適化と関係しているかの簡潔な復習を提供する。
関数$y = f(x)$があるとする。ここで、$x$と$y$の両方は実数である。この関数の微分[derivative]は$f'(x)$とか$\frac{dy}{dx}$と表記される。微分$f'(x)$は点$x$における$f(x)$の傾斜をもたらす。言い換えれば、これは対応する出力の変化を得るために入力の小さな変化をスケールする方法を指定する。すなわち、$f(x + \epsilon) \approx f(x) + \epsilon f'(x)$である。
故に、微分は、$y$において小さな改良を加えるために$x$を変化させる方法を教えてくれるので、関数を最小化するのに有用である。例えば、我々は$f(x - \epsilon \text{sign}(f'(x)))$が十分に小さな$\epsilon$に対して$f(x)$より小さいことを知っている。従って、我々は微分の反対の符号を持つ小さな増分で$x$を動かすことで$f(x)$を減少させることができる。この技術は勾配降下法[gradient descent]と呼ばれる[@Cauchy1847]。この技術の一例は[@fig:4.1]を参照のこと。
$f'(x) = 0$であるとき、微分はどの方向に動くかといった情報をもたらさない。$f'(x) = 0$である点は臨界点[critical points]とか停留点[stationary points]として知られる。極小[local minimum]は$f(x)$がすべての近傍の点よりも小さい点である。つまり、微小増分を作ってもそれ以上に$f(x)$を減少させることができないということである。極大[local maximum]は$f(x)$がすべての近傍の点よりも大きい点である。つまり、微小増分を作ってもそれ以上に$f(x)$を増加させることができないということである。臨界点には最大でも最小でもない点が存在する。これらは鞍点[saddle points]として知られる。臨界点の各種の例は[@fig:4.2]を参照のこと。

![臨界点の種類。一次元における3種類の臨界点の例。臨界点はゼロの傾斜を持つ点である。そのような点は、近傍の点よりも小さい極小、近傍の点より大きい極大、その点自体よりも高い点と低い点の両方の近傍点を持つ鞍点、のいずれかとなり得る。](fig/4-2.png){#fig:4.2}

最も小さい$f(x)$の絶対値を得る点は最小[global minimum]という。関数には1つだけの最小、または、複数の最小が存在し得る。そこは大域最適[globally optimal]でない極小ともなり得る。深層学習の文脈において、我々は最適でない多数の極大や非常に平らな領域に囲まれた多数の鞍点を持ち得る関数を最適化する。このすべては、特に関数への入力が多次元であるとき、最適化を困難にする。故に、我々は通常、非常に小さければ正式に最小でなくても良い$f$の値を求めることで手打ちとする。一例は[@fig:4.3]を参照のこと。

![最小化の近似。最適化アルゴリズムは複数の極大または平坦域が存在するときに最大を求められないかもしれない。深層学習の文脈において、我々は一般に、真に最小でなかったとしても、それらがコスト関数の著しく低い値に対応している限り、そのような解を許容する。](fig/4-3.png){#fig:4.3}

我々はしばしば複数の入力を持つ関数を最小化する。すなわち、$f : \mathbb{R}^n \rightarrow \mathbb{R}$である。「最小化」の概念を理解するためには、依然としてたった1つ（スカラ）の出力である必要がある。
複数の入力を持つ関数では、偏微分[partial derivatives]の概念を用いなければならない。偏微分$\frac{\partial}{\partial x_i} f(\boldsymbol{x})$は点$\boldsymbol{x}$において$x_i$だけが増加するたびに$f$がどれだけ変化するかを測定する。勾配[gradient]とは、微分の考え方をその微分がベクトルに関するものである場合に一般化したものである。つまり、$f$の勾配はすべての偏微分から成るベクトルであり、$\nabla_\boldsymbol{x} f(\boldsymbol{x})$と表記される。勾配の要素$i$は$x_i$に関する$f$の偏微分である。複数の次元では、臨界点はすべての勾配の要素がゼロに等しい点である。
方向$\boldsymbol{u}$（単位ベクトル）における方向微分[directional derivative]とは方向$u$における関数$f$の傾斜である。別の言い方をすれば、方向微分とは$\alpha$に関する関数$f(\boldsymbol{x} + \alpha \boldsymbol{u})$の微分であり、$\alpha = 0$で計算される。連鎖律を用いて、$\frac{\partial}{\partial \alpha} f(\boldsymbol{x} + \alpha \boldsymbol{u})$は$\alpha = 0$であるときに$\boldsymbol{u}^\top \nabla_\boldsymbol{x} f(\boldsymbol{x})$に計算される。
$f$を最小化するため、我々は$f$が最速で減少する方向を求めたい。方向微分を用いてこれを行うことができる。

$$
\min_{\boldsymbol{u}, \boldsymbol{u}^\top \boldsymbol{u} = 1} \boldsymbol{u}^\top \nabla_\boldsymbol{x} f(\boldsymbol{x})
$$

$$
= \min_{\boldsymbol{u}, \boldsymbol{u}^\top \boldsymbol{u} = 1} \| \boldsymbol{u} \|_2 \| \nabla_\boldsymbol{x} f(\boldsymbol{x}) \|_2 \cos \theta
$$

ここで、$\theta$は$\boldsymbol{u}$とその勾配のなす角である。$\| \boldsymbol{u} \|_2 = 1$で置き換えて、$\boldsymbol{u}$に依存しない因数を無視すると、これは$\min_\boldsymbol{u} \cos \theta$に単純化される。これは$\boldsymbol{u}$が勾配と反対方向を指すときに最小化される。別の言い方をすれば、勾配は真っ直ぐの上り坂を指し、負の勾配は真っ直ぐの下り坂を指す。我々は負の勾配の方向に動かすことで$f$を減少させることができる。これは最急降下法[steepest descent]とか勾配降下法[gradient descent]として知られる。

最急降下法は新しい点を提案する。

$$
\boldsymbol{x}' = \boldsymbol{x} - \epsilon \nabla_\boldsymbol{x} f(\boldsymbol{x})
$$

ここで、$\epsilon$はステップの大きさを決定する正のスカラである学習率[learning rate]である。我々はいくつかの異なる方法で$\epsilon$を選択することができる。人気のアプローチは$\epsilon$を小さな定数に設定することである。時折、我々は方向微分を消失させるステップサイズを解くことができる。もうひとつのアプローチはいくつかの$\epsilon$の値に対して$f(\boldsymbol{x} - \epsilon \nabla_\boldsymbol{x} f(\boldsymbol{x}))$を計算して、目的関数の値が最も小さくなるものを選ぶという方法である。この後者の戦略は直線探索[line search]と呼ばれる。
最急降下法はすべての勾配の要素がゼロである（または、実際には、ゼロに非常に近い）ときに収束する。いくつかの場合では、この反復的なアルゴリズムを実行するのを回避して、$\boldsymbol{x}$に対して式$\nabla_\boldsymbol{x} f(\boldsymbol{x})$を解くことで臨界点に直接ジャンプすることができるかもしれない。
勾配降下法は連続空間における最適化に限定されるにもかかわらず、より良いconfigurationsに向けて反復的に（近似的に最適な小さな移動で）小さく移動させるという汎用的な概念は離散空間に一般化できる。離散パラメータの目的関数をascendingすることはhill climbingと呼ばれている[@Russel2003]。

### 勾配の先へ：ヤコビ行列とヘッセ行列

時折、***
