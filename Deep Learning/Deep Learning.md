---
title: Deep Learning [@Goodfellow2016]
---
# はじめに

発明家たちは考える機械を作り出すことを長らく夢見ていた。この願望は少なくとも古代ギリシアの時代に遡る。神話上の人物[mythical figures]であるPygmalion、Daedalus、Hephaestusはすべて伝説的な発明家と解釈することができ、Galatea、Talos、Pandoraはすべて人工的な生命とみなすことができる。([@Ovid2004; @Sparkes1996; @Tandy1997])
プログラム可能なコンピュータが最初に発想された[conceived]とき、人々はそのような機械が賢くなれるかどうかを、それが作られる以前に100年以上に渡って、知りたいと思っていた。こんにち、人工知能(AI)は多くの実用的なアプリケーションや活発な研究テーマ[research topics]がある盛んな分野[thriving field]である。我々は手順の決まった作業[routine labor]を自動化したり、音声や画像を理解したり、診断を行ったり[make diagnoses in medicine]、基礎科学研究を補助したりする知的なソフトウェアに目を向けている。
人工知能分野の初期の頃は、人間の頭では難しい[intelectually difficult for human beings]がコンピュータには比較的簡単[relatively straightforward]である問題、すなわち、形式的で数学的な規則のリストによって説明できる問題に急速に取り組んで解決していた。後に、人工知能の真の課題は、人々が行うには容易だが形式的に説明するのが難しい作業、すなわち、話された言葉や画像中の顔を認識するような、意識せず、直観的に解いている問題を解決することであると分かった。
本書はこれらのより直観的な問題への解法について書かれている。この解法はコンピュータが経験から学び、より単純な概念との関係を通して定義される個々の概念による概念の階層の観点から世界を理解することを可能にする。経験から知識を収集することで、このアプローチはコンピュータが必要とするすべての知識を形式的に指定する人間のオペレータを必要としない。概念の階層はより単純なものからそれらを構築することでコンピュータが複雑な概念を学習することを可能にする。これらの概念がどのように積み重なって構築されるかを示すために図を描くとすると、その図は深い[deep]、すなわち、多くの層を持っている。この理由により、我々はこのアプローチをAIの深層学習[deep learning]と呼んでいる。
AIの初期の成果の多くは比較的に邪魔の無い[sterile]で形式的な環境で行われ、コンピュータはその世界に関する多くの知識を持つ必要がなかった。例えば、IBMのDeep Blueというチェスシステムは1997年に世界チャンピオンのGarry Kasparovを破った[@Hsu2002]。チェスは、勿論、64個のマスと厳密に決められた方法のみに移動できる32個のコマだけで構成される非常に単純な世界である。出来の良いチェスの戦略を考案することは途方もない成果であるが、その課題は一連のチェスのコマや可能な移動をコンピュータに説明することの難しさによるものではない。チェスは完全に形式的な規則の非常に簡単なリストによって完璧に説明できる。これはプログラマによって前もって容易に提供される。
皮肉なことに、人間にとって中でも最も難しい精神的な仕事である抽象的で形式的な作業はコンピュータにとって中でも最も簡単である。コンピュータは最強の人間のチェスプレイヤーさえも破ることが長らく可能であったが、物体や言葉を認識する平均的な人間の能力の一部に匹敵するように最近なったばかりである。人間の日々の生活は膨大な量の世界に関する知識を必要とする。この知識の大半は主観的かつ直観的であり、それゆえに、形式的な方法で明確に表現する[articulate]は難しい。コンピュータは知的な方法で振る舞うためにこれと同じ知識を捕捉する必要がある。人工知能における重要な課題のひとつはこの形式的でない知識をコンピュータにどのようにして与えるかということである。
いくつかの人工知能プロジェクトは形式言語で世界に関する知識をハードコードすることを目指していた。コンピュータは論理的な推論規則を用いてこれらの形式言語における命題[statement]に関して自動的に理由付けを行うことができる。これは人工知能の知識ベースのアプローチとして知られる。これらのプロジェクトは大きな成果には結びつかなかった。このようなプロジェクトの最も有名なもののひとつとしてCycがある[@Lenat1989]。CycはCycLと呼ばれる言語における推論エンジンおよび命題データベースである。これらの命題は人間の教師[supervisor]のひとりによって入力される。これはやっかいな[unwieldy]プロセスである。人々は世界を正確に記述するために十分な複雑さを持つ形式的な規則を考案しようと取り組む。例えば、Cycは朝に髭を剃るFredという名の人間についての話を理解できなかった[@Linde1992]。この推論エンジンは話の矛盾を検出した。つまり、人が電気的な部分を持たないことを知っているが、Fredが電気カミソリを持っていたので、"髭剃り中のFred"というエンティティが電気的な部分から構成されると理解した。そのため、Fredが髭剃り中でもヒトであるかと訪ねたのだった。
ハードコードされた知識に依存するシステムによって直面する困難はAIシステムが、生データからパターンを抽出することで、自らの知識を獲得する能力を必要としていることを示唆している。この能力は機械学習として知られる。機械学習の事始めはコンピュータが現実世界の知識を伴う問題に取り組み、主観的なように見える決定を下すことを可能にすることであった。ロジスティック回帰[logistic regression]とよばれる単純な機械学習アルゴリズムは帝王切開分娩[cesarean delivery]を推奨するかどうかを決定できる[@Mor-Yosef1990]。naive Bayesと呼ばれる単純な機械学習アルゴリズムは正当なメールとスパムメールを分けることができる。
これらの単純な機械学習アルゴリズムのパフォーマンスはそれらに与えられるデータの表現[representation]に強く依存する。例えば、ロジスティック回帰が帝王切開分娩を勧めるのに使われるとき、AIシステムは患者を直接検査しない。代わりに、医師が、子宮瘢痕[uterine scar]の有無といった、関連情報の一部をシステムに伝える。患者の表現に含まれる情報の各部分は特徴[feature]として知られる。ロジスティック回帰はこれらの患者の特徴のそれぞれが様々な結果とどれだけ関連しているかを学習する。しかし、特徴がどのように定義されているかにはまったくもって影響を与えることはない。ロジスティック回帰に、形式化された医師の報告ではなく、患者のMRIを与えた場合、有用な予測をさせることはできないだろう。MRI画像の個々のピクセルは分娩中に発生するかもしれないいずれかの合併症と僅かな相関を持っている。この表現への依存性はコンピュータ・サイエンスや日常生活にさえも至るところに現れる一般的な現象である。コンピュータサイエンスでは、データの集合を検索するような操作は、集合が上手に[intelligently]構造化され、インデックス化されると、指数関数的に速く進む。人々はアラビア数字で計算をすることは容易に可能だが、ローマ数字で計算を見出すにはさらにもっと多くの時間がかかる。表現の選択が機械学習アルゴリズムのパフォーマンスに多大な影響をもたらすことは驚くことではない。単純な視覚的な例として、[@fig:1.1]を参考にすること。

![異なる表現の例：散布図に線を引いて2つのデータのカテゴリに分けたいとしよう。左図では、デカルト座標でいくつかのデータを表していて、線を引くことはできない。右図では、極座標でデータを表していて、縦線を引いて解けるほど単純になっている。（図はDavid Warde-Farleyとの共作）](fig/1-1.png){#fig:1.1}

多くの人工知能タスクはそのタスク用に抽出された正しい特徴セットを設計し、単純な機械学習アルゴリズムにそれらの特徴を与えることで解くことができる。例えば、音声から話者を識別するのに有用な特徴は話者の声道の大きさの推定値である。この特徴は話者が男性か女性か子供かといった強力な手がかりをもたらす。
しかし、多くのタスクでは、何の特徴を抽出すべきかを知ることは難しい。例えば、写真の中の車を検出するためのプログラムを書きたいとしよう。我々は車にホイールがあることを知っているので、特徴としてホイールの有無を利用したいと思うかもしれない。残念ながら、ピクセル値の観点からホイールがどう見えるかを厳密に説明することは難しい。ホイールは単純な幾何形状を持つが、その画像は、ホイールに落ちる影、ホイールの金属部分に反射する[glaring off]太陽、車のフェンダー、ホイールの一部を覆う手前にある物体によって複雑になりうる。
この問題への解法のひとつは表現から出力へのマッピングだけでなく表現それ自体を発見するために機械学習を使うことである。このアプローチは表現学習[representation learning]として知られる。学習した表現はしばしば手作業で設計された表現で得られるものよりも更に良いパフォーマンスとなる。これらは、最小限の人間の介入で、AIシステムが新しいタスクにすばやく適応することも可能にする。表現学習アルゴリズムは単純なタスクには分単位で、複雑なタスクには数時間から数ヶ月単位で良好な特徴セットを見つけることができる。複雑なタスクに対して手動で特徴を設計することは膨大な量の人間の時間と労力を要する。つまり、研究者コミュニティ全体では何十年かかる可能性がある。
表現学習アルゴリズムの典型的な例はautoencoderである。autoencoderは入力データを異なる表現に変換するエンコーダ機能とその新しい表現を元のフォーマットに変換し直すデコーダ機能の組み合わせである。autoencoderは、入力がエンコーダとデコーダを通るとき、できるだけ多くの情報を保存するように訓練されるが、新しい表現が様々な良好な特性を持たせるようにも訓練される。異なる種類のautoencoderは異なる種類の特性を達成することを目的としている。
特徴や特徴を学習するためのアルゴリズムを設計するとき、我々の目標は通常観測データを説明するバラツキの要因[factors of variation]を分割することである。この文脈において、我々は「要因」という語を単に影響の源を分けることを指すためだけに用いる。すなわち、この要因は通常では乗算によって組み合わされない。そのような要因は直接観測される量ではしばしばない。代わりに、これらは観測可能な量に影響を与える物理世界における観測不可能な物体や観測不可能な力として存在し得る。これらは有用な簡単化した説明をもたらす人間の脳内の構築物や観測データの推測される原因としても存在し得る。これらはそのデータにおける高度なバラツキを理解するのに役立つ概念や抽象化として考えられる。発言の録音を解析するとき、バラツキの要因は話者の年齢、性別、訛り、話している言葉を含む。車の画像を解析するとき、バラツキの要因は車の位置、色、角度、太陽の明るさを含む。
多くの現実世界の人工知能アプリケーションにおける困難さの主な原因はバラツキの要因の多くがありとあらゆる観測可能なデータの断片に影響を及ぼすことである。赤い車の画像にある個々のピクセルは夜中ではほとんど真っ黒となるかもしれない。車の輪郭の形状は見る角度に依存する。ほとんどのアプリケーションはバラツキの要因を紐解き[disentangle]、考慮しないものを破棄する必要がある。
もちろん、そのような高レベルで抽象的な特徴を生データから抽出することは非常に困難である可能性がある。話者の訛りのような、これらのバラツキの要因の多くは洗練されたほぼ人間レベルのデータの理解を用いることでのみ識別できる。元の問題を解くのとほぼ同じくらい表現を得ることが難しいとき、表現学習は一見役に立つようには見えない。
深層学習[deep learning]は表現学習におけるこの中心的問題を他のより単純な表現の観点から説明される表現を導入することによって解決する。深層学習はコンピュータがより単純な概念から複雑な概念を構築することを可能にする。[@fig:1.2]はどのように深層学習システムがヒトの画像の概念をカドや輪郭のような単純な概念を組み合わせることで表現する事ができるかを示す。そして、カドや輪郭は同様にエッジで定義される。

![深層学習モデルの図解。コンピュータにとって、ピクセル値の集合で表されるこの画像のような、そのままの感覚の入力データの意味を理解することは難しい。一連のピクセルから物体の正体へマッピングする関数は非常に複雑である。このマッピングを学習または評価することは直接的に取り組んだ場合には打開不可能であるように思える。深層学習は望まれる複雑なマッピングを、それぞれがモデルの異なる層によって記述される、入れ子になった単純なマッピングの列に分解することでこの難しさを解決する。この入力は、観測可能な変数を含むという理由で名付けられた、可視層[visible layer]で表現される。そして、隠れ層[hidden layer]の列は画像から抽象的な特徴を徐々に抽出する。これらの層は値がデータに含まれずことから「隠れ」と呼ばれる。その代わりに、モデルは概念が観測データにおける関係を説明するのに有用であるかを決定しなければならない。ここにある画像は各隠れユニットによって表現される特徴の種類の可視化したものである。ピクセルがあるとすると、第1層は、近傍のピクセルの明るさを比較することで、エッジを容易に識別できる。第1隠れ層のエッジの説明があるとすると、第2隠れ層はカドや拡張された輪郭を容易に検索できる。これは、エッジの集合として識別可能である。第2隠れ層のカドや輪郭に関する画像の説明があるとすると、第3隠れ層は、カドや輪郭の特定の集合を見つけることで、特定の物体の全体像を検出できる。最後に、この物体部分に関する画像の説明は画像中に物体の存在を識別するのに使うことができる。画像は @Zeiler2014 の許可を得て転載した。](fig/1-2.png){#fig:1.2}

深層学習モデルの典型的な例はfeedforward deep networkや多層パーセプトロン[multilayer perceptron; MLP]である。多層パーセプトロンはある入力値の集合を出力値にマッピングする単なる数学的な関数である。この関数は多数のより単純な関数を組み立てることで形作られる。異なる数学的な関数のそれぞれのアプリケーションを入力の新しい表現をもたらすとみなすことができる。
データに対して正しい表現を学習するというアイデアは深層学習に対する一側面である。深層学習の別の側面は深さがコンピュータに多段のコンピュータプログラムを学習することを可能にするということである。表現の各層は並列に別の命令セットを実行した後のコンピュータのメモリの状態として考えることができる。より大きな深さを持つネットワークはより多くの命令を次第に実行できる。順次命令は、以後の命令が以前の命令の結果を参照し直すことができるので、強大な力をもたらす。深層学習のこの視点により、層のactivationにあるすべての情報は入力を説明するバラツキの要因を必ずしもエンコードしているわけではない。その表現は入力を理解できるプログラムを実行するのに役立つ状態情報をも保存する。この状態情報は伝統的なコンピュータ・プログラムにおけるカウンタやポインタに類似するかもしれない。入力の中身には全くもって関係ないが、モデルがその処理をまとめるのに役立つ。
モデルの深さを測る主要な方法は2つある。ひとつの見方はそのアーキテクチャを計算するのに実行する必要がある順次命令の数に基づく。我々はこれを入力を考慮してモデルの各出力を計算する方法を述べるフローチャートを通る最長経路の長さとみなすことができる。2つの等価なコンピュータプログラムがどの言語でプログラムが書かれているかに依存して異なる長さを持つであろうことと同様に、同じ関数はどの関数がフローチャートにおける個々のステップとして利用する事ができるかに依存して異なる深さを持つフローチャートとして描かれ得る。[@fig:1.3]はどのようにしてこの言語の選択が同じアーキテクチャに対して2つの異なる値[measurements]をもたらし得るかを描いている。

![各ノードが操作を行うような、入力を出力にマッピングする計算グラフの図解。深さは入力から出力への最長経路の長さであるが、取り得る計算ステップを構成するやり方の定義に依存する。これらのグラフで図示される計算はロジスティック回帰モデル$\sigma(w^T x)$の出力である。ここで、$\sigma$はlogistic sigmoid functionである。コンピュータ言語の要素として加算、乗算、logistic sigmoidを使う場合、このモデルは3の深度を持つ。ロジスティック回帰それ自体を1つの要素と見る場合、このモデルは1の深度を持つ。](fig/1-3.png){#fig:1.3}

もうひとつのアプローチは、深い確率的なモデルで使われるが、モデルの深さを計算グラフの深さではなく概念が互いにどう関係するかを記述するグラフの深さであるとみなす。この場合、各概念の表現を計算する必要がある計算のフローチャートの深さは概念それ自体のグラフよりも深いかもしれない。これは、より複雑な概念に関する情報を与えられれば、より単純な概念のシステムの理解を改良できるためである。例えば、影の中にある1つの眼を持つ顔の画像を観察するAIシステムは最初のうちは1つの眼のみを理解するかもしれない。顔が存在することを検出した後は、そのシステムは第2の眼が同様におそらく存在することを推論できる。この場合、概念のグラフは2つの層、すなわち、眼のための層と顔のための層のみを含むが、計算のグラフはn回を与えるように各概念の推定値を改良するならば、2n個の層を含む。
これら2つの見方、すなわち、計算グラフの深さと確率的なモデルのグラフの深さ、のどちらが最適であるかは常に明確ではないので、
