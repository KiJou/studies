---
title: Deep Learning [@Goodfellow2016]
---
# はじめに

発明家たちは考える機械を作り出すことを長らく夢見ていた。この願望は少なくとも古代ギリシアの時代に遡る。神話上の人物[mythical figures]であるPygmalion、Daedalus、Hephaestusはすべて伝説的な発明家と解釈することができ、Galatea、Talos、Pandoraはすべて人工的な生命とみなすことができる。([@Ovid2004; @Sparkes1996; @Tandy1997])
プログラム可能なコンピュータが最初に発想された[conceived]とき、人々はそのような機械が賢くなれるかどうかを、それが作られる以前に100年以上に渡って、知りたいと思っていた。こんにち、人工知能(AI)は多くの実用的なアプリケーションや活発な研究テーマ[research topics]がある盛んな分野[thriving field]である。我々は手順の決まった作業[routine labor]を自動化したり、音声や画像を理解したり、診断を行ったり[make diagnoses in medicine]、基礎科学研究を補助したりする知的なソフトウェアに目を向けている。
人工知能分野の初期の頃は、人間の頭では難しい[intelectually difficult for human beings]がコンピュータには比較的簡単[relatively straightforward]である問題、すなわち、形式的で数学的な規則のリストによって説明できる問題に急速に取り組んで解決していた。後に、人工知能の真の課題は、人々が行うには容易だが形式的に説明するのが難しい作業、すなわち、話された言葉や画像中の顔を認識するような、意識せず、直観的に解いている問題を解決することであると分かった。
本書はこれらのより直観的な問題への解法について書かれている。この解法はコンピュータが経験から学び、より単純な概念との関係を通して定義される個々の概念による概念の階層の観点から世界を理解することを可能にする。経験から知識を収集することで、このアプローチはコンピュータが必要とするすべての知識を形式的に指定する人間のオペレータを必要としない。概念の階層はより単純なものからそれらを構築することでコンピュータが複雑な概念を学習することを可能にする。これらの概念がどのように積み重なって構築されるかを示すために図を描くとすると、その図は深い[deep]、すなわち、多くの層を持っている。この理由により、我々はこのアプローチをAIの深層学習[deep learning]と呼んでいる。
AIの初期の成果の多くは比較的に邪魔の無い[sterile]で形式的な環境で行われ、コンピュータはその世界に関する多くの知識を持つ必要がなかった。例えば、IBMのDeep Blueというチェスシステムは1997年に世界チャンピオンのGarry Kasparovを破った[@Hsu2002]。チェスは、勿論、64個のマスと厳密に決められた方法のみに移動できる32個のコマだけで構成される非常に単純な世界である。出来の良いチェスの戦略を考案することは途方もない成果であるが、その課題は一連のチェスのコマや可能な移動をコンピュータに説明することの難しさによるものではない。チェスは完全に形式的な規則の非常に簡単なリストによって完璧に説明できる。これはプログラマによって前もって容易に提供される。
皮肉なことに、人間にとって中でも最も難しい精神的な仕事である抽象的で形式的な作業はコンピュータにとって中でも最も簡単である。コンピュータは最強の人間のチェスプレイヤーさえも破ることが長らく可能であったが、物体や言葉を認識する平均的な人間の能力の一部に匹敵するように最近なったばかりである。人間の日々の生活は膨大な量の世界に関する知識を必要とする。この知識の大半は主観的かつ直観的であり、それゆえに、形式的な方法で明確に表現する[articulate]は難しい。コンピュータは知的な方法で振る舞うためにこれと同じ知識を捕捉する必要がある。人工知能における重要な課題のひとつはこの形式的でない知識をコンピュータにどのようにして与えるかということである。
いくつかの人工知能プロジェクトは形式言語で世界に関する知識をハードコードすることを目指していた。コンピュータは論理的な推論規則を用いてこれらの形式言語における命題[statement]に関して自動的に理由付けを行うことができる。これは人工知能の知識ベースのアプローチとして知られる。これらのプロジェクトは大きな成果には結びつかなかった。このようなプロジェクトの最も有名なもののひとつとしてCycがある[@Lenat1989]。CycはCycLと呼ばれる言語における推論エンジンおよび命題データベースである。これらの命題は人間の教師[supervisor]のひとりによって入力される。これはやっかいな[unwieldy]プロセスである。人々は世界を正確に記述するために十分な複雑さを持つ形式的な規則を考案しようと取り組む。例えば、Cycは朝に髭を剃るFredという名の人間についての話を理解できなかった[@Linde1992]。この推論エンジンは話の矛盾を検出した。つまり、人が電気的な部分を持たないことを知っているが、Fredが電気カミソリを持っていたので、"髭剃り中のFred"というエンティティが電気的な部分から構成されると理解した。そのため、Fredが髭剃り中でもヒトであるかと訪ねたのだった。
ハードコードされた知識に依存するシステムによって直面する困難はAIシステムが、生データからパターンを抽出することで、自らの知識を獲得する能力を必要としていることを示唆している。この能力は機械学習として知られる。機械学習の事始めはコンピュータが現実世界の知識を伴う問題に取り組み、主観的なように見える決定を下すことを可能にすることであった。ロジスティック回帰[logistic regression]とよばれる単純な機械学習アルゴリズムは帝王切開分娩[cesarean delivery]を推奨するかどうかを決定できる[@Mor-Yosef1990]。naive Bayesと呼ばれる単純な機械学習アルゴリズムは正当なメールとスパムメールを分けることができる。
これらの単純な機械学習アルゴリズムのパフォーマンスはそれらに与えられるデータの表現[representation]に強く依存する。例えば、ロジスティック回帰が帝王切開分娩を勧めるのに使われるとき、AIシステムは患者を直接検査しない。代わりに、医師が、子宮瘢痕[uterine scar]の有無といった、関連情報の一部をシステムに伝える。患者の表現に含まれる情報の各部分は特徴[feature]として知られる。ロジスティック回帰はこれらの患者の特徴のそれぞれが様々な結果とどれだけ関連しているかを学習する。しかし、特徴がどのように定義されているかにはまったくもって影響を与えることはない。ロジスティック回帰に、形式化された医師の報告ではなく、患者のMRIを与えた場合、有用な予測をさせることはできないだろう。MRI画像の個々のピクセルは分娩中に発生するかもしれないいずれかの合併症と僅かな相関を持っている。この表現への依存性はコンピュータ・サイエンスや日常生活にさえも至るところに現れる一般的な現象である。コンピュータサイエンスでは、データの集合を検索するような操作は、集合が上手に[intelligently]構造化され、インデックス化されると、指数関数的に速く進む。人々はアラビア数字で計算をすることは容易に可能だが、ローマ数字で計算を見出すにはさらにもっと多くの時間がかかる。表現の選択が機械学習アルゴリズムのパフォーマンスに多大な影響をもたらすことは驚くことではない。単純な視覚的な例として、[@fig:1.1]を参考にすること。

![異なる表現の例：散布図に線を引いて2つのデータのカテゴリに分けたいとしよう。左図では、デカルト座標でいくつかのデータを表していて、線を引くことはできない。右図では、極座標でデータを表していて、縦線を引いて解けるほど単純になっている。（図はDavid Warde-Farleyとの共作）](fig/1-1.png){#fig:1.1}

多くの人工知能タスクはそのタスク用に抽出された正しい特徴セットを設計し、単純な機械学習アルゴリズムにそれらの特徴を与えることで解くことができる。例えば、音声から話者を識別するのに有用な特徴は話者の声道の大きさの推定値である。この特徴は話者が男性か女性か子供かといった強力な手がかりをもたらす。
しかし、多くのタスクでは、何の特徴を抽出すべきかを知ることは難しい。例えば、写真の中の車を検出するためのプログラムを書きたいとしよう。我々は車にホイールがあることを知っているので、特徴としてホイールの有無を利用したいと思うかもしれない。残念ながら、ピクセル値の観点からホイールがどう見えるかを厳密に説明することは難しい。ホイールは単純な幾何形状を持つが、その画像は、ホイールに落ちる影、ホイールの金属部分に反射する[glaring off]太陽、車のフェンダー、ホイールの一部を覆う手前にある物体によって複雑になりうる。
この問題への解法のひとつは表現から出力へのマッピングだけでなく表現それ自体を発見するために機械学習を使うことである。このアプローチは表現学習[representation learning]として知られる。学習した表現はしばしば手作業で設計された表現で得られるものよりも更に良いパフォーマンスとなる。これらは、最小限の人間の介入で、AIシステムが新しいタスクにすばやく適応することも可能にする。表現学習アルゴリズムは単純なタスクには分単位で、複雑なタスクには数時間から数ヶ月単位で良好な特徴セットを見つけることができる。複雑なタスクに対して手動で特徴を設計することは膨大な量の人間の時間と労力を要する。つまり、研究者コミュニティ全体では何十年かかる可能性がある。
表現学習アルゴリズムの典型的な例はautoencoderである。autoencoderは入力データを異なる表現に変換するエンコーダ機能とその新しい表現を元のフォーマットに変換し直すデコーダ機能の組み合わせである。autoencoderは、入力がエンコーダとデコーダを通るとき、できるだけ多くの情報を保存するように訓練されるが、新しい表現が様々な良好な特性を持たせるようにも訓練される。異なる種類のautoencoderは異なる種類の特性を達成することを目的としている。
特徴や特徴を学習するためのアルゴリズムを設計するとき、我々の目標は通常観測データを説明するバラツキの要因[factors of variation]を分割することである。この文脈において、我々は「要因」という語を単に影響の源を分けることを指すためだけに用いる。すなわち、この要因は通常では乗算によって組み合わされない。そのような要因は直接観測される量ではしばしばない。代わりに、これらは観測可能な量に影響を与える物理世界における観測不可能な物体や観測不可能な力として存在し得る。これらは有用な簡単化した説明をもたらす人間の脳内の構築物や観測データの推測される原因としても存在し得る。これらはそのデータにおける高度なバラツキを理解するのに役立つ概念や抽象化として考えられる。発言の録音を解析するとき、バラツキの要因は話者の年齢、性別、訛り、話している言葉を含む。車の画像を解析するとき、バラツキの要因は車の位置、色、角度、太陽の明るさを含む。
多くの現実世界の人工知能アプリケーションにおける困難さの主な原因はバラツキの要因の多くがありとあらゆる観測可能なデータの断片に影響を及ぼすことである。赤い車の画像にある個々のピクセルは夜中ではほとんど真っ黒となるかもしれない。車の輪郭の形状は見る角度に依存する。ほとんどのアプリケーションはバラツキの要因を紐解き[disentangle]、考慮しないものを破棄する必要がある。
もちろん、そのような高レベルで抽象的な特徴を生データから抽出することは非常に困難である可能性がある。話者の訛りのような、これらのバラツキの要因の多くは洗練されたほぼ人間レベルのデータの理解を用いることでのみ識別できる。元の問題を解くのとほぼ同じくらい表現を得ることが難しいとき、表現学習は一見役に立つようには見えない。
深層学習[deep learning]は表現学習におけるこの中心的問題を他のより単純な表現の観点から説明される表現を導入することによって解決する。深層学習はコンピュータがより単純な概念から複雑な概念を構築することを可能にする。[@fig:1.2]はどのように深層学習システムがヒトの画像の概念をカドや輪郭のような単純な概念を組み合わせることで表現する事ができるかを示す。そして、カドや輪郭は同様にエッジで定義される。

![深層学習モデルの図解。コンピュータにとって、ピクセル値の集合で表されるこの画像のような、そのままの感覚の入力データの意味を理解することは難しい。一連のピクセルから物体の正体へマッピングする関数は非常に複雑である。このマッピングを学習または評価することは直接的に取り組んだ場合には打開不可能であるように思える。深層学習は望まれる複雑なマッピングを、それぞれがモデルの異なる層によって記述される、入れ子になった単純なマッピングの列に分解することでこの難しさを解決する。この入力は、観測可能な変数を含むという理由で名付けられた、可視層[visible layer]で表現される。そして、隠れ層[hidden layer]の列は画像から抽象的な特徴を徐々に抽出する。これらの層は値がデータに含まれずことから「隠れ」と呼ばれる。その代わりに、モデルは概念が観測データにおける関係を説明するのに有用であるかを決定しなければならない。ここにある画像は各隠れユニットによって表現される特徴の種類の可視化したものである。ピクセルがあるとすると、第1層は、近傍のピクセルの明るさを比較することで、エッジを容易に識別できる。第1隠れ層のエッジの説明があるとすると、第2隠れ層はカドや拡張された輪郭を容易に検索できる。これは、エッジの集合として識別可能である。第2隠れ層のカドや輪郭に関する画像の説明があるとすると、第3隠れ層は、カドや輪郭の特定の集合を見つけることで、特定の物体の全体像を検出できる。最後に、この物体部分に関する画像の説明は画像中に物体の存在を識別するのに使うことができる。画像は @Zeiler2014 の許可を得て転載した。](fig/1-2.png){#fig:1.2}

深層学習モデルの典型的な例はfeedforward deep networkや多層パーセプトロン[multilayer perceptron; MLP]である。多層パーセプトロンはある入力値の集合を出力値にマッピングする単なる数学的な関数である。この関数は多数のより単純な関数を組み立てることで形作られる。異なる数学的な関数のそれぞれのアプリケーションを入力の新しい表現をもたらすとみなすことができる。
データに対して正しい表現を学習するというアイデアは深層学習に対する一側面である。深層学習の別の側面は深さがコンピュータに多段のコンピュータプログラムを学習することを可能にするということである。表現の各層は並列に別の命令セットを実行した後のコンピュータのメモリの状態として考えることができる。より大きな深さを持つネットワークはより多くの命令を次第に実行できる。順次命令は、以後の命令が以前の命令の結果を参照し直すことができるので、強大な力をもたらす。深層学習のこの視点により、層のactivationにあるすべての情報は入力を説明するバラツキの要因を必ずしもエンコードしているわけではない。その表現は入力を理解できるプログラムを実行するのに役立つ状態情報をも保存する。この状態情報は伝統的なコンピュータ・プログラムにおけるカウンタやポインタに類似するかもしれない。入力の中身には全くもって関係ないが、モデルがその処理をまとめるのに役立つ。
モデルの深さを測る主要な方法は2つある。ひとつの見方はそのアーキテクチャを計算するのに実行する必要がある順次命令の数に基づく。我々はこれを入力を考慮してモデルの各出力を計算する方法を述べるフローチャートを通る最長経路の長さとみなすことができる。2つの等価なコンピュータプログラムがどの言語でプログラムが書かれているかに依存して異なる長さを持つであろうことと同様に、同じ関数はどの関数がフローチャートにおける個々のステップとして利用する事ができるかに依存して異なる深さを持つフローチャートとして描かれ得る。[@fig:1.3]はどのようにしてこの言語の選択が同じアーキテクチャに対して2つの異なる値[measurements]をもたらし得るかを描いている。

![各ノードが操作を行うような、入力を出力にマッピングする計算グラフの図解。深さは入力から出力への最長経路の長さであるが、取り得る計算ステップを構成するやり方の定義に依存する。これらのグラフで図示される計算はロジスティック回帰モデル$\sigma(w^T x)$の出力である。ここで、$\sigma$はlogistic sigmoid functionである。コンピュータ言語の要素として加算、乗算、logistic sigmoidを使う場合、このモデルは3の深度を持つ。ロジスティック回帰それ自体を1つの要素と見る場合、このモデルは1の深度を持つ。](fig/1-3.png){#fig:1.3}

もうひとつのアプローチは、深い確率的なモデルで使われるが、モデルの深さを計算グラフの深さではなく概念が互いにどう関係するかを記述するグラフの深さであるとみなす。この場合、各概念の表現を計算する必要がある計算のフローチャートの深さは概念それ自体のグラフよりも深いかもしれない。これは、より複雑な概念に関する情報を与えられれば、より単純な概念のシステムの理解を改良できるためである。例えば、影の中にある1つの眼を持つ顔の画像を観察するAIシステムは最初のうちは1つの眼のみを理解するかもしれない。顔が存在することを検出した後は、そのシステムは第2の眼が同様におそらく存在することを推論できる。この場合、概念のグラフは2つの層、すなわち、眼のための層と顔のための層のみを含むが、計算のグラフはn回を与えるように各概念の推定値を改良するならば、2n個の層を含む。
これら2つの見方、すなわち、計算グラフの深さと確率的なモデルのグラフの深さ、のどちらが最適であるかは常に明確ではないので、そして、これらのグラフを構築する一連の最小要素は人によりけりなので、コンピュータプログラムの長さに対する単一の正しい値が存在しないのと同様に、アーキテクチャの深度に対する単一の正しい値は存在しない。また、モデルが「深層」足り得るためにどれだけの深さが必要であるかに関してのコンセンサスは存在しない。しかし、深層学習は関数を学習したり概念を学習したりする構造の量を伝統的な機械学習が行う場合よりも多く伴うモデルの研究であると問題なくみなすことができる。
まとめると、本書の主題である深層学習はAIへのアプローチである。具体的には、機械学習の一種であり、コンピュータシステムが経験とデータによって改善することを可能にする技術である。我々は機械学習が複雑な現実世界の環境で操作できるAIシステムを構築するための唯一実行可能なアプローチであると主張する。深層学習は、より単純な概念との関係で定義される各概念とより抽象度の低いものの観点から計算されるより抽象的な表現を持つ入れ子になった概念の階層として世界を表現することで大きな力と柔軟性を達成する機械学習の特定の種類である。[@fig:1.4]はこれらの異なるAI分野の間の関係を図示する。[@fig:1.5]はそれぞれがどのように機能するかの高レベルな図式を提示する。

![どんな深層学習が表現学習の一種であるかということ、同様に機械学習の一種であるということ、いろんなものに使われているがAIへのアプローチのすべてではないということを示すベン図。ベン図の各セクションはAI技術の例を含む。](fig/1-4.png){#fig:1.4}

![AIシステムの異なる部分が異なるAI分野内と互いにどのように関連し合うかを示すフローチャート。色付き[shaded boxes]はデータから学習可能である要素を示す。](fig/1-5.png){#fig:1.5}

## 本書を読むべきは誰か？

- 要約：
    - この本は機械学習を学ぶ学生や機械学習を使いたいソフトウェアエンジニアを読者として想定している
    - パート1は応用数学と機械学習の基礎、パート2実践的な深度学習アルゴリズム、パート3は最新研究動向
    - 必要無いと感じた箇所は順次読み飛ばしてもらって構わない

![本書の高レベルな構成図。ある章からある章への矢印は前者が後者を理解することへの前提となる資料であることを示す。](fig/1-6.png){#fig:1.6}

## 深層学習における歴史的傾向

ある歴史的な文脈で深度学習を理解することは最も簡単である。深度学習の詳細な歴史を提供する代わりに、いくつかの重要な傾向を見ていく。

- 深度学習は長く濃い歴史を歩んできたが、異なる哲学的な視点を反映するように、いろんな名前で行われ、人気には上がり下がりがあった。
- 深度学習は扱える訓練データの量が増えるにつれて有用になっていった。
- 深度学習モデルは深度学習に対するコンピュータインフラ（ハードウェアとソフトウェアの両方）が改良するにつれて時間とともに大型化してきた。
- 深度学習は時間とともに正確性を向上させながら、ますます複雑になるアプリケーションを解いてきた。

### 様々な呼び名とニューラルネットワークの運命の変化

我々は、本書の多くの読者が深層学習をワクワクする新技術として耳にしてきたが、新興の分野に関する本で「歴史」と書かれているのを目にして驚いている、と予測している。事実、深層学習は1940年代にまで遡ることができる。現在の人気に先立って何年もの間比較的人気がなかった、また、最近では「深層学習」とだけ呼ばれているが、様々な異なる呼び名で広まっていたことから、深度学習は単に新しいように見えるだけである。この分野は、異なる研究者や異なる見方の影響を反映するために、幾度となくリブランディングを繰り返してきた。
深層学習の包括的な歴史は本書の範疇を逸脱する。しかし、いくつかの基本的な前後関係[context]は深層学習を理解するために有用である。大まかに言えば、3つの発展の波があった。1940年代から1960年代におけるcyberneticsとして知られる深層学習、1980年代から1990年代におけるconnectionismとして知られる深層学習、2006年に始まる深層学習の名の下の現在の再起である。これは[@fig:1.7]で定量的に図示される。

![Google Booksに従って、"cybernetics"、"connectionism"または"neural networks"としての語句の頻度によって計測される通りの、人工ニューラルネット研究の3つの歴史的な波のうちの2つ（第三波は出現が最近すぎる）。第一波は、biological learning[@McCulloch1943; @Hebb1949]の理論群の発展や単一のニューロンの訓練を可能にするパーセプトロン[@Rosenblatt1958]のような最初のモデルの実装とともに、1940年代から1960年代にcyberneticsとして始まった。第二波は、1つか2つの隠れ層を持つニューラルネットワークを訓練するための逆伝播法[@Rumelhart1986a]とともに、1980年から1995年の間のconnectionistアプローチとして始まった。現在の第三波である深層学習は2006年頃に始まり[@Hinton2006; @Bengio2007; @Ranzato2007a]、2016年現在には本の形としてたった今出現している。他の2つの波は関連する科学活動が起こってからかなり後に本の形として同じように現れた。](fig/1-7.png){#fig:1.7}

我々がこんにち認識している最初期の学習アルゴリズムのいくつかはbiological learningの計算モデル、すなわち、学習が脳内でどのように起こる、または、起こり得るかについてのモデルであることが意図されていた。結果として、深層学習が広まったときの名前のひとつに人工ニューラルネットワーク[artifiicial neural networks; ANN]というものがある。これに対応する深層学習モデルの見方は、これらが（人間の脳かその他の動物の脳のいずれかの）生物学的な脳に触発された工学システムであるという点である。機械学習にt買われるニューラルネットワークの種類は時折に脳の機能を理解するために使われてきた[@Hinton1991]が、これらは現実的な生物学的な機能のモデルとして一般に設計されていない。深層学習でのニューラル的視点は2つの主なアイデアによって動機付けられる。アイデアのひとつは脳が知的な振る舞いが可能であるという例えによる証明をもたらすということであり、知能を構築するのに概念的に簡単な道筋は脳の背後にある計算の原則をリバースエンジニアリングして、その機能性を複製することである。もうひとつの見方は脳や人間の知能の基礎をなす原則を理解することがとても興味深いことになるだろうということである。つまり、これらの基礎科学の疑問に光を当てる機械学習モデルは工学アプリケーションを解決する能力以外では有用である。
モダンな用語としての「深度学習」は機械学習モデルの現在の種類に関する神経科学的な視点を超えている。これは複数の構成レベルを学習するというより一般的な原則に訴える。これは、神経に触発される必要のない機械学習フレームワークで適用させることができる。
モダンな深層学習の最初期のものは神経科学的な視点から動機付けられる単純な線形モデルであった。これらのモデルは$n$個の入力値$x_1, \dots, x_n$を取り、出力$y$に関係づけるように設計された。これらのモデルは重み$w_1, \dots, w_n$を学習し、出力$f(\mathbb{x}, \mathbb{w}) = x_1 w_1 + \dots = x_n w_n$を計算するだろう。このニューラルネットワーク研究の第一波は、[@fig:1.7]に記されるように、cyberneticsとして知られた。
McCulloch-Pittsのニューロン[@McCulloch1943]は初期の脳機能のモデルであった。この線形モデルは$f(x, w)$が正か負かを確かめることで入力の2つの異なるカテゴリを認識できた。もちろん、モデルがカテゴリの望ましい定義に一致するためには、重みを正確に設定する必要があった。これらの重みは人間のオペレータによって設定させることができた。1950年代には、パーセプトロン[@Rosenblatt1958; @Rosenblat1962]は各カテゴリから入力例を与えることでカテゴリを定義得る重みを学習する事ができた最初のモデルとなった。ほぼ同時期に始まったadaptive linear element (ADALINE)は実数を予測するために$f(x)$の値自体を単純に返す[@Widrow1960]。また、データからこれらの値を予測するように学習することができた。
これらの単純な学習アルゴリズムは近年の機械学習の状況に大きく影響した。ADALINEの重みを適合するのに使われる訓練アルゴリズムは確率的勾配降下法[stochastic gradient descent]と呼ばれるアルゴリズムの特殊な場合であった。確率的勾配降下法アルゴリズムの微修正版はこんにちの深度学習モデルに対する支配的な訓練アルゴリズムとして存続している。
パーセプトロンやADALINEで使われる$f(x, w)$に基づくモデルは線形モデルと呼ばれる。これらのモデルは最も広く使われる機械学習モデルのひとつとして存続しているが、多くの場合、元のモデルが訓練した方法ではない異なる方法で訓練される。
線形モデルは多くの制限がある。最も有名なものとして、これらはXOR関数を学習できない。ここで、$f([0, 1], w) = 1$かつ$f([1, 0], w) = 1$だが、$f([1, 1], w) = 0$かつ$f([0, 0], w) = 0$である。線形モデルにおけるこれらの欠点を見つけた批評家たちは一般に生物学に触発された学習に対して反発を起こした[@Minsky1969]。これはニューラルネットワークの人気における最初の大きな落ち込み[first major dip]であった。
こんにち、神経科学は深層学習の研究者にとっての重要なインスピレーション源とみなされているが、当分野に対する主要な手引き[predominant guide]ではもはやない。
こんにちの深層学習研究における神経科学の役割の縮小に対する主な理由は単純に手引きとして使うには脳に関して十分な情報を持っていないということにある。脳で使われる実際のアルゴリズムの深い理解を得るには、（最低限でも）何千の相互接続されたニューロンの活動を同時にモニターすることができる必要があるだろう。我々はこれをすることができないので、最も単純でよく研究されている脳の一部のいくつかでさえもなかなか理解できていない[@Olshausen2005]。
神経科学は単一の深層学習アルゴリズムが多くの異なるタスクを解くことが可能であってほしいと思う理由をもたらした。神経科学者はフェレットが視覚の信号を脳の聴覚を処理する領域に送るようにつなぎ替えるとそこで「見る」ことを学習することができることを発見した[@VonMelchner2000]。これは多くの哺乳類の脳がその脳で処理される様々なタスクのほとんどを解くために単一のアルゴリズムを用いているのだろうということを示唆している。この仮説の以前では、機械学習研究は、自然言語処理、視覚、経路計画[motion planning]、発話認識を研究する研究者の異なるコミュニティがあり、更に分かれていた。こんにち、これらのアプリケーションのコミュニティは依然として別れたままだが、同時に深層学習の研究グループがこれらの応用分野の多く、さらには、すべてを研究することは一般的である。
我々は神経科学由来のいくつかの大まかなガイドラインを描くことができる。お互いの相互作用を介することでのみ知的になる多くの計算ユニットを持つことの基本的なアイデアは脳に触発されている。neocognitron[@Fukushima1980]は哺乳類の視覚系の構造に触発された画像処理のための強力なモデルのアーキテクチャをもたらした。これは後に、[@sec:9.10]に見られる、モダンなconvolutional networkの基礎となった[@LeCun1998b]。こんにちの殆どのニューラルネットワークは正規化線形ユニット[rectified linear unit]と呼ばれるモデルのニューロンに基づいている。オリジナルのcognitron[@Fukushima1975]は我々の脳機能の知識に強く触発されたより複雑なバージョンを導入した。単純化されたモダンなバージョンは、1つのinfluenceとして神経科学を引用する@Nair2010や@Glorot2011a、より工学指向なinfluencesを引用する@Jarrett2009といった、多くの視点からのアイデアを合体させて開発された。神経科学は重要なインスピレーション源である一方、厳格な手引きと受け取る必要はない。我々は実際のニューロンがモダンな正規化線形ユニット以上に非常に様々な関数を計算することを知っているが、ニューロンを現実に近づけることは機械学習のパフォーマンスに改善を未だもたらしていない。また、神経科学はいくつかのニューラルネットワークのアーキテクチャにうまくインスピレーションを与えたが、我々はこれらのアーキテクチャを訓練するのに使う学習アルゴリズムに対するさらなる手引きを提示するための、神経科学に対するbiological learningに関して未だ十分に知らない。報道記事は脳と深層学習の類似性をしばしば強調する。これは、kernel machinesやベイズ統計のような他の機械学習分野で働いている研究者よりも、深層学習の研究者が1つの影響として脳を引用する可能性が高いという点では正しいが、脳をシミュレートする試みとして深層学習を見るべきではない。モダンな深層学習は多数の分野、特に、線形代数、確率論、情報理論、数値最適化のような応用数学基盤からインスピレーションを受けいる。幾人かの深層学習の研究者は重要なインスピレーション源として神経科学を引用するが、その他の人たちは神経科学を全く考慮しない。
アルゴリズムレベルで脳がどのように働くかを理解する努力が健在であることは記しておきたい。この努力は「計算論的神経科学[computational neuroscience]」として主に知られ、深層学習とは研究分野が分かれている。研究者にとって両分野を行ったり来たりすることは普通のことである。深層学習の分野は知能を必要とするタスクをうまく解く事ができるコンピュータシステムを構築する方法と主に関係しており、計算論的神経科学は脳が実際にどのように機能しているかのより正確なモデルを構築することと主に関係している。1980年代には、connectionismやparalell distributed processingと呼ばれるムーブメントを介してニューラルネットワーク研究の第二波が大半出現した[@Rumelhart1986c; @McClelland1995]。connectionismは認知科学の文脈で発生した。認知科学は複数の異なる解析レベルを組み合わせて意識を理解する学際的アプローチである。1980年の初頭では、ほとんどの認知科学者は記号推論[symbolic reasoning]のモデルを研究した。その人気にもかかわらず、記号モデルはどのようにして脳がニューロンを用いて実際に実装できるだろうかという観点から説明するのが難しかった。connectionistsはニューロン的な実装に実際に根拠を置くことができる認知のモデルを研究し始めた[@Touretzky1985]。これは1940年代の心理学者Donald Hebbの研究まで遡る多くのアイデアを復活させた。
connectionismの中心的なアイデアは多数の単純な計算ユニットが一緒にネットワーク化されるとき知的な振る舞いを達成できることである。この洞察は計算モデルにおける隠れユニットへ適用されるように生物学的な神経系におけるニューロンにも同様に適用される。
1980年代のconnectionism運動の間には、こんにちの深度学習の中心にあり続けるいくつかの重要な概念が生じた。
これらの概念のひとつは分散表現[distributed representation]についてである[@Hinton1986]。これはシステムへの各入力が多くの特徴によって表現されるべきであり、各特徴が多くの取り得る入力の表現を伴うべきであるというアイデアである。例えば、車、トラック、鳥を認識できる視覚システムがあり、これらの物体が赤、緑、青のいずれかとしよう。表現する方法の一つとして、これらの入力は、赤いトラック、赤い車、赤い鳥、緑のトラック、以下略といった9つの取り得る組み合わせのそれぞれに対して活性化する個別のニューロンまたは隠れユニットを持つことだろう。これは9つの異なるニューロンを必要とし、各ニューロンは色の概念と物体の正体を独立して学習しなければならない。この状況を改善する方法のひとつとして、色を述べる3つのニューロンと物体の正体を述べる3つのニューロンによる分散表現を使うことがある。これは合計9つではなく6つのニューロンのみを必要とし、赤さを説明するニューロンは、ある特定の物体カテゴリの画像からだけでなく、車、トラック、鳥の画像から赤さについて学習できる。分散表現の概念は本書の中心であり、[@sec:15]でより詳細に記述してある。
もうひとつのconnectionist運動の成果は内部表現を伴うディープニューラルネットワークを訓練するために逆伝播法をうまく利用したことと、逆伝播法を普及させたことである[@Rumelhart1986a; @LeCun1987]。このアルゴリズムは人気が上がったり下がったりしてきたが、本書を執筆している現在では、深層モデルを訓練する支配的なアプローチである。
1990年代に、研究者たちはニューラルネットワークのシーケンスのモデリングについて重要な発展を成し遂げた。@Hochreiter1991と@Bengio1994は、[@sec:10.7]で示されるように、長いシーケンスのモデリングにおいて基盤の数学的な困難さのいくつかを識別した。@Hochreiter1997はこれらの困難さのいくつかを解くためのlong short-term memory (LSTM)ネットワークを導いた。こんにち、LSTMは、Googleでの多くの自然言語処理タスクを含めた、多数のシーケンスモデリングのタスクに広く使われている。
ニューラルネットワーク研究の第二波は1990年代中頃まで続いた。ニューラルネットワークや他のAI技術に基づく投機は投資を求めつつ非現実で野心的な主張に変わり始めた。AI研究がこれらの不当な期待を果たさなかったとき、投資家は失望した。同時に、機械学習のその他の分野は発展を遂げた。kernel machines[@Boser1992; @Cortes1995; @Scholkopf1999]やグラフィカルモデル[@Jordan1998]の両方は多くの重要なタスクで良い成果を出した。これら2つの要因は2007年まで続いたニューラルネットワークの人気の衰退をもたらした。
時を同じくして、ニューラルネットワークはいくつかのタスクで印象的なパフォーマンスを得続けた[@LeCun1998b; @Bengio2001]。Canadian Institute for Advanced Research (CIFAR)はそのNeural Computation and Adaptive Perception (NCAP)研究イニシアティブを介してニューラルネットワーク研究を生きながらえさせるのを援助したこの計画はトロント大学のGeoffrey Hinton、モントリオール大学のYoshua Bengio、ニューヨーク大学のYann LeCunに率いられる機械学習研究グループを結成した。学際的なCIFAR NCAP研究イニシアティブは神経科学者、人間の視覚やコンピュータビジョンの専門家も含まれた。
この時点で、ディープネットワークは訓練するのが非常に難しいと一般に理解されていた。現在の我々は1980年代から存在しているアルゴリズムが非常に有効であることを知っているが、2006年頃は明らかではなかった。この問題はおそらく単純に、これらのアルゴリズムが当時に使えるハードウェアで多くの実験を可能にするには計算コストが高すぎた、といことである。
ニューラルネットワーク研究の第三波は2006年のブレイクスルーを以て始まった。Geoffrey Hintonはdeep belief networkと呼ばれるニューラルネットワークの一種がgreedy layer-wise pretrainingと呼ばれる戦略を用いて効率的に訓練できることを示した[@Hinton2006]。これは、[@sec:15.1]にさらなる詳細を記載している。他のCIFAR関連[CIFAR-affiliated]の研究グループは同様の戦略が多くの他の種類のディープネットワークを訓練するのに使えること[@Bengio2007; @Ranzato2007a]、テスト例の一般化を改良するのに役立つことをまたたく間に示した。このニューラルネットワーク研究の波は、今や研究者が以前に可能であったよりも深いニューラルネットワークを訓練できることを強調し、深さの理論的重要性に注意を向けるために「深層学習」という用語の使用を広めた[@Bengio2007; @Delalleau2011; @Pascanu2014a; @Montufar2014]。このとき、ディープニューラルネットワークは手作業で設計された機能性と同程度の他の機械学習に基づく競合のAIシステムより勝っていた。このニューラルネットワークの人気の第三波は執筆当時まで続いているが、深層学習研究の焦点はこの波のさなかであって目まぐるしく変化してきた。この第三波は新しい教師なし学習技術と小さなデータセットから上手に一般化する深層モデルの能力に焦点を当てて始まったが、こんにちでは、より古い教師あり学習アルゴリズムと大きなラベル付きデータセットを活用する深層モデルの能力により大きな関心が集まっている。

### データセットサイズの増加

中には、＊＊＊と疑問に思う方もいるかもしれない。
