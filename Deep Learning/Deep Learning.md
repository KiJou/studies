---
title: Deep Learning [@Goodfellow2016]
---
# はじめに

発明家たちは考える機械を作り出すことを長らく夢見ていた。この願望は少なくとも古代ギリシアの時代に遡る。神話上の人物[mythical figures]であるPygmalion、Daedalus、Hephaestusはすべて伝説的な発明家と解釈することができ、Galatea、Talos、Pandoraはすべて人工的な生命とみなすことができる。([@Ovid2004; @Sparkes1996; @Tandy1997])
プログラム可能なコンピュータが最初に発想された[conceived]とき、人々はそのような機械が賢くなれるかどうかを、それが作られる以前に100年以上に渡って、知りたいと思っていた。こんにち、人工知能(AI)は多くの実用的なアプリケーションや活発な研究テーマ[research topics]がある盛んな分野[thriving field]である。我々は手順の決まった作業[routine labor]を自動化したり、音声や画像を理解したり、診断を行ったり[make diagnoses in medicine]、基礎科学研究を補助したりする知的なソフトウェアに目を向けている。
人工知能分野の初期の頃は、人間の頭では難しい[intelectually difficult for human beings]がコンピュータには比較的簡単[relatively straightforward]である問題、すなわち、形式的で数学的な規則のリストによって説明できる問題に急速に取り組んで解決していた。後に、人工知能の真の課題は、人々が行うには容易だが形式的に説明するのが難しい作業、すなわち、話された言葉や画像中の顔を認識するような、意識せず、直観的に解いている問題を解決することであると分かった。
本書はこれらのより直観的な問題への解法について書かれている。この解法はコンピュータが経験から学び、より単純な概念との関係を通して定義される個々の概念による概念の階層の観点から世界を理解することを可能にする。経験から知識を収集することで、このアプローチはコンピュータが必要とするすべての知識を形式的に指定する人間のオペレータを必要としない。概念の階層はより単純なものからそれらを構築することでコンピュータが複雑な概念を学習することを可能にする。これらの概念がどのように積み重なって構築されるかを示すために図を描くとすると、その図は深い[deep]、すなわち、多くの層を持っている。この理由により、我々はこのアプローチをAIの深層学習[deep learning]と呼んでいる。
AIの初期の成果の多くは比較的に邪魔の無い[sterile]で形式的な環境で行われ、コンピュータはその世界に関する多くの知識を持つ必要がなかった。例えば、IBMのDeep Blueというチェスシステムは1997年に世界チャンピオンのGarry Kasparovを破った[@Hsu2002]。チェスは、勿論、64個のマスと厳密に決められた方法のみに移動できる32個のコマだけで構成される非常に単純な世界である。出来の良いチェスの戦略を考案することは途方もない成果であるが、その課題は一連のチェスのコマや可能な移動をコンピュータに説明することの難しさによるものではない。チェスは完全に形式的な規則の非常に簡単なリストによって完璧に説明できる。これはプログラマによって前もって容易に提供される。
皮肉なことに、人間にとって中でも最も難しい精神的な仕事である抽象的で形式的な作業はコンピュータにとって中でも最も簡単である。コンピュータは最強の人間のチェスプレイヤーさえも破ることが長らく可能であったが、物体や言葉を認識する平均的な人間の能力の一部に匹敵するように最近なったばかりである。人間の日々の生活は膨大な量の世界に関する知識を必要とする。この知識の大半は主観的かつ直観的であり、それゆえに、形式的な方法で明確に表現する[articulate]は難しい。コンピュータは知的な方法で振る舞うためにこれと同じ知識を捕捉する必要がある。人工知能における重要な課題のひとつはこの形式的でない知識をコンピュータにどのようにして与えるかということである。
いくつかの人工知能プロジェクトは形式言語で世界に関する知識をハードコードすることを目指していた。コンピュータは論理的な推論規則を用いてこれらの形式言語における命題[statement]に関して自動的に理由付けを行うことができる。これは人工知能の知識ベースのアプローチとして知られる。これらのプロジェクトは大きな成果には結びつかなかった。このようなプロジェクトの最も有名なもののひとつとしてCycがある[@Lenat1989]。CycはCycLと呼ばれる言語における推論エンジンおよび命題データベースである。これらの命題は人間の教師[supervisor]のひとりによって入力される。これはやっかいな[unwieldy]プロセスである。人々は世界を正確に記述するために十分な複雑さを持つ形式的な規則を考案しようと取り組む。例えば、Cycは朝に髭を剃るFredという名の人間についての話を理解できなかった[@Linde1992]。この推論エンジンは話の矛盾を検出した。つまり、人が電気的な部分を持たないことを知っているが、Fredが電気カミソリを持っていたので、"髭剃り中のFred"というエンティティが電気的な部分から構成されると理解した。そのため、Fredが髭剃り中でもヒトであるかと訪ねたのだった。
ハードコードされた知識に依存するシステムによって直面する困難はAIシステムが、生データからパターンを抽出することで、自らの知識を獲得する能力を必要としていることを示唆している。この能力は機械学習として知られる。機械学習の事始めはコンピュータが現実世界の知識を伴う問題に取り組み、主観的なように見える決定を下すことを可能にすることであった。ロジスティック回帰[logistic regression]とよばれる単純な機械学習アルゴリズムは帝王切開分娩[cesarean delivery]を推奨するかどうかを決定できる[@Mor-Yosef1990]。naive Bayesと呼ばれる単純な機械学習アルゴリズムは正当なメールとスパムメールを分けることができる。
これらの単純な機械学習アルゴリズムのパフォーマンスはそれらに与えられるデータの表現[representation]に強く依存する。例えば、ロジスティック回帰が帝王切開分娩を勧めるのに使われるとき、AIシステムは患者を直接検査しない。代わりに、医師が、子宮瘢痕[uterine scar]の有無といった、関連情報の一部をシステムに伝える。患者の表現に含まれる情報の各部分は特徴[feature]として知られる。ロジスティック回帰はこれらの患者の特徴のそれぞれが様々な結果とどれだけ関連しているかを学習する。しかし、特徴がどのように定義されているかにはまったくもって影響を与えることはない。ロジスティック回帰に、形式化された医師の報告ではなく、患者のMRIを与えた場合、有用な予測をさせることはできないだろう。MRI画像の個々のピクセルは分娩中に発生するかもしれないいずれかの合併症と僅かな相関を持っている。この表現への依存性はコンピュータ・サイエンスや日常生活にさえも至るところに現れる一般的な現象である。コンピュータサイエンスでは、データの集合を検索するような操作は、集合が上手に[intelligently]構造化され、インデックス化されると、指数関数的に速く進む。人々はアラビア数字で計算をすることは容易に可能だが、ローマ数字で計算を見出すにはさらにもっと多くの時間がかかる。表現の選択が機械学習アルゴリズムのパフォーマンスに多大な影響をもたらすことは驚くことではない。単純な視覚的な例として、[@fig:1.1]を参考にすること。
多くの人工知能タスクは

![異なる表現の例](fig/1-1.png){#fig:1.1}
