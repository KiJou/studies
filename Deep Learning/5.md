# 機械学習の基礎

深層学習は機械学習の特定の種類である。深層学習を良く理解するためには、機械学習の基本原則をしっかりと理解しなければならない。この章は以降の本書全体を通して適用される最重要の一般的な原則についての簡潔な授業を提供する。新参の読者や視野を広くしたい方は、[@Murphy2012]や[@Bishop2006]のような、基礎部分をより包括的にカバーする機械学習のテキストを検討することをオススメする。あなたがすでに機械学習の基礎に親しんでいるならば、[@sec:5.11]まで飛ばしてもらって構わない。この節は深層学習アルゴリズムの発展に強く影響を与えてきた伝統的な機械学習技術に対するいくつかの視点をカバーする。

学習アルゴリズムとは何かを定義するところから始めて、線形回帰アルゴリズムを使って一例を示そう。そこで次に、訓練データを一致させる課題が新しいデータに一般化するパターンを見つける課題とどれだけ異なるかを記述することにする。ほとんどの機械学習アルゴリズムはハイパーパラメータ[hyperparameters]と呼ばれる設定を持つ。これは、学習アルゴリズム自体の外で決定されなければならない。つまり、我々は追加データを用いてこれらを設定する方法を議論する。機械学習は実質的に、複雑な関数を統計的に推定するためにコンピュータを使用することを重んじ、これらの関数の周りの信頼区間を証明することを軽んじる、応用的な統計学の一形式である。従って、我々は、頻度論的推定量[frequentist estimators]とベイズ推定[Bayesian inference]という、2つの統計学への中心的アプローチを示す。ほとんどの機械学習アルゴリズムは、教師あり学習と教師なし学習のカテゴリに分けられる。そこで、我々はこれらのカテゴリを説明し、各カテゴリに由来するいくつかの単純な学習アルゴリズムの例を与える。ほとんどの深層学習アルゴリズムは確率的勾配降下法とよばれる最適化アルゴリズムに基づいている。我々は、機械学習アルゴリズムを作るために、最適化アルゴリズム、コスト関数、モデル、データセットといった、様々なアルゴリズムの構成要素を組み合わせる方法を述べる。最後に、[@sec:5.11]では、一般化するために伝統的な機械学習の能力を制限していた要因のいくつかを述べる。これらの課題は、これらの障害を克服する深層学習アルゴリズムの開発を動機付けてきた。

## 学習アルゴリズム

機械学習アルゴリズムとはデータから学習することができるアルゴリズムである。しかし、学習とは何を意味するのだろうか？ @Mitchell1997 は、「ある種別のタスク$T$およびパフォーマンス尺度$P$に関する経験$E$によって、$T$におけるタスクでの、$P$によって測定されるパフォーマンスが改善する場合、コンピュータプログラムは$E$から学習すると言う。」という、簡潔な定義を与えている。経験$E$、タスク$T$、パフォーマンス尺度$P$は多種多様なものが想像できるが、我々は本書においてこれらのエンティティのそれぞれに使われるかもしれないものを形式的に定義しようとしたりはしない。代わりに、次節にて、直観的な説明と機械学習アルゴリズムを構築するのに使える様々な種類のタスク、パフォーマンス尺度、経験の例を提供する。

### タスク$T$

機械学習は人間が記述および設計した固定のプログラムで解くには難しすぎるタスクに対処することが可能となる。科学的および哲学的視点から見ると、その理解を深めることは知性の基となる原則の理解を深めることを必然的に伴うので、機械学習は興味深い。
この「タスク」という語の比較的に形式的な定義において、学習の工程それ自体はタスクではない。学習はタスクを処理するための能力を獲得する方法である。例えば、ロボットを歩けるようにしたい場合、歩くことはタスクである。我々は、歩き方を学習するようにロボットをプログラミングしたり、手動で歩き方を指定するプログラムを直接書いてみようとしたりすることができる。
機械学習のタスクは通常、機械学習システムがどのようなexampleを処理すべきかに関して記述される。exampleは機械学習システムに処理させたい物体または事象から定量的に計測された特徴[features]の集合である。我々は一般にexampleを各成分$x_i$が別の特徴であるようなベクトル$\boldsymbol{x} \in \mathbb{R}^n$と表現する。例えば、画像の特徴は通常、その画像の中のピクセルの値である。
多くの種類のタスクは機械学習によって解くことができる。最も一般的な機械学習タスクのいくつかには以下が含まれる。

- 分類[classification]：この種のタスクでは、コンピュータプログラムはある入力が$k$個のカテゴリのいずれに属すかを特定することを求められる。このタスクを解くために、学習アルゴリズムは通常、関数$f : \mathbb{R}^n \rightarrow {1, \dots, k}$を生み出すことを求められる。$y = f(\boldsymbol{x})$であるとき、モデルはベクトル$\boldsymbol{x}$で記述される入力を数値コード$y$で識別されるカテゴリに割り当てる。他にも、例えば、$f$が種別の確率分布を出力するような、様々な分類法が存在する。分類タスクの一例として、物体認識がある。これは、（通常ではピクセルの明るさの値の集合として記述される）画像を入力とし、画像中の物体を識別する数値コードを出力とする。例えば、Willow GarageのPR2というロボットは異なる種類の飲み物を認識し、命令によって人々に届けることができるウェイターととして振る舞うことができる[@Goodfellow2010]。近年の物体認識は深層学習によるものが最も洗練されている[@Krizhevsky2012; @Ioffe2015]。物体認識はコンピュータが顔を認識することを可能にする技術[@Taigman2014]と基本は同じである。これは、写真アルバムの中の人たちを自動的にタグ付けしたり、コンピュータがユーザとより自然に対話したりするために使うことができる。
- 欠けている入力を伴う分類[classification with missing inputs]：コンピュータ・プログラムがその入力ベクトルにすべての測定値を常に与えることを保証しない場合、分類はより挑戦的になる。分類タスクを解くために、学習アルゴリズムはベクトルの入力からカテゴリの出力へマッピングする単一の関数を定義しなければならない。入力のいくつかが欠けているとき、学習アルゴリズムは、単一の分類関数を与えるのではなく、関数の集合を学習しなければならない。各関数はその欠けている入力の異なる部分集合を持つ$\boldsymbol{x}$を分類することに対応する。この種の状況は医療診断において、多くの種の医療検査は高価であり侵襲的[invasive]であるので、頻繁に発生する。そのような関数の大きな集合を効率的に定義する方法のひとつはすべての関連する変数上の確率分布を学習し、欠けている変数を周辺化すること[marginalizing out]で分類タスクを解くことである。$n$個の入力変数では、欠けている入力の取り得る集合ごとに必要となる$2^n$個の異なる分類関数すべてを得られるが、コンピュータプログラムは同時確率分布を記述する単一の関数のみを学習する必要がある。この方法でそのようなタスクに適用される深層確率モデルの例は[@Goodfellow2013b]を参照のこと。この節で述べられるその他のタスクの多くは欠けている入力とともに機能するように一般化することもできる。つまり、欠けている入力を伴う分類は機械学習ができることの単なる一例である。
- 認識[regression]：この種類のタスクでは、コンピュータプログラムはある入力が与えられた場合に数値を予測することを求められる。このタスクを解くために、学習アルゴリズムは関数$f : \mathbb{R}^n \rightarrow \mathbb{R}$を出力することを求められる。この種類のタスクは、出力の形式が異なることを除いて、分類と似ている。認識タスクの例は、被保険者になされるであろう保険金支払額の期待値[expected claim amount]の予測（保険料[insurance premiums]を設定するために使われる）、または、有価証券[securities]の将来的な価格の予測である。
- 文字起こし[transcription]：この種類のタスクでは、機械学習システムはある種のデータの比較的に非構造的な表現を調べて、離散的な文章形式に情報を書き起こすことを求められる。例えば、光学的な文字認識では、コンピュータプログラムは文章の画像を含む写真を見せられ、文字列の形式（例えば、ASCIIかUnicode形式）でこの文章を返すことを求められる。Googleストリートビューはこの方法で郵便番号を処理するために深層学習を用いている[@Goodfellow2014d]。もうひとつの例は音声認識[speech recognition]である。そこでは、コンピュータプログラムは音声波形を与えられ、録音の中で話された言葉を記述する文字列か単語IDを吐き出す。深層学習は、Microsoft、IBM、Googleを含む主要な企業で用いられる近代的な音声認識システムの極めて重要な要素である[@Hinton2012b]。
- 機械翻訳[machine translation]：機械翻訳タスクでは、入力はある言語における記号の列から予め構成され、コンピュータプログラムはこれを別の言語における記号の列に変換しなければならない。これは一般的に、英語からフランス語への翻訳のように、自然言語へ応用される。深層学習は最近になってこの種のタスクに重要な影響をもたらし始めている[@Sutskever2014; @Bahdanau2015]。
- 構造化された出力[structured output]：構造化された出力のタスクは出力が異なる要素間の重要な関係を持つベクトル（または、複数の値から成る他のデータ構造）である任意のタスクである。これは広範囲のカテゴリであり、他の多くのタスクと同様に、上記で述べられる書き起こしや翻訳のタスクを包含する[subsume]。一例として、構文解析[parsing]がある。これは、動詞、名詞、副詞などとして木の節をタグ付けすることでその文法構造を記述する木に自然言語の文をマッピングすることである。構文解析タスクに適用される深層学習の例は[@Collobert2011]を参照のこと。もうひとつの例は画像のピクセル単位の領域分割である。ここでは、コンピュータプログラムは画像中のすべてのピクセルに特定のカテゴリを割り当てる。例えば、深層学習は空撮写真で道路の位置に注釈を付けるのに使うことができる[@Mnih2010]。出力形式はこれらの注釈スタイルのタスクと同じくらいに入力の構造を鏡写しにする必要はない。例えば、画像の表題付け[image captioning]では、コンピュータプログラムは画像を調べ、画像を説明する自然言語の文を出力する[@Kiros2014a; @Kiros2014b; @Mao2015; @Vinyals2015b; @Donahue2014; @Karpathy2015; @Fang2015; @Xu2015]。これらのタスクは、プログラムがすべてで強固な相互関連を持ついくつかの値を出力しなければならないので、構造化出力タスク[structured output tasks]と呼ばれる。例えば、image captioningプログラムで生成される単語は正しい文を形作らなければならない。
- 異常検知[anomaly detection]：この種のタスクでは、コンピュータプログラムは事象または物体の集合を選別し、普通ではない[unusual]または非定型[atypical]であるとしてこれらの一部をフラグを立てる。異常検知タスクの例はクレジットカード詐欺[fraud]の検知である。買い物の習慣をモデル化することで、クレジットカード会社はカードの不正使用を検知できる。泥棒があなたのクレジットカードやクレジットカード情報を盗む場合、泥棒の買い物はしばしばあなた自身とは異なる購買タイプ上の確率分布を生じさせることがあるだろう。クレジットカード会社は、そのカードが特徴的ではない買い物に使われたらすぐに取引を一時停止することで詐欺を防ぐことができる。異常検知の手法の調査については[@Chandola2009]を参照のこと。
- 合成と標本化[synthesis and sampling]：この種のタスクでは、機械学習アルゴリズムは訓練データにあるものと似ている新しいexamplesを生成することを求められる。機械学習を介する合成および標本化は、大量のコンテンツを手作業で作るのが高価だったり、退屈だったり、時間がかかりすぎたりするであろうときのメディアアプリケーションに対して役立つ可能性がある。例えば、ビデオゲームは大きな物体や地形に対するテクスチャを、アーティストに各ピクセルを手作業でラベル付けしてもらうのではなく、自動的に生成できる[@Luo2013]。いくつかの場合、我々は標本化や合成のプロシージャが入力を与えられたときに特定の種類の出力を生成してほしいと考える。例えば、音声生成タスクでは、文字の形の文[written sentence]を与え、プログラムにその文の声のバージョン[spoken version]を含む音声波形を吐くよう求める。これは構造化出力タスクの一種であるが、各入力に対するたった1つの正解の出力が存在しないような定量化が追加されている。そして、我々は、出力がより自然で現実味を帯びているように見せるために、出力において大量のバラツキを明示的に望む。
- 欠落値の補完[imputation of missing values]：この種のタスクでは、機械学習アルゴリズムは新しいexample$\boldsymbol{x} \in \mathbb{R}^n$を与えられるが、$\boldsymbol{x}$のいくつかの成分$x_i$が欠落している。アルゴリズムは欠けている成分の値の推定をもたらす必要がある。
- ノイズ除去[denoising]：この種のタスクでは、機械学習アルゴリズムは不明の破損プロセスによってキレイなexample$\boldsymbol{x} \in \mathbb{R}^n$から破損したexample$\boldsymbol{x}^\tilde \in \mathbb{R}^n$を入力として与えられる。学習者はキレイなexample$\boldsymbol{x}$をその破損したバージョン$\boldsymbol{x}^\tilde$から予測する、または、より一般的には条件付き確率分布$p(\boldsymbol{x} | \boldsymbol{x}^\tilde)$を予測する必要がある。
- 密度推定[density estimation]または確率質量関数の推定[probability mass function estimation]：密度推定問題では、機械学習アルゴリズムは関数$p_{model} : \mathbb{R}^n \rightarrow \mathbb{R}$を学習することを求められる。ここで、$p_{model}(\boldsymbol{x})$はexamplesが描かれる空間上の確率密度関数（$\boldsymbol{\mathbf{x}}$が連続的である場合）または確率質量関数（$\boldsymbol{\mathbf{x}}$が離散的である場合）として解釈できる。そのようなタスクをうまくこなすために（パフォーマンス尺度$P$を述べるときにそれが意味するものを厳密に示そうと思う）、アルゴリズムはそこに示されるデータの構造を学習する必要がある。examplesが密集している所や発生する可能性が低い所を知っていなければならない。前述されたほとんどのタスクは学習アルゴリズムが少なくとも確率分布の構造を暗黙のうちにキャプチャする必要がある。密度推定はその分布を明示的にキャプチャすることを可能にする。原則として、我々は同様に他のタスクを解くためにその分布上の計算を行うことができる。例えば、確率分布$p(\boldsymbol{x})$を得るために確率推定を行ったとすれば、欠落値補完タスクを解くためにその分布を用いることができる。値$x_i$が欠けていて、$\mathbb{x}_{-i}$で表記されるその他すべての値が与えられている場合、それ上の分布が$p(x_i | \boldsymbol{x}_{-i})$によって与えられることを知っている。実践では、多くの場合で$p(\boldsymbol{x})$で必要な処理が計算上扱いづらいので、密度推定はこれらすべての関連するタスクを解くことを常に可能としない。

もちろん、多くのその他のタスクやタスクの種類が取り得る。我々がここに並べたタスクの種類は、タスクの厳密な分類体系を定義するためではなく、機械学習ができることの例を提供するためのみを意図している。

### パフォーマンス尺度$P$

機械学習アルゴリズムの能力を評価するため、我々はそのパフォーマンスの定量的な尺度を設計しなければならない。通常、このパフォーマンス尺度$P$はシステムによってもたらされるタスク$T$に特有なものである。
分類、欠けている入力を伴う分類、文字起こしのようなタスクに対しては、しばしばモデルの正確さ[accuracy]を計測する。正確さはモデルが正しい出力を生み出しているexamplesの単なる割合である。モデルが正しくない出力を生み出しているexamplesの割合である誤り率[error rate]を計測することで同等の情報も得られる。我々はしばしば誤り率を0-1 lossの期待値として参照する。特定のexampleでの0-1 lossは正しく分類されれば$0$となり、そうでなければ$1$となる。密度推定のようなタスクでは、正確さ、誤り率、その他いずれの種類の0-1 lossを測定することも意味をなさない。代わりに、exampleごとに連続値のスコアをモデルに与える別のパフォーマンスの測定基準を用いなければならない。最も一般的なアプローチは、モデルがいくつかの
examplesに割り当てる平均多数確率を報告することである。
通常、それが現実世界に展開させたときにどれだけうまく機能するだろうかを決定するので、我々は機械学習アルゴリズムがそれまでに見たことのないデータをどれだけうまく処理するかについて興味がある。故に、我々は機械学習システムを訓練するために使われるデータとは別のテスト用データセット[test set of data]を用いてこれらのパフォーマンス尺度を評価する。
パフォーマンス尺度の選択は率直で客観的であるように見えるかもしれないが、システムの望ましい振る舞いにうまく対応するパフォーマンス尺度を選ぶことはしばしば難しい。
いくつかの場合、これは計測すべきものを決めることが難しいためである。例えば、文字起こしタスクを処理するとき、文字列全体を書き起こすという点でシステムの正確さを計測すべきだろうか、または、いくつかの文字列の要素が正解しているときに部分点を与えるようなよりきめ細かいパフォーマンス尺度を用いるべきだろうか？認識タスクを処理するとき、頻繁に中くらいのミスをする場合、または、まれに非常に大きなミスをする場合であれば、システムをより減点すべきだろうか？これらの種類の設計上の選択はアプリケーションに依存する。
その他の場合、我々は理想的には計測したい量を知っているが、それを測定することは実用的ではない。例えば、これは密度推定の文脈において頻繁に発生する。最適な確率モデルの多くは暗黙的にのみ確率分布を表現する。多くのそのようなモデルでは空間の特定の点に割り当てられる実際の確率の値を計算することは解決困難である。これらの場合、設計目的に依然として対応する代替基準を設計するか、望ましい基準に対する良好な近似を設計するか、をしなければならない。

### 経験$E$

機械学習アルゴリズムは、学習プロセス中に持ち得る経験の種類によって、教師なし[unsupervised]と教師あり[supervised]に大別することができる。
本書における学習アルゴリズムのほとんどはデータセット[dataset]全体を経験することができると理解できる。データセットは、[@sec:5.1.1]で定義されるように、多数のexamplesの集合である。時折、我々はexamplesをデータポイント[data points]と呼ぶ。
統計学者や機械学習の研究者によって研究される最古のデータセットひとつはIris datasetである[@Fisher1936]。これは150本のアヤメ属の花の様々な部分の計測値の集合である。それぞれの個々の花は1つのexampleに対応する。各exampleにある特徴は花の各部分の計測値である。つまり、萼片[sepal]の長さ、萼片の幅、花弁[petal]の長さ、花弁の幅である。そのデータセットはそれぞれの花がどの種に属しているかも記録している。そのデータセットには3つの異なる種が示されている。
教師なし学習アルゴリズム[unsupervised learning algorithms]は多数の特徴を含むデータセットを経験し、このデータセットの構造の有用な特性を学習する。深層学習の文脈において、我々は通常、密度推定にあるように明示的に、または、合成やノイズ除去のようなタスクのように暗黙的に、データセットを生成する確率分布全体を学習したい。いくつかのその他の教師なし学習アルゴリズムは、似たexamplesのクラスタにデータセットを分けることから成るクラスタリングのような、他の役割をこなす。
教師あり学習アルゴリズム[supervised learning algorithms]は特徴を含むデータセットを経験するが、各exampleはラベル[label]または対象[target]に関連付けられてもいる。例えば、Iris datasetはそれぞれのアヤメの花の種類で注釈が付けられている。教師あり学習アルゴリズムはIris datasetを学んだり、これらの計測値に基づいてアヤメの花を3つの異なる種類に分類することを学習したりすることができる。
大雑把に言えば、教師なし学習は無作為なベクトル$\boldsymbol{\mathbf{x}}$のいくつかのexamplesを観察し、確率分布$p(\boldsymbol{\mathbf{x}})$、または、その分布のいくつかの興味深い特性を暗黙的または明示的に学習しようと試みることを伴う。一方で、教師あり学習は無作為なベクトル$\boldsymbol{\mathbf{x}}$や関連する値またはベクトル$\boldsymbol{\mathbf{y}}$のいくつかのexamplesを観察し、$\boldsymbol{\mathbf{x}}$から$\boldsymbol{\mathbf{y}}$を、通常では$p(\boldsymbol{\mathbf{y}} | \boldsymbol{\mathbf{x}})$を推定することによって、予測することを学習することを伴う。教師あり学習という用語は機械学習システムにすべきことを示す講師や教師によってもたらされる対象$\boldsymbol{\mathbf{y}}$の視点に由来する。教師なし学習では、講師や教師がおらず、アルゴリズムはこの導きなしにデータを理解するために学習しなければならない。
教師なし学習と教師あり学習は公式に定義された用語ではない。これらの線引きはしばしば曖昧である。多くの機械学習技術は両方のタスクを処理するために使うことができる。例えば、確率の連鎖律は、ベクトル$\boldsymbol{\mathbf{x}} \in \mathbb{R}^n$に対して、同時分布が以下のように分解できることを示している。

$$
p(\boldsymbol{\mathbf{x}}) = \prod_{i = 1}^n p(\mathbf{x}_i | \mathbf{x}_1, \dots, \mathbf{x}_{i-1})
$$

この分解は、モデル化$p(\boldsymbol{\mathbf{x}})$の表面上は教師なしである問題を$n$個の教師あり学習の問題に分けることで解くことができることを意味する。あるいは、学習$p(y | \boldsymbol{\mathbf{x}})$の教師あり学習の問題を同時分布$p(\boldsymbol{\mathbf{x}}, y)$を学習するための伝統的な教師なし学習技術を用いて以下を推論することで解くことができる。

$$
p(y | \boldsymbol{\mathbf{x}}) = \frac{p(\boldsymbol{\mathbf{x}}, y)}{\sum_{y'} p(\boldsymbol{\mathbf{x}}, y')}
$$

教師なし学習と教師あり学習は完全に形式的で明確な概念ではないにも関わらず、これらは機械学習アルゴリズムで行うことのいくつかをおおまかに分類するのに役立っている。慣例として、人々は認識、分類、構造化出力の問題を教師あり学習と呼ぶ。他のタスクの裏付けとしての密度推定は通常、教師なし学習とみなされる。
他の種類の学習パラダイムが取り得る。例えば、半教師あり学習では、いくつかのexamplesはsupervision targetを含むが、それ以外は含まない。multi-instance学習では、examplesの集合全体はある種別のexampleを含むかどうかでラベル付けされるが、集合の個々のメンバーはラベル付けされない。深層モデルを伴うmulti-instance学習の最近の例は[@Kotzias2015]を参照のこと。
いくつかの機械学習アルゴリズムは単に固定のデータセットを経験するだけではない。例えば、強化学習[reinforcement learning]アルゴリズムは環境と相互作用する。つまり、学習アルゴリズムとその経験の間にフィードバックループが存在する。そのようなアルゴリズムは本書の範疇を超える。強化学習に関する情報は@Sutton1998か@Bertsekas1996を、強化学習への深層学習のアプローチは@Mnih2013を参照ください。
ほとんどの機械学習アルゴリズムは単純にデータセットを経験する。データセットはいろんな方法で記述できる。すべての場合で、データセットはexamplesの集合である。これは、特徴の集合でもある。
データセットを記述する一般的な方法のひとつは計画行列[design matrix]である。計画行列は各行に異なるexampleを含む行列である。その行列の各列は異なる特徴に対応する。例えば、Iris datasetはexampleごとに4つの特徴を持つ150個のexamplesから成る。これは、計画行列$\boldsymbol{X} \in \mathbb{R}^{150 \times 4}$によってそのデータセットを表現できることを意味する。ここで、$X_{i,1}$は花$i$の萼片の長さであり、$X_{i,2}$は花$i$の萼片の幅であり、以降も同様である。我々は計画行列のデータセットをどのように処理するかという観点で本書における学習アルゴリズムのほとんどを説明する。
もちろん、データセットを計画行列として述べるために、各exampleをベクトルとして説明することが可能でなければならず、これらのベクトルのそれぞれは同じ大きさでなければならない。これは常にできるとは限らない。例えば、様々な幅や高さを持つ写真の集合がある場合、異なる写真は異なるピクセル数を含むだろう。なので、同じベクトル長で記述できるであろう写真はそのすべてではない。[@sec:9.7]や[@sec:10]では、このような不均質なデータの様々な種類を扱う方法を述べる。これらのような場合では、$m$行の行列としてデータセットを記述するのではなく、$m$個の要素を含む集合${\boldsymbol{x}^{(1)}, \boldsymbol{x}^{(2)}, \dots, \boldsymbol{x}^{(m)}}$として記述する。この表記法は任意の2つのexampleベクトル$\boldsymbol{x}^{(i)}$と$\boldsymbol{x}^{(j)}$が同じ大きさを持つことを暗に示さない。
教師あり学習の場合、そのexampleは特徴の集合と同様にラベルまたは対象を含んでいる。例えば、写真からの物体認識を行うために学習アルゴリズムを用いたい場合、写真のそれぞれに写っているものを指定する必要がある。我々はこれを、人間を0で示し、車を1で示し、猫を2で示し、といったような数値コードで行うかもしれない。しばしば、特徴の観測結果$\boldsymbol{X}$の計画行列を含むデータセットで行うとき、example$i$に対するラベルをもたらす$y_i$を持つラベルのベクトル$\boldsymbol{y}$ももたらす。
もちろん、時折、ラベルは単一の値以上のものになり得るだろう。例えば、文全体を書き起こすために音声認識システムを訓練したい場合、各exampleの文に対するラベルは単語の列である。
教師あり学習と教師なし学習の正式な定義が存在しないのと同様に、データセットや経験の厳密な分類法は存在しない。ここで述べられる構造はほとんどの場合をカバーするが、新しいアプリケーションには新しいものを設計することが常に可能である。

### 例：線形回帰

経験を通してあるタスクでのコンピュータプログラムのパフォーマンスを改善することができるアルゴリズムとしての機械学習アルゴリズムの定義は幾分か抽象的である。これをより具体的にするため、我々は単純な機械学習アルゴリズムの例を示す。すなわち、線形回帰[linear regression]である。我々は、アルゴリズムの挙動を理解するのに役立つ機械学習のさらなる概念を導入するたびに、この例にたびたび立ち戻るだろう。
名前が暗示する通り、線形回帰は回帰問題を解く。言い換えれば、その目標はベクトル$\boldsymbol{x} \in \mathbb{R}^n$を入力として取り、出力としてスカラ$y \in \mathbb{R}$の値を予測することができるシステムを作ることである。線形回帰の出力は入力の一次関数である。求めるべき$y$を我々のモデルが予測した値を$\hat{y}$とする。我々はその出力を以下と定義する。

$$
\hat{y} = \boldsymbol{w}^\tap \boldsymbol{x}
$$

ここで、$\boldsymbol{w} \in \mathbb{R}^n$はパラメータ[parameters]のベクトルである。
パラメータはシステムの振る舞いを制御する値である。この場合、$w_i$はすべての特徴からの寄与の総和を取る前に特徴$x_i$で乗算する係数である。我々は$\boldsymbol{w}$を各特徴が予測にどれだけの影響を与えるかを決定する重み[weights]の集合とみなすことができる。$x_i$が正の重み$w_i$を受ける場合、その特徴の値が増加すると予測値$\hat{y}$の値は増加する。特徴が負の重みを受ける場合、その特徴の値が増加すると予測値の値は減少する。特徴の重みが絶対値で大きい場合、予測値において大きな影響をもたらす。特徴の重みがゼロであるならば、予測値に影響をもたらさない。
従って、我々はタスク$T$の定義を、$\hat{y} = \boldsymbol{w}^\top \boldsymbol{x}$を出力することで$\boldsymbol{x}$から$y$を予測すること、とする。次に、我々はパフォーマンス尺度$P$の定義を必要とする。
訓練には使わずにモデルがどれだけうまく処理するかを評価するためだけに使うような、$m$個のexampleの入力の計画行列があるとする。これらのexamplesのそれぞれに対して$y$の正しい値をもたらす回帰対象のベクトルもある。このデータセットは評価に使われるだけなので、我々はこれをテストセットと呼ぶ。我々は入力の計画行列を$\boldsymbol{X}^{(test)}$と表し、回帰対象のベクトルを$\boldsymbol{y}^{(test)}$と表す。
モデルのパフォーマンスを測定する方法のひとつはテストセットでのモデルの平均二乗誤差[mean squared error]を計算することである。$\boldsymbol{y}^{(test)}$がテストセットでのモデルの予測値をもたらすならば、平均二乗誤差は以下によって求められる。

$$
\text{MSE}_{test} = \frac{1}{m} \sum_i (\boldsymbol{\hat{y}}^{(test)} - \boldsymbol{y}^{(test)})_i^2
$$

直観として、この誤差の尺度が$\boldsymbol{\hat{y}}^{(test)} = \boldsymbol{y}^{(test)}$のときに$0$に減少することを理解できる。我々は以下であることも確認できる。

$$
\text{MSE}_{test} = \frac{1}{m} \| \boldsymbol{\hat{y}}^{(test)} - \boldsymbol{y}^{(test)} \|_2^2
$$

つまり、その誤差は予測値と対象の間のユークリッド距離が増加するたびに増加する。
機械学習アルゴリズムを作るために、我々は、アルゴリズムが訓練セット$(\boldsymbol{X}^{train}, \boldsymbol{y}^{train})$を観察することによって経験を得る事ができるときに$\text{MSE}_{test}$を減少させる方法で重み$\boldsymbol{w}$を改善するであろうアルゴリズムを設計する必要がある。これを行う直観的な方法のひとつ（これについては後に[@sec:5.5.1]でその根拠を示す）は訓練セットでの平均二乗誤差$\text{MSE}_{train}$を最小化することである。
$\text{MSE}_{train}$を最小化するために、その勾配が$\boldsymbol{0}$となる所で解くことができる。

$$
\nabla_{\boldsymbol{w}} \text{MSE}_{train} = 0
$$

$$
\Rightarrow \nabla_{\boldsymbol{w}} \frac{1}{m} \| \boldsymbol{\hat{y}}^{(train)} - \boldsymbol{y}^{(train)} \|_2^2 = 0
$$

$$
\Rightarrow \frac{1}{m} \nabla_{\boldsymbol{w}} \| \boldsymbol{X}^{(train)} \boldsymbol{w} - \boldsymbol{y}^{(train)} \|_2^2 = 0
$$

$$
\Rightarrow \nabla_{\boldsymbol{w}} (\boldsymbol{X}^{(train)} \boldsymbol{w} - \boldsymbol{y}^{(train)})^\top (\boldsymbol{X}^{(train)} \boldsymbol{w} - \boldsymbol{y}^{(train)}) = 0
$$

$$
\Rightarrow \nabla_{\boldsymbol{w}} ( \boldsymbol{w}^\top \boldsymbol{X}^{(train) \top} \boldsymbol{X}^{(train)} \boldsymbol{w} - 2 \boldsymbol{w}^\top \boldsymbol{X}^{(train) \top} \boldsymbol{y}^{(train)} + \boldsymbol{y}^{(train) \top} \boldsymbol{y}^{(train)}) = 0
$$

$$
\Rightarrow 2 \boldsymbol{X}^{(train) \top} \boldsymbol{X}^{(train)} \boldsymbol{w} - 2 \boldsymbol{X}^{(train) \top} \boldsymbol{y}^{(train)} = 0
$$

$$
\Rightarrow \boldsymbol{w} = (\boldsymbol{X}^{(train) \top} \boldsymbol{X}^{(train)})^{-1} \boldsymbol{X}^{(train) \top} \boldsymbol{y}^{(train)}
$$

その解が[@eq:5.12]によって求められる連立方程式は正規方程式[normal equations]として知られる。[@eq:5.12]を計算することは単純な学習アルゴリズムを構成する。線形回帰の学習アルゴリズムの動きの例は[@fig:5.1]を参照のこと。

![各点が1つの特徴を含む10個のデータポイントから成る訓練セットを持つ線形回帰問題。ただ1つの特徴のみが存在するので、重みベクトル$\boldsymbol{w}$は学習のための単一のパラメータ$w_1$のみを含む。（左）線形回帰は線$y = w_1$がすべての訓練点をできるだけ通るような$w_1$の設定を学習することを確認する。（右）プロットされた点は正規方程式で求められる$w_1$の値を示す。これは、訓練セットでの平均二乗誤差を最小化することを確認できる。](fig/5-1.png){#fig:5.1}

線形回帰という用語はしばしば、切片項$b$という追加パラメータを持つもう少し洗練されたモデルを指すのに使われる。このモデルでは、以下となる。

$$
\hat{y} = \boldsymbol{w}^\top \boldsymbol{x} + b
$$

すなわち、パラメータから予測値へのマッピングは依然として一次関数であるが、特徴から予測値へのマッピングはアフィン関数となっている。このアフィン関数への拡張は、モデルの予測値のプロットが依然として線のように見えるが、原点を通る必要がないことを意味する。バイアスパラメータ$b$を追加する代わりに、重みのみを持つが、常に$1$にセットされる追加の成分を持つ引数$\boldsymbol{x}$を持つモデルを使う続けることもできる。追加の$1$の成分に対応する重みはバイアスパラメータの役割を担う。我々は、本書を通してアフィン関数を指すときに、頻繁に「線形」という用語を用いる。
切片項$b$はしばしばアフィン変換のバイアス[bias]パラメータと呼ばれる。この用語法は、変換の出力がいずれの入力も存在しないときに$b$となるようバイアスされるという視点から派生する。この用語は、統計的推定アルゴリズムの期待される推定量は真の量に等しくない、という統計的なバイアスのアイデアとは異なる。
もちろん、線形回帰は極めて単純で限定的な学習アルゴリズムであるが、どのようにして学習アルゴリズムがうまく機能することができるかの例をもたらす。次節において、我々は学習アルゴリズム設計の基礎をなす基本原則のいくつかを述べ、それらの原則がどのようにしてより複雑な学習アルゴリズムを作るのに使うことができるかを実証する。

## 容量、過剰適合、過少適合

機械学習における中心的課題は、モデルを訓練したときのものだけでなく、アルゴリズムが新規で未見[new, previously unseen]の入力に対してうまく処理しなければならないということである。以前に観察していない入力でうまく処理する能力は汎化[generalization]と呼ばれる。
一般に、機械学習モデルを訓練するとき、我々は訓練セットへのアクセス権を持つ。すなわち、訓練誤差[training error]と呼ばれる訓練セットでの誤差の尺度を計算することができ、そして、この訓練誤差を減らす。これまでのところで言えば、我々が述べてきたものは単なる最適化問題である。最適化から機械学習を隔てるものは、我々が汎化誤差[generalization error]を欲していることである。これは、テスト誤差[test error]とも呼ばれ、同様に小さくされるべきものである。汎化誤差は新規の入力における誤差の期待値として定義される。ここで、期待値は、システムが実践で遭遇すると期待される入力の分布から描かれる、様々な取り得る入力に渡って取られる。
我々は一般に、訓練セットとは別に集められたテストセットのexamplesでのパフォーマンスを計測することで機械学習モデルの汎化誤差を推定する。
線形回帰の例では、訓練誤差を最小化することでモデルを訓練した。

$$
\frac{1}{m^{(train)}} \| \boldsymbol{X}^{(train)} \boldsymbol{w} - \boldsymbol{y}^{(train)} \|_2^2
$$

しかし、実際に気をつけるべきはテスト誤差$\frac{1}{m^{(test)}} \| \boldsymbol{X}^{(test)} \boldsymbol{w} - \boldsymbol{y}^{(test)} \|_2^2$である。
どうすれば訓練セットのみを観察できるときにテストセットにおけるパフォーマンスに影響を与えることができるか？統計的学習理論[statistical learning theory]の分野がいくつかの答えをもたらしてくれる。訓練セットとテストセットが任意に集められる場合、できることはほとんどない。訓練セットとテストセットの集められ方についてのいくつかの仮定を設けることができれば、いくらか歩みを進めることができる。
訓練データとテストデータはデータ生成過程[data-generating process]と呼ばれるデータセット上の確率分布によって生成される。一般に、まとめて独立同分布仮定[i.i.d. assumptions]として知られる仮定の集合を作る。これらの仮定は、各データセット内のexamplesがお互いに独立[independent]であり、訓練セットとテストセットが、お互いに同じ確率分布で描かれることで、同様に分布している[identically distributed]とする。この仮定は単一のexample上の確率分布でデータ生成過程を記述することを可能にする。我々はこの共有された基礎をなす分布をデータ生成分布[data-generating distribution]と呼び、$p_{data}$と表記する。この確率的フレームワークとi.i.d.仮定は訓練誤差とテスト誤差の間の関係を数学的に研究することを可能にする。
我々が訓練誤差とテスト誤差の間に見出だせる直接のつながりのひとつは無作為に選択するモデルの訓練誤差の期待値がそのモデルのテスト誤差の期待値に等しいことである。確率分布$p(\boldsymbol{x}, y)$を持ち、訓練セットとテストセットを生成するために繰り返しそこからサンプリングを行うとする。両方の期待値は同じデータセットサンプリング過程を用いて形成されるので、ある固定の値$\boldsymbol{w}$に対して、訓練セットの誤差の期待値はテストセットの誤差の期待値とまったく同じである。2つのconditionsはサンプリングを行うデータセットに割り当てる名前が異なるだけである。
もちろん、機械学習アルゴリズムを用いるとき、我々は前もってパラメータを固定せず、両方のデータセットをサンプリングする。訓練セットをサンプリングし、訓練セットの誤差をへらすためにパラメータを選択するのに用い、そして、テストセットをサンプリングする。この過程に基づくと、テスト誤差の期待値は訓練誤差の期待値以上となる。機械学習アルゴリズムがどれだけうまく処理するかを決定する要因は以下を行う能力である。

1. 訓練誤差を小さくする
2. 訓練誤差とテスト誤差のギャップを小さくする

これらの2つの要因は機械学習における2つの中心的な課題に対応する。すなわち、過少適合[underfitting]と過剰適合[overfitting]である。アンダーフィッティングはモデルが訓練セットで十分に小さな誤差の値を得られないときに発生する。オーバーフィッティングは訓練誤差とテスト誤差の間のギャップが大きすぎるときに発生する。
我々はその容量[capacity]を変更することでモデルがオーバーフィットかアンダーフィットのどちらを起こしやすいかを制御することができる。噛み砕いて言えば、モデルの容量とは多種多様な関数にフィットする能力のことである。低容量のモデルは訓練セットをフィットさせるのに苦戦するだろう。高容量のモデルはテストセットで役に立たないような訓練セットの特性を暗記することで過学習する可能性がある。
学習アルゴリズムの容量を制御する方法のひとつは、仮説空間[hypothesis space]、すなわち、学習アルゴリズムが解として選択できる関数の集合を選択することによるものである。例えば、線形回帰アルゴリズムはその仮説空間として入力のすべての一次関数の集合を持つ。我々は線形回帰をその仮説空間に、単なる一次関数ではなく、多項式を含めるように一般化することができる。そうすることでモデルの容量が増加する。
次数[degree]１の多項式はすでに馴染みのある線形回帰モデルをもたらす。これは以下の予測値を持つ。

$$
\hat{y} = b + wx
$$

線形回帰モデルにもたらされる別の特徴として$x^2$を導入することで、$x$の関数として二次関数であるモデルを学習できる。

$$
\hat{y} = b + w_1 x + w_2 x^2
$$

このモデルはその入力の二次関数を実装するにも関わらず、出力は依然としてパラメータの一次関数である。そのため、我々は依然として閉形式でモデルを訓練するために正規方程式を用いることができる。追加の特徴としてさらなる指数の$x$を加え続けることができる。例えば、次数9の多項式を得るには、以下となる。

$$
\hat{y} = b + \sum_{i = 1}^9 w_i x^i
$$

機械学習アルゴリズムは、これらの容量が、処理する必要があるタスクの実際の複雑さと与えられる訓練データ量に対して適切であるとき、一般に適切に処理するだろう。不十分な容量を持つモデルは複雑なタスクを解くことができない。高容量のモデルは複雑なタスクを解くことができるが、その容量が現在のタスクを解くのに必要な量より大きいとき、過学習するかもしれない。
[@fig:5.2]はこの原則を動きで示す。真の基礎にある関数が二次であるところの問題にフィットしようと試みる一次、二次、9次の予測器を比較する。一次関数は真の基礎をなす問題にある曲がり具合を捕捉できない。すなわち、アンダーフィットしている。9次の予測器は正しい関数を表現する能力があるが、訓練examplesより多いパラメータを持つので、訓練点をきっちり通る他の無限に多くの関数を表現する能力もある。非常に広範囲に渡る様々な解が存在するとき、うまく汎化する解を選択する機会はほとんどない。この例では、二次モデルはタスクの真の構造に完璧に一致している。なので、新しいデータにうまく一般化する。
これまでに、我々はモデルの容量を変化させる方法をひとつだけ述べてきた。すなわち、持っている入力の特徴の数を変化させ、同時にこれらの特徴に関連する新しいパラメータを追加することによる方法である。実際にはモデルの容量を変化させる方法はたくさん存在する。容量はモデルの選択によってのみ決定されるものではない。モデルは、訓練目的を減少させるためにパラメータを変化させるとき、学習アルゴリズムがどの関数の族から選ぶことができるかを指定する。これはモデルのrepresentational capacityと呼ばれる。多くの場合、この族の中で最良の関数を見つけることは難しい最適化問題である。実践では、学習アルゴリズムは最良の関数を実際に見つけることはせず、単に訓練誤差を大きく減らすだけである。最適化アルゴリズムの不備のようなこれらの追加の制限は、学習アルゴリズムの実効容量[effective capacity]がモデルの族のrepresentational capacityより小さいかもしれないことを意味する。

![この例の訓練セットに3つのモデルをフィットさせる。訓練セットは、$x$の値を無作為にサンプリングし、二次関数を計算することで決定論的に$y$を選択することによって、合成的に生成する。（左）データにフィットされる一次関数は、データに現れる曲線を捕捉出来ない、というアンダーフィッティングに悩まされる。（中）データにフィットされる二次関数は未見の点にうまく一般化する。これはそこまで大きなオーバーフィッティングおよびアンダーフィッティングに悩まされることはない。（右）データにフィットされる次数9の多項式はオーバーフィッティングに悩まされる。ここでは、我々は劣決定[underdetermined]の正規方程式を解くためにMoore-Penroseの擬似逆行列を用いた。この解はすべての訓練点をきっちり通るが、我々は正確な構造を抽出するのに十分幸運ではなかった。実際の下地の関数には現れない2つの訓練点の間の深い谷がある。データの左側で鋭く増加してもいるが、真の関数はこの範囲では減少する。](fig/5-2.png){#fig:5.2}

機械学習モデルの汎化を改善する事に関する近年のアイデアは、少なくともプトレマイオスくらい初期の哲学者にまでさかのぼる思考の改良である。多くの初期の学者は、現在ではオッカムの剃刀[Occam;s razor]（1287頃～1347）として最も広く知られている倹約の原則[principle of parsimony]を頼りにする。この原則は、既知の観察結果を同様にうまく説明している競合する仮説のうち、「最も単純な」ものを選択すべきである、ということを示している。このアイデアは形式化され、20世紀に統計的学習理論の創設者らによってより精緻に作り上げられた[@Vapnik1971; @Vapnik1982; @Blumer1989; @Vapnik1995]。
統計的学習理論はモデルの容量を定量化する様々な方法を提供する。これらの中で、最も良く知られているのは、Vapnik-Chervonenkis次元[Vapnik-Chervonenkis dimension]、または、VC次元である。VC次元は二値分類器の容量を計測する。VC次元は、分類器が任意にラベル付けできる$m$個の異なる$\boldsymbol{x}$の点の訓練セットが存在するときの$m$の取り得る最大値であると定義される。モデルの容量を定量化することは統計的学習理論が定量的な予測値を作ることを可能にする。統計的学習理論における最も重要な結果は、訓練誤差と汎化誤差の間の食い違い度[discrepancy]がモデル容量の増加に従って大きくなり、訓練examples数の増加に従って小さくなる量によって上から抑えられる[bounded from above]ことを示している[@Vapnik1971; @Vapnik1982; @Blumer1989; @Vapnik1995]。これらの境界は機械学習アルゴリズムが行えるような知的な正当化[intelectual justification]をもたらすが、深層学習アルゴリズムで行うときには実際にはほとんど使われない。これは、ひとつにはその境界がしばしば非常に緩くなるためであり、ひとつには深層学習アルゴリズムの容量を決定することがかなり難しくなり得るためである。深層学習アルゴリズムの容量を決定することの問題は、実効容量が最適化アルゴリズムの能力によって制限されるので、特に難しく、我々は深層学習において活用される一般的な非凸最適化問題の理論的理解をほんの少し有するのみである。
我々は、（訓練誤差とテスト誤差の間のギャップが小さくなるため、）単純な関数の方が一般化される可能性が高くなる一方、依然として低い訓練誤差を達成するため、十分に複雑な仮説を選択する必要があることを思い出す必要がある。一般に、訓練誤差は、モデル容量が増加するたびに、取り得る誤差の最小値に漸近するまで、減少する（誤差の尺度が最小値を持つと仮定した場合）。一般に、汎化誤差はモデル容量の関数としてU字型の曲線を持つ。これは[@fig:5.3]に図示される。

![容量と誤差の典型的な関係。訓練誤差とテスト誤差は別々に振る舞う。グラフの左端では、訓練誤差と汎化誤差は共に高い。これはunderfitting regimeである。容量が増加するに従って、訓練誤差は減少するが、訓練誤差と汎化誤差のギャップは増加する。最終的に、このギャップの大きさが訓練誤差の減少を上回り、overfitting regimeに突入する。ここでは、容量が最適容量を超えて大きくなりすぎている。](fig/5-3.png){#fig:5.3}

任意に高い容量の最も極端なケースに近づくため、我々はノンパラメトリックモデルの概念を導入する。ここまで、我々は線形回帰のようなパラメトリックモデルのみを見てきた。パラメトリックモデルは、いずれのデータが観測される前に、有限で固定の大きさを持つパラメータベクトルによって記述される関数を学習する。ノンパラメトリックモデルはそのような制限を持たない。
時折、ノンパラメトリックモデルは（取り得るすべての確率分布上で探索するアルゴリズムのような）実践において実装できない単なる理論的な抽象概念である。しかし、我々は複雑さを訓練セットの大きさの関数とすることによって実践的なノンパラメトリックモデルを設計することもできる。そのようなアルゴリズムの例のひとつは最近傍回帰[nearest neighbor regression]である。固定長の重みのベクトルを持つ線形回帰と異なり、最近傍回帰モデルは訓練セットから$\boldsymbol{X}$と$\boldsymbol{y}$を単に格納する。テスト点$\boldsymbol{x}$を分類することを求めるとき、モデルは訓練セット内の最も近い成分を探し出し、関連する回帰対象を返す。言い換えれば、$\i = argmin \| \boldsymbol{X}_{i,:} - \boldsymbol{x} \|_2^2$であるところの$\hat{y} = y_i$である。そのアルゴリズムは学習済み距離尺度のような$L^2$ノルム以外の距離測度に一般化することもできる[@Goldberger2005]。アルゴリズムが同率で最近傍であるすべての$\boldsymbol{X}_{i,:}$に対する$y_i$の値を平均化することによって同率状態を打開することができ、そして、このアルゴリズムは任意の回帰データセットで取り得る最小の訓練誤差を達成することができる（訓練誤差は、2つの同一の入力が異なる出力に関連する場合、ゼロより大きくなるかもしれない）。
最後に、我々はパラメトリックな学習アルゴリズムを必要に応じてパラメータ数を増やした別のアルゴリズムで包み込むことによってノンパラメトリックな学習アルゴリズムを作ることもできる。例えば、我々は入力の多項式展開の上での線形回帰によって学習された多項式の次数を変化させる学習の外側のループを想像できるだろう。
理想的なモデルはデータを生成する真の確率分布を知っているという神託である。そのようなモデルでさえ、依然として分布にいくらかのノイズが存在するので、多くの問題による誤差が課されるだろう。教師あり学習の場合、$\boldsymbol{x}$から$y$へのマッピングは本質的に確率的であり得るだろうし、$y$は$\boldsymbol{x}$に含まれるこれら以外の他の変数を伴う決定論的関数であり得るだろう。真の分布$p(\boldsymbol{x}, y)$から予測値を作る神託によって課される誤差はベイズ誤差[Bayes error]と呼ばれる。
訓練誤差と汎化誤差は訓練セットの大きさが変化するたびに変化する。汎化誤差の期待値は訓練examplesの数が増加しても一切増加しない可能性がある。ノンパラメトリックモデルでは、取り得る最良の誤差が達成されるまで、データが多いほどより良い汎化を生み出す。最適容量より小さい容量を持つ任意の固定のパラメトリックモデルはベイズ誤差を超える誤差の値に漸近するだろう。図は[@fig:5.4]を参照のこと。モデルが最適な容量を持ちながらも、未だ、訓練誤差と汎化誤差の間のギャップが大きいことが起こり得ることに注意する。この状況では、より多くの訓練examplesを集めることでこのギャップを減らすことができるかもしれない。

![訓練誤差とテスト誤差における訓練データセットの大きさの影響、および、最適なモデル容量における同様のもの。我々は、次数5の多項式に中程度のノイズ量を加えることに基づいた合成回帰問題を構成し、単一のテストセットを生成し、いくつかの異なる大きさの訓練セットを生成した。大きさごとに、95%の信頼区間を示すエラーバーをプロットするために
40個の異なる訓練セットを生成した。（上）二次モデルとテスト誤差を最小化するように選ばれた次数を持つモデルの2つの異なるモデルに対する訓練セットとテストセットのMSE。両方とも閉形式でフィットする。二次モデルでは、訓練セットの大きさが増加するに従って訓練誤差は増加している。これはより大きなデータセットがフィットしづらいためである。同時に、少量の不正確な仮説が訓練データと一致するので、テスト誤差が減少している。二次モデルはタスクを解くのに十分な容量を持っていないので、そのテスト誤差は高い値に漸近する。最適容量でのテスト誤差はベイズ誤差に漸近する。その訓練誤差は、訓練セットの特定のインスタンスを暗記する訓練アルゴリズムの能力のために、ベイズ誤差以下に落ち得る。訓練サイズが無限大へ増加するに従って、いずれの固定容量モデル（ここでは、二次モデル）の訓練誤差も少なくともベイズ誤差まで上昇しなければならない。（下）訓練セットの大きさが増加するに従って、（ここでは最適な多項式のregressorの次数として示される）最適容量は増加する。最適容量はタスクを解くために十分な複雑さへ達した後に変動しなくなる[plateaus]。](fig/5-4.png){#fig:5.4}

### No Free Lunch定理

学習理論は、機械学習アルゴリズムがexamplesの有限の訓練セットからうまく汎化できることを主張する。これはいくつかの論理の基本原則と矛盾するように思える。帰納的な推論、もしくは、examplesの限定的な集合から一般的な規則を推論することは論理的に正しくない。集合のすべてのメンバを述べる規則を論理的に推論するには、その集合のすべてのメンバに関する情報がなければならない。
ひとつには、機械学習は真に論理的な推論で使われるまったく特定の規則ではなく確率的規則のみをもたらすことでこの問題を回避する。機械学習は考慮している集合のほとんどのメンバについて確率的に正しい規則を求めることを約束する。残念ながら、これでも全部の問題を解く訳ではない。機械学習に対するノーフリーランチ定理[no free lunch theorem] [@Wolpert1996]は、取り得るすべてのデータ生成分布上で平均したとすると、すべての分類アルゴリズムは未見の点を分類するときに同じ誤差を持つ、ということを示している。言い換えれば、ある意味で、機械学習アルゴリズムが他のどんなものよりも全般的に優れているということは一切ない。我々が思い描くことができる最も洗練されたアルゴリズムは、すべての点が同じ種別に属すると予測するのと同じ平均パフォーマンスを（取り得るすべてのタスクで）持つ。
幸いにも、これらの結果は取り得るすべてのデータ生成分布で平均するときにのみ満たされる。我々が現実世界のアプリケーションで遭遇する種類の確率分布についての仮定を作る場合、これらの分布でうまく行われる学習アルゴリズムを設計できる。
これは、機械学習研究の目標が普遍的な学習アルゴリズムや絶対的な最良の学習アルゴリズムを探すことではない、ということを意味している。代わりに、我々の目標は、どんな種類の分布がAIエージェントが経験する「現実世界」と関連しているか、そして、どんな種類の機械学習アルゴリズムが我々の気にしている種類のデータ生成分布から描かれるデータをうまく処理するか、を理解することである。

### 正則化

ノーフリーランチ定理は、機械学習アルゴリズムが特定のタスクでうまく処理するように設計しなければならない、ということを暗示している。我々は学習アルゴリズムに選好[preferences]の集合を組み込むことでこれを行う。これらの選好がアルゴリズムに解くことを求める学習問題に沿っているとき、よりうまく処理される。
これまで、具体的に述べてきた学習アルゴリズムを修正する唯一の方法は学習アルゴリズムが選択できる解の仮説空間から関数を追加または削除することでモデルのrepresentational capacity
を増加または減少させることである。我々は回帰問題に対する多項式の次数の増加または減少の特定の例を与えた。我々がこれまでに述べてきた視点は単純化しすぎている。
アルゴリズムの振る舞いは、仮説空間内に許可されている関数の集合をどれだけ大きく作るかによってだけでなく、それらの関数の特定の恒等式によっても強く影響を受ける。これまでに学んできた学習アルゴリズムである線形回帰はその入力の一次関数の集合から成る仮説空間を持つ。これらの一次関数は、入力と出力の関係が本当に線形に近いところの問題に対して有用となり得る。これらは、非常に非線形なように振る舞う問題ではあまり役に立たない。例えば、線形回帰は、$x$から$\sin(x)$を予測するのに使ってみようとした場合、うまく行えないだろう。従って、我々は、どんな種類の関数から解を描くことができるかを選ぶことによって、アルゴリズムのパフォーマンスを制御することができる。
我々は学習アルゴリズムにその仮説空間におけるある解よりも別の解に対する選好を与えることもできる。これは、両方の関数が適格であるが、片方が好ましい、ということを意味している。好ましくない解は好ましい解より大幅に良く訓練データにフィットする場合に限って選択させるだろう。
例えば、我々はweight decayを含めるために線形回帰に対する訓練基準を修正できる。weight decayを伴う線形回帰を行うため、我々は、より小さな二乗$L^2$ノルムを持つように重みに対する選好を表現する訓練および基準の両方の平均二乗誤差を含む総和$J(\boldsymbol{w})$を最小化する。具体的には、以下となる。

$$
J(\boldsymbol{w}) = \text{MSE}_{train} + \lambda \boldsymbol{w}^\top \boldsymbol{w}
$$

ここで、$\lambda$はより小さな重みに対する選好の強さを制御する前もって選択した値である。$\lambda = 0$であるとき、課される選好はなく、$\lambda$が大きくなるに従って重みが小さくなる。$J(\boldsymbol{w})$の最小化は結果として、訓練データにフィットすることと小さくなることのトレードオフである重みの選択となる。これはより小さな傾斜を持つ解、または、より少量の特徴に重みを置く解をもたらす。weight decayを介してオーバフィットまたはアンダーフィットするモデルの傾向を制御できる方法の例として、我々は異なる$\lambda$の値で高次多項式の線形回帰モデルを訓練することができる。その結果は[@fig:5.5]を参照のこと。

![[@fig:5.2]の例の訓練セットに高次多項式の回帰モデルをフィットさせる。真の関数は二次であるが、ここでは次数9のモデルのみを用いる。高次モデルがオーバーフィッティングするのを防止するためにweight decayの具合を変化させる。（左）非常に大きな$\lambda$では、まったく傾斜がない関数を学習するようモデルに強いることができる。これは定数関数しか表現できないので、アンダーフィットする。（中）中くらいの$\lambda$の値では、学習アルゴリズムは正しい一般的な形状を持つ曲線を復元する。モデルはもっと複雑な形状を持つ関数を表現する能力があるにも関わらず、weight descayはより少ない係数で記述されるより単純な関数を用いるよう促した。（右）ゼロに近づく（すなわち、最小正則化を伴う劣決定問題を解くためにMoore-Penroseの擬似逆行列を用いる）weight decayでは、[@fig:5.2]で見たように、9次多項式は大幅にオーバーフィットする。](fig/5-5.png){#fig:5.5}

より一般的には、コスト関数にregularizerと呼ばれるペナルティを加えることで関数$f(\boldsymbol{x}; \boldsymbol{\theta})$を学習するモデルを正則化できる。weight decayの場合、regularizerは$\Omega(\boldsymbol{w}) = \boldsymbol{w}^\top \boldsymbol{w}$である。[@sec:7]では、他の多くのregularizersが取り得るものを見ていく。
別の関数よりもある関数の方を選好することを説明することは、仮説空間にメンバを含めたり除いたりすることよりもモデルの容量を制御する一般的な方法である。仮説空間から関数を除外することはその関数に対する無限に強い選好を表現することとみなすことができる。
我々のweight decayの例では、最小化する基準における追加の項を介して、明示的により小さな重みで定義される一次関数に対する選好を表現した。暗黙的でも明示的でも、異なる解に対して選好を表現する他の方法が多数存在する。共に、これらの様々なアプローチは正則化[regularization]として知られる。正則化とは訓練誤差ではなく汎化誤差を減らすことを意図した学習アルゴリズムを作るために施す任意の修正である。正則化は機械学習の分野の中心的な関心事のひとつであり、その重要性において匹敵するのは最適化のみである。
ノーフリーランチ定理は、最良の機械学習アルゴリズムが存在しない、特に、最適な正則化の形式が存在しないことを明らかにした。代わりに、我々は解きたい特定のタスクに適した正則化の形式を選択しなければならない。一般、そして、特に本書における深層学習の哲学とは、（人間ができるすべての知的なタスクのような）広範囲のタスクすべてが極めて汎用用途の正則化の形式を用いて効率的に解か得るであろうことである。

## ハイパーパラメータと検証セット

ほとんどの機械学習アルゴリズムは、アルゴリズムの振る舞いを制御するのに使うことができる設定であるハイパーパラメータを持つ。ハイパーパラメータの値は学習アルゴリズムそれ自体に適合しない（ある学習アルゴリズムが別の学習アルゴリズムに対する最良のハイパーパラメータを学習するような入れ子の学習プロシージャを設計できるにもかかわらず）。
[@fig:5.2]にある多項式回帰の例は、多項式の次数、という単一のハイパーパラメータを持つ。これは、容量のハイパーパラメータとして振る舞う。weight decayの強さを制御するのに使われる$\lambda$の値はもうひとつのハイパーパラメータの例である。
時折、設定は、最適化するのが難しいので、学習アルゴリズムが学習しないハイパーパラメータとなるよう選択される。さらに頻繁に、訓練セットでそのハイパーパラメータを学習することは適切でないので、設定はハイパーパラメータでなければならない。これはモデル容量を制御するすべてのハイパーパラメータに適用される。訓練セットで学習する場合、そのようなハイパーパラメータは常に取り得る最大のモデル容量を選択するだろうから、結果としてオーバーフィッティングになる（[@fig:5.3]を参照）。例えば、低次多項式かつ正のweight decay設定よりも高次多項式かつ$\lambda = 0$のweight decay設定の方が常にうまく訓練セットにフィットさせることができる。
この問題を解決するためには、訓練アルゴリズムが観察しないexamplesの検証セット[validation set]を必要とする。以前に我々は、学習プロセスが完了した後に、訓練セットと同じ分布に由来するexamplesから構成される、hold-out[訓練セットの一部から提供される]されたテストセットが学習器の汎化誤差を推定するのに使うことができることを説明した。テストexamplesが、ハイパーパラメータを含め、モデルについての選択を行うあらゆるところで使われていないことは重要である。このため、検証セットで使うことができるテストセットからのexampleは一切ない。従って、我々は常に訓練データから検証セットを構築する。具体的には、2つの互いに素な部分集合[two disjoint subsets]に訓練データを分割する。これらの部分集合のひとつはパラメータを学習するのに使われる。もう片方の部分集合は、訓練の後または最中に汎化誤差を推定するのに使われる、検証セットであり、それに従ってハイパーパラメータを更新することができる。パラメータを学習するのに使われるデータの部分集合は、これが訓練プロセス全体で使われるより大きなデータのプールと混同し得るにも関わらず、依然として一般に訓練セットと呼ばれる。ハイパーパラメータの選択を導くために使われるデータの部分集合は検証セットと呼ばれる。一般に、訓練データの約80%が訓練に使われ、20%が検証に使われる。検証セットはハイパーパラメータを「訓練」するのに使われるので、検証セットの誤差は汎化誤差を小さく見積もるだろうが、一般に訓練誤差が行うよりもその量は小さくなる。すべてのハイパーパラメータの最適化が完了した後、汎化誤差はテストセットを用いて推定できるだろう。
実際には、同じテストセットが長年に渡って様々なアルゴリズムのパフォーマンスを評価するのに繰り返し使われてきたとき、特に、そのテストセット上での報告された最新のパフォーマンスを破っている科学コミュニティからの試みのすべてを考慮する場合、我々は同じようにテストセットで楽観的評価を持つようになる。故に、ベンチマークは陳腐化し、訓練済みシステムの本当の実地パフォーマンスを反映しない。ありがたいことに、コミュニティは新しい（そして、通常はより野心的で大きな）ベンチマークデータセットに移行する傾向にある。

### 交差検証

データセットを固定の訓練セットと固定のテスト接tおに分けることは結果としてテストセットが小さくなる場合に問題となり得る。小さなテストセットは推定される平均テスト誤差の周りの統計的な不確かさを暗示することで、与えられたタスクにおいてアルゴリズム$A$がアルゴリズム$B$よりうまく機能することを主張することが難しくなる。
データセットが数十万個以上のexamplesを持つとき、これは深刻な問題ではない。データセットが小さすぎるとき、代替の手順は、増加する計算コストを代償として、平均テスト誤差の推定値においてexamplesのすべてを用いることを可能にする。これらの手順はもとのデータセットの無作為に選択された異なる部分集合または分裂[splits]での訓練およびテスト計算を繰り返すというアイデアに基づく。これらの中で最も一般的なものは、[@lst:5.1]に示される、$k$分割交差検証[k-fold cross-validation]の手順である。ここでは、データセットの区分が重複しない部分集合に分割することで形成される。そして、テスト誤差は$k$個の試行の平均を取ることで推定できるだろう。試行$i$では、$i$番目のデータの部分集合がテストセットとして使われ、残りのデータが訓練セットとして使われる。問題はそのような平均誤差の推定器の分散のunbiasedな推定器が存在しない[@Bengio2004]ので、近似が一般に用いられることである。

```
Define KFoldXV($\mathbb{D}$, $A$, $L$, $k$):
Require: $\mathbb{D}$、与えられたデータセットであり、要素$\boldsymbol{z}^{(i)}$を持つ
Require: A$$、学習アルゴリズムであり、入力としてデータセットを取り、学習済みの関数を出力する関数とみなせる
Require: $L$、損失関数であり、学習済みの関数$f$とexample $\boldsymbol{z}^{(i)} \in \mathbb{D}$から$\mathbb{R}$内のスカラへの関数とみなせる
Require: $k$、foldsの数
  \mathbb{D}$を、その和集合が$\mathbb{D}$となるような、$k$個の相互排他的な部分集合$\mathbb{D}_i$に分割する
  $i$を$1$から$k$まで繰り返す
    $f_i = A(\mathbb{D} \setminus \mathbb{D}_i)$
    $\boldsymbol{z}^{j}$を$\mathbb{D}_i$内の要素で繰り返す
      $e_j = L(f_i, \boldsymbol{z}^{j})$
    繰り返し終わり
  繰り返し終わり
  $\boldsymbol{e}$を返す
```
: $k$分割交差検証のアルゴリズム。これは、小さなテストセットにおける損失$L$の平均が高すぎる分散を持つかもしれないので、与えられたデータセット$\mathbb{D}$が汎化誤差の正確な推定値を生み出すには単純な訓練/テストまたは訓練/検証の分裂に対して小さすぎるとき、学習アルゴリズム$A$の汎化誤差を推定するのに使うことができる。データセット$\mathbb{D}$は要素として抽象的なexamples$\boldsymbol{z^{(i)}}$（$i$番目のexampleに対して）を含んでいる。これは、教師あり学習の場合では$\boldsymbol{z}^{(i)} = (\boldsymbol{x}^{(i)}, \boldsymbol{y}^{(i)})$の入力と対象の対を、教師なし学習では単なる入力$\boldsymbol{z}^{(i)} = \boldsymbol{x}^{(i)}$を表し得るだろう。このアルゴリズムは$\mathbb{D}$におけるexampleごとの誤差のベクトル$\boldsymbol{e}$を返す。この平均は推定される汎化誤差である。ここのexamplesの誤差はその平均の周りの信頼区間を計算するのに使うことができる[@e:5.47]。これらの信頼区間は交差検証を用いるとうまく正当化されないにも関わらず、アルゴリズム$A$の誤差の信頼区間が下の方にあり、アルゴリズム$B$の信頼区間と交差しない場合に限り、アルゴリズム$A$がアルゴリズム$B$より優れていることを宣言するのに使うことは依然として一般的なプラクティスである。



## 推定器、バイアス、分散

点推定は関心のある量の「最良」の推定値をもたらすための試みである。一般に、関心のある量は、[@sec:5.1.4]にある線形回帰の例における重みのように、あるパラメトリックモデルにおける単一のパラメータまたはパラメータのベクトルとなり得るが、a whole functionである可能性もある。
真の値とパラメータの推定値を区別するため、我々の慣例ではパラメータ$\boldsymbol{\theta}$の推定点を$\hat{\boldsymbol{\theta}}$で表記するだろう。
${\boldsymbol{x}^{(1)}, \dots, \boldsymbol{x}^{(m)}}$が$m$個の独立同分布（i.i.d.）のデータ点の集合であるとする。点推定器[point estimators]または統計量[statistic]はそのデータの任意の関数である。

$$
\hat{\boldsymbol{\theta}} = g(\boldsymbol{x}^{(1)}, \dots, \boldsymbol{x}^{(m)})
$$

この定義は、$g$が真の$\boldsymbol{\theta}$に近い値を返す必要も、$g$の範囲が$\boldsymbol{\theta}$の許容できる値の集合と同じである必要さえもない。この点推定器の定義は非常に一般的であり、推定器の設計者に大きな柔軟性を与えるだろう。故に、ほとんどすべての関数が推定器として定量化するが、良い推定器は、訓練データを生成した本物の下地の$\boldsymbol{\theta}$に近い出力を持つ関数である。
今のところ、我々は統計学に対して頻度論者的な視点を取っている。これはつまり、我々は、真のパラメータの値$\boldsymbol{\theta}$が固定だが不明である一方で、点推定$\hat{\boldsymbol{\theta}}$がデータの関数であると仮定している。データは無作為な過程から描かれるので、そのデータのいずれの関数も無作為である。従って、$\hat{\boldsymbol{\theta}}$は確率変数である。

#### 関数推定

時折、我々は関数推定[function estimation]（または、関数近似）を行うことに興味がある。ここで、我々は入力ベクトル$\boldsymbol{x}$が与えられたときの変数$\boldsymbol{y}$を推定しようとしている。$\boldsymbol{y}$と$\boldsymbol{x}$の間の近似の関係を記述する関数$f(\boldsymbol{x})$が存在すると仮定する。例えば、$\boldsymbol{y} = f(\boldsymbol{x} + \epsilon)$であると仮定できるだろう。ここで、$\epsilon$は$\boldsymbol{x}$から予測可能でない$\boldsymbol{y}$の部分を表す。関数推定において、我々はモデルまたは推定$\hat{f}$で$f$を近似することに興味がある。関数推定は実際には単にパラメータ$\boldsymbol{\theta}$を推定することと同じである。つまり、関数推定器$\hat{f}$は単に関数空間における点推定である。（[@sec:5.1.4]で言及される）線形回帰の例や（[@sec:5.2]で言及される）多項式回帰の例の両方は、パラメータ$\boldsymbol{w}$を推定するか$\boldsymbol{x}$から$y$へマッピングする関数$\hat{f}$を推定するかのいずれかとして解釈され得るであろうシナリオを示す。
そこで、我々は点推定器の最も一般的に研究される特性を説明し、それらがこれらの推定器について教えてくれるものを議論する。

### バイアス

推定器のバイアスは以下のように定義される。

$$
\text{bias}(\hat{\boldsymbol{\theta}}_m) = \mathbb{E}(\hat{\boldsymbol{\theta}}_m) - \boldsymbol{\theta}
$$

ここで、期待値はデータ全体に対するもの（確率変数からのサンプルとして理解される）であり、$\boldsymbol{\theta}$はデータ生成分布を定義するのに使われる$\boldsymbol{\theta}$の真の基礎となる値である。推定器$\hat{\boldsymbol{\theta}}_m$は$\text{bias}(\hat{\boldsymbol{\theta}}_m) = \boldsymbol{0}$である場合に不偏[unbiased]であると言う。これは、$\mathbb{E}(\hat{\boldsymbol{\theta}}_m) = \boldsymbol{\theta}$であることを暗に示す。推定器$\hat{\boldsymbol{\theta}}_m$は$\lim_{m \rightarrow \infty} \text{\hat{\boldsymbol{\theta}}_m} = \boldsymbol{0}$である場合に漸近的に不偏[asymptotically unbiased]であると言う。これは$\lim_{m \rightarrow \infty} \mathbb{E}(\hat{\boldsymbol{\theta}}_m) = \boldsymbol{\theta}$であることを暗に示す。

#### 例：ベルヌーイ分布

平均$\theta$を持つベルヌーイ分布に従って独立同分布的であるサンプルの集合${x^{(1)}, \dots, x^{(m)}}$を考える。

$$
P(x^{(i)}; \theta) = \theta^{x^{(i)}} (1 - \theta)^{(1 - x^{(i)})}
$$

この分布の$\theta$パラメータに対する一般的な推定器は訓練サンプルの平均である。

$$
\hat{\theta}_m \frac{1}{m} \sum_{i = 1}^m x^{(i)}
$$

この推定器が偏っているかどうかを決定するため、我々は[@eq:5.22]を[@eq:5.20]に置き換えることができる。

$$
\text{bias}(\hat{\theta}_m) = \mathbb{E}[\hat{\theta}_m] - \theta
$$

$$
= \mathbb{E}[\frac{1}{m} \sum_{i=1}^m x^{(i)}] - \theta
$$

$$
= \frac{1}{m} \sum_{i=1}^m \mathbb{E}[x^{(i)}] - \theta
$$

$$
= \frac{1}{m} \sum_{i=1}^m \sum_{x^{(i)} = 0}^1 (x^{(i)} \theta^{x^{(i)}} (1 - \theta)^{(1 - x^{(i)})}) - \theta
$$

$$
= \frac{1}{m} \sum_{i=1}^m (\theta) - \theta
$$

$$
= \theta - \theta = 0
$$

$\text{bias}(\hat{\theta}) = 0$であるので、推定器$\hat{\theta}$は不偏であると言える。

#### 例：平均のガウス分布推定器

では、ガウス分布$p(x^{(i)}) = \mathcal{N}(x^{(i)}; \mu, \sigma^2)$に従って独立同分布的であるサンプルの集合${x^{(1)}, \dots, x^{(m)}}$を考える。ここで、$i \in {1, \dots, m}$である。ガウスの確率密度関数は以下で与えられることを思い出してほしい。

$$
p(x^{(i)}; \mu, \sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp \left( -\frac{1}{2} \frac{(x^{(i)} - \mu)^2}{\sigma^2} \right)
$$

ガウス分布の平均パラメータの一般的な推定器は標本平均[sample mean]として知られる。

$$
\hat{\mu}_m = \frac{1}{m} \sum_{i=1}^m x^{(i)}
$$

標本平均の偏りを決定するため、その期待値の計算に再び目を向ける。

$$
\text{bias}(\hat{\mu}_m) = \mathbb{E}[\hat{\mu}_m] - \mu
$$

$$
= \mathbb{E} \left[ \frac{1}{m} \sum_{i=1}^m x^{(i)} \right] - \mu
$$

$$
= \left( \frac{1}{m} \sum_{i=1}^m \mathbb{E} \left[ x^{(i)} \right] \right) - \mu
$$

$$
= \left( \frac{1}{m} \sum_{i=1}^m \mu \right) - \mu
$$

$$
\mu - \mu = 0
$$

従って、標本平均がガウスの平均パラメータの不偏の推定器であることが分かる。

#### 例：ガウス分布の分散の推定器

この例では、ガウス分布の分散パラメータ$\sigma^2$の2つの異なる推定器を比較する。我々はいずれかの推定器が偏っているかどうかを知ることに関心がある。
我々が考慮する第1の$\sigma^2$の推定器は標本分散[sample variance]として知られる。

$$
\hat{\sigma}_m^2 = \frac{1}{m} \sum_{i=1}^m \left( x^{(i)} - \hat{\mu}_m \right)^2
$$

ここで、$\hat{\mu}_m$は標本平均である。より形式的に言えば、我々は以下を計算することに関心がある。

$$
\text{bias}(\hat{\sigma}_m^2) = \mathbb{E}[\hat{\sigma}_m^2] - \sigma^2
$$

まずは項$\mathbb{E}[\hat{\sigma}_m^2]$を計算することから始める。

$$
\mathbb{E}[\hat{\sigma}_m^2] = \mathbb{E} \left[ \frac{1}{m} \sum_{i=1}^m \left( x^{(i)} - \hat{\mu}_m \right)^2 \right]
$$

$$
= \frac{m - 1}{m} \sigma^2
$$

[@eq:5.37]に戻って、我々は$\hat{\sigma}^2$のバイアスが$-\sigma^2 / m$であると結論付ける。従って、標本分散は偏った推定器である。

以下の不偏標本分散[unbiased sample variance]の推定器は別のアプローチをもたらす。

$$
\tilde{\sigma}_m^2 = \frac{1}{m - 1} \sum_{i = 1}^m \left( x^{(i)} - \hat{\mu}_m \right)^2
$$

名前が示す通り、この推定器は不偏である。すなわち、$\mathbb{E}[\tilde{\sigma}_m^2] = \sigma^2$であることが分かる。

$$
\mathbb{E}[\tilde{\sigma}_m^2] = \mathbb{E} \left[ \frac{1}{m - 1} \sum_{i = 1}^m \left( x^{(i)} - \hat{\mu}_m \right)^2 \right]
$$

$$
= \frac{m}{m - 1} \mathbb{E}[\hat{\sigma}_m^2]
$$

$$
= \frac{m}{m - 1} \left( \frac{m - 1}{m} \sigma}^2 \right)
$$

$$
= \sigma^2
$$

我々は2つの推定器を持っている。一方はバイアスがあり、他方はバイアスがない。不偏な推定器は明らかに望ましいものであるが、常に「最良」の推定器であるとは限らない。これから見ていくが、しばしば他の重要な特性を持つバイアスありの推定器を用いることがある。

### 分散と標準誤差

考慮したいかもしれない推定器のもうひとつの特性はデータサンプルの関数として変化することが予測される量である。そのバイアスを定めるために推定器の期待値を計算したのと同様に、その分散を計算できる。推定器の分散[variance]は確率変数が訓練セットであるところの以下のような分散である。

$$
\text{Var}(\hat{\theta})
$$

また、分散の二乗根は標準誤差[standard error]と呼ばれ、$\text{SE}(\hat{\theta})$と表記される。
推定器の分散、または、標準誤差は、基礎をなすデータ生成過程からデータセットを独立してリサンプリングするとき、データから計算される推定値がどれだけ変化すると予測されるだろうかという尺度をもたらす。低いバイアスを示す推定器を好むかもしれないのと同様に、我々は比較的低い分散をもつことも好むだろう。
有限個のサンプルを用いるいずれかの統計量を計算するとき、同じ分布から別のサンプルを得て、これらの統計量が異なっていたかもしれないという意味で、真の下地のパラメータの推定値は不確かである。任意の推定器における分散の期待値は定量化したい誤差の源である。
平均の標準誤差は以下で求められる。

$$
\text{SE}(\hat{\mu}_m) = \sqrt{\text{Var} \left[ \frac{1}{m} \sum_{i=1}^m x^{(i)} \right]} = \frac{\sigma}{\sqrt{m}}
$$

ここで、$\sigma^2$はサンプル$x^i$の真の分散である。標準誤差はしばしば$\sigma$の推定値を用いて推定される。残念ながら、サンプルの分散の二乗根や分散の不偏な推定器の二乗根のいずれも標準偏差の不偏な推定値をもたらさない。両方のアプローチは真の標準偏差を過少に推定する傾向があるが、実践では依然として使われている。分散の不偏な推定器の二乗根の方がより過少推定しにくい。大きな$m$に対して、その近似は極めて合理的である。
平均の標準誤差は機械学習の実験において非常に有用である。我々はしばしばテストセットでの誤差の標本平均を計算することで汎化誤差を推定する。テストセットの中のexamples数はこの推定値の正確さを決める。平均が正規分布で近似的に分布するであろうことを教えてくれる中心極限定理の利点を活かし、我々は真の期待値が任意の選ばれた区間に降下する確率を計算するのに標準誤差を用いることができる。例えば、平均$\hat{\mu}_m$を中心とする95%の信頼区間は平均$\hat{\mu}_m$と分散$\text{SE}(\hat{\mu}_m)^2$を持つ正規分布のもとで以下のようになる。

$$
(\hat{\mu}_m - 1.96 \text{SE}(\hat{\mu}_m), \hat{\mu}_m + 1.96 \text{SE}(\hat{\mu}_m))
$$

機械学習の実験において、アルゴリズム$A$の誤差に対する95%信頼区間の上界がアルゴリズム$B$の誤差の95%信頼区間の下界より小さい場合、アルゴリズム$A$はアルゴリズム$B$より優れている、と言うのが一般的である。

#### 例：ベルヌーイ分布

もう一度、ベルヌーイ分布から独立同分布的に描かれるサンプルの集合${x^{(1)}, \dots, x^{(m)}}$を考える（再掲、$P(x^{(i)}; \theta) = \theta^{x^{(i)}} (1 - \theta)^{(1 - x^{(i)})}$）。今回は、推定器$\hat{\theta}_m = \frac{1}{m} \sum_{i=1}^m x^{(i)}$の分散を計算することに関心がある。

$$
\text{Var}(\hat{\theta}_m) = \text{Var} \left( \frac{1}{m} \sum_{i=1}^m x^{(i)} \right)
$$

$$
= \frac{1}{m^2} \sum_{i=1}^m \text{Var} \left( x^{(i)} \right)
$$

$$
= \frac{1}{m^2} \sum_{i=1}^m \theta (1 - \theta)
$$

$$
= \frac{1}{m^2} m \theta (1 - \theta)
$$

$$
= \frac{1}{m} \theta (1 - \theta)
$$

推定器の分散はデータセットのexamples数である$m$の関数に従って減少する。これは、人気の推定器の一般的な特性であり、一貫性を議論するときにこれに立ち返ろうと思う（[@sec:5.4.5]を参照）。

### 平均二乗誤差を最小化するためのバイアスと分散のトレードオフ

バイアスと分散は推定器において2つの異なる誤差の源を計測する。バイアスは関数またはパラメータの真の値からの偏差の期待値を計測する。一方の分散は、データの特定のサンプリングを引き起す可能性があるという推定器の値の期待値からの偏差の尺度をもたらす。
1つはバイアスの方が大きく、1つは分散のほうが大きい2つの推定器の間の選択を与えられるときに何が起こるか？どうやってこれらの間を選択するか？例えば、[@fig:5.2]に示される関数を近似することに興味があり、大きなバイアスを持つモデルと大きな分散に悩まされるモデルの間の選択肢を提示されるのみであると想像してみよう。どうやってこれらの間を選択するか？
このトレードオフに折り合いをつける最も一般的な方法は交差検証を用いることである。経験上、交差検証は多くの現実世界のタスクで大きく成功を収めている。あるいは、推定値の平均二乗誤差（MSE）を比較することもできる。

$$
\text{MSE} = \mathbb{E}[(\hat{\theta}_m - \theta)^2]
$$

$$
= \text{Bias}(\hat{\theta}_m)^2 + \text{Var}(\hat{\theta}_m)
$$

MSEはパラメータ$\theta$の推定器と真の値の間の、二乗誤差の意味での、全体の偏差の期待値である。[@eq:5.54]から明らかである通り、MSEを計算することはバイアスと分散の両方が組み込まれている。望ましい推定器は小さなMSEを持つこれらであり、これらはこれらのバイアスと分散をいくらか抑制するよう管理する推定器である。
バイアスと分散の関係は、容量、アンダーフィッティング、オーバーフィッティングといった機械学習の概念と強く結びついている。汎化誤差がMSEによって計測されるとき（ここで、バイアスと分散が汎化誤差の有意義な要素である）、容量が増加すると分散が増加し、バイアスが減少する傾向がある。これは[@fig:5.6]に図示される。ここでは、容量の関数としてU型の汎化誤差曲線を確認できる。

![容量が増加する（$x$軸）のに従って、バイアス（点線）は減少する傾向にあり、分散（破線）は増加する傾向にある。すると、汎化誤差（太線）に対して別のU型曲線を生み出す。ある軸に沿って容量を変化させる場合には最適な容量が存在し、容量がこの最適値を下回るとアンダーフィットし、上回るとオーバーフィットする。この関係は、[@sec:5.2]や[@fig:5.3]で述べられる、容量とアンダーフィッティングとオーバーフィッティングの間の関係に似ている。](fig/5-6.png){#fig:5.6}

### 一貫性

これまで、我々は固定サイズの訓練セットに対する様々な推定器の特性を議論してきた。通常、我々は訓練データの量が増えるにつれて推定器の振る舞いも考慮する。特に、我々は通常、データ点の数$m$が増加するにつれて、点の推定値は対応するパラメータの真の値に収束することを望む。我々は以下のようにしたい。

$$
\text{plim}_{m \rightarrow \infty} \hat{\theta}_m = \theta
$$

記号$\text{plim}$は確率における収束を示し、任意の$\epsilon > 0$に対して、$m \rightarrow \infty$につれて$P(|\hat{\theta}_m - \theta| > \epsilon) \rightarrow 0$となることを意味する。[@eq:5.55]で述べられる条件は一貫性[consistency]として知られる。これは時折、弱い一貫性と呼ばれ、$\hat{\theta}$の$\theta$へのほとんど確実な[almost sure]収束を指して強い一貫性とする。確率変数の列$\boldsymbol{\mathbf{x}}^{(1)}, \boldsymbol{\mathbf{x}}^{(2)}, \dots$の値$\boldsymbol{x}$への概収束[almost sure convergence]は$p(\lim_{m \rightarrow \infty} \boldsymbol{\mathbf{x}}^{(m)} = \boldsymbol{x}) = 1$であるときに発生する。
一貫性は、推定器によって課されるバイアスがデータexamplesの数が増えるにつれて減退することを保証する。しかし、そのreverseは真ではない。つまり、漸近的な不偏性は一貫性を暗示しない。例えば、$m$個のサンプルのデータセット${x^{(1)}, \dots, x^{(m)}}$で、正規分布$\mathcal{N}(x; \mu, \sigma^2)$の平均パラメータ$\mu$を推定することを考える。我々はデータセットの最初のサンプル$x^{(1)}$を不偏な推定器$\hat{\theta} = x^{(1)}$として用いることができるかもしれない。この場合、$\mathbb{E}(\hat{\theta}_m) = \theta$であるので、推定器は、見えるデータ点の数に関係なく、不偏である。もちろん、これは、推定値が漸近的に不偏であることを暗示する。しかし、これは、$m \rightarrow \infty$となるたびに$\hat{\theta}_m \rightarrow \theta$であるケースではないので、一貫性を持つ推定器ではない。

## 最尤推定

我々は一般的な推定器の定義やこれらの解析された特性を見てきた。しかし、こららの推定器はとこから来たのだろう？ある関数が良好な推定器であるかもしれないことを推測し、そのバイアスと分散を解析するのではなく、我々は様々なモデルに対して良好な推定器となる特定の関数群を導出できるある原則を手に入れたいと考える。
そのような原則の中で最も一般的なものは最尤[maximum likelihood]原則である。
実際のものだが分かっていないデータ生成分布$p_{data}(\boldsymbol{\mathbf{x}})$から独立して描かれる$m$個のexamplesの集合$\mathbb{X} = {\boldsymbol{x}^{(1)}, \dots, \boldsymbol{x}^{(m)}}$を考える。
$p_{model}(\boldsymbol{\mathbf{x}}; \boldsymbol{\theta})$が$\boldsymbol{\theta}$で指される同じ空間での確率分布のパラメトリックな族であるとする。言い換えれば、$p_{model}(\boldsymbol{x}; \boldsymbol{\theta}$は任意のconfiguration $\boldsymbol{x}$を真の確率$p_{data }(\boldsymbol{x})$を推定する実数にマッピングする。
従って、$\boldsymbol{\theta}$に対する最尤推定量[maximum likelihood estimator]は以下のように定義される。

$$
\boldsymbol{\theta}_{ML} = \argmax_{\boldsymbol{\theta}} p_{model}(\mathbb{X}; \boldsymbol{\theta})
$$

$$
= \argmax_{\boldsymbol{\theta}} \prod_{i=1}^m p_{model}(\boldsymbol{x}^{(i)}; \boldsymbol{\theta})
$$

多数の確率にわたるこの積は様々な理由により都合が悪い可能性がある。例えば、これは数値的なアンダーフローを起こしがちである。より便利だが等価な最適化問題を得るため、尤度の対数を取ることがその$\argmax$を変化させないが、総乗を総和に便利に変換することを示す。

$$
\boldsymbol{\theta}_{ML} = \argmax_{\boldsymbol{\theta}} \sum_{i=1}^m \log p_{model}(\boldsymbol{x}^{(i)}; \boldsymbol{\theta})
$$

$\argmax$は***
