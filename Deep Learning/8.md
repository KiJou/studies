# 深層モデルの訓練に対する最適化

深層学習アルゴリズムは多くの状況で最適化を伴う。例えば、PCAのようなモデルで推論を行うことは最適化問題を解くことを伴う。我々はしばしば、証明を記述したりアルゴリズムを設計したりするために解析的な最適化を用いる。深層学習に組み込まれる多くの最適化問題の中で、最も困難なものはニューラルネットワークの訓練である。ニューラルネットワークの訓練問題のたった1つのインスタンスを解くために何百のマシンで数日から数ヶ月を投資することは極めて一般的である。この問題はそれほどに重要であり、それほどに高価であるので、最適化技術の特殊化された集合はそれを最適化するために開発された。本性はニューラルネットワークの訓練に対するこれらの最適化技術を提示する。
あなたが勾配ベースの最適化の基本原則に親しみを持たないならば、[@sec:4]を復習することを提案する。この章は一般における数値的最適化の簡潔な概要を含む。
本章は、コスト関数$J(\boldsymbol{\theta})$を大幅に減少させるニューラルネットワークのパラメータ$\boldsymbol{\theta}$を求める、という最適化の1つの特定のケースに焦点を当ている。これは、追加の正則化項と同様に訓練セット全体で評価されるパフォーマンス測度を一般に含む。
我々は機械学習タスクに対する訓練アルゴリズムとして使われる最適化が純粋な最適化と異なる具合の説明から始める。次に、ニューラルネットワークの最適化を難しくする具体的な課題にいくつかを提示する。そして、最適化アルゴリズム自体とパラメータを初期化するための戦略の両方を含めた、いくつかの実践的なアルゴリズムを定義する。より発展的なアルゴリズムは訓練中に学習率に適応したり、コスト関数の二階微分に含まれる情報を活用したりする。最後に、単純な最適化アルゴリズムを高レベルの手順に組み合わせることによって形成されるいくつかの最適化略のレビューで結論とする。

## 学習は純粋な最適化とどれほど異なるか

深層モデルの訓練で使われる最適化アルゴリズムはいくつかの点で伝統的な最適化アルゴリズムと異なる。機械学習は通常では間接的に行われる。ほとんどの機械学習シナリオでは、我々は、テストセットに関して定義され、扱いづらくもあるかもしれない、あるパフォーマンス測度$P$に関心を持っている。故に、我々は間接的にのみ$P$を最適化する。そうすることが$P$を改善するだろうという望みを持って異なるコスト関数$J(\boldsymbol{\theta})$を減少させる。これは、$J$を最小化することがそれ自体の目標である純粋な最適化と対照的である。深層モデルの訓練に対する最適化アルゴリズムもまた一般に機械学習の目的関数の特定の構造に関するある特殊化を含む。
一般的には、コスト関数は訓練セットに対する平均として、以下のように記述できる。

$$
J(\boldsymbol{\theta}) = \mathbb{E}_{(\boldsymbol{x}, \mathbf{y}) \sim \hat{p}_{data}} L(f(\boldsymbol{x}; \boldsymbol{\theta}), y)
$$

ここで、$L$はexampleごとの損失関数であり、$f(\boldsymbol{x}; \boldsymbol{\theta})$は入力が$\boldsymbol{x}$であるときに予測される出力であり、$\hat{p}_{data}$は経験分布である。教師あり学習の場合、$y$はtarget出力である。本章を通して、我々は、$L$への引数が$f(\boldsymbol{x}; \boldsymbol{\theta})$と$y$である、正規化なし教師ありの場合を開発する。様々な形式の正則化や教師なし学習を開発するために、この開発を、例えば、引数として$\boldsymbol{\theta}$か$\boldsymbol{x}$を含むように、または、引数として$y$を除外するように拡張することは自明である。
[@eq:8.1]は訓練セットに関する目的関数を定義する。我々は通常では、期待値が単に有限の訓練セットに対するのではなく、*データ生成分布*$p_{data}$に渡って取られるところの対応する目的関数を最小化する方を好むだろう。

$$
J^*(\boldsymbol{\theta}) = \mathbb{E}_{(\boldsymbol{x}, \mathbf{y}) \sim p_{data}} L(f(\boldsymbol{x}; \boldsymbol{\theta}), y)
$$

### 経験的リスク最小化

機械学習アルゴリズムの目標は[@eq:8.2]で与えられる汎化誤差の期待値を減らすことである。この量はリスク[risk]として知られる。我々はここで期待値が真の下地の分布$p_{data}$に対して取られることを強調する。真の分布$p_{data}(\boldsymbol{x}, y)$を知っていたならば、リスク最小化は最適化アルゴリズムによって解くことが出来る最適化タスクであっただろう。しかしながら、$p_{data}(\boldsymbol{x}, y)$を知らず、サンプルの訓練セットを持つだけであるとき、我々は機械学習問題を持つ。
機械学習問題を最適化問題に変換し直すための最も単純な方法は訓練セットに関して損失の期待値を最小化することである。これは真の分布$p(\boldsymbol{x}, y)$を訓練セットで定義される経験分布$\hat{p}(\boldsymbol{x}, y)$で置き換えることを意味する。いま、我々は経験的リスク[empirical risk]を最小化する。

$$
\mathbb{E}_{\boldsymbol{x}, \mathbf{y} \sim \hat{p}_{data}(\boldsymbol{x}, y)} [L(f(\boldsymbol{x}; \boldsymbol{\theta}), y)] = \frac{1}{m} \sum_{i=1}^m L(f(\boldsymbol{x}^{(i)}; \boldsymbol{\theta}), y^{(i)})
$$

ここで、$m$は訓練examplesの数である。
この平均訓練誤差を最小化することに基づく訓練プロセスは経験的リスク最小化[empirical risk minimization]として知られる。この設定では、機械学習は***
