# 深層フィードフォワードネットワーク

フィードフォワードニューラルネットワーク[feedforward neural networks]とか多層パーセプトロン[multilayer perceptrons]（MLPs）とも呼ばれる、深層フィードフォワードネットワーク[deep feedforward networks]は典型的な深層学習モデルである。フィードフォワードネットワークの目標はある関数$f^*$を近似することである。例えば、分類器に対して、$y = f^*(\boldsymbol{x})$は入力$\boldsymbol{x}$をカテゴリ$y$に対応させる。フィードフォワードネットワークはマッピング$\boldsymbol{y} = f(\boldsymbol{x}; \boldsymbol{\theta})$を定義し、最良の関数近似となるパラメータ$\boldsymbol{\theta}$の値を学習する。
これらのモデルは、$\boldsymbol{x}$から計算される関数を通り、$f$を定義するのに使われる途中計算を通り、最終的に出力$\boldsymbol{y}$へ情報が流れるので、フィードフォワード[feedforward]と呼ばれる。モデルの出力がそれ自体に戻されるフィードバック[feedback]接続は存在しない。フィードフォワードニューラルネットワークがフィードバック接続を含むよう拡張されるとき、これらは、[@sec:10]で示されるように、リカレントニューラルネットワーク[recurrent neural networks]と呼ばれる。
フィードフォワードネットワークは機械学習の専門家にとって極めて重要である。これらは多くの重要な商用アプリケーションの基礎を形成する。例えば、写真からの物体認識で使われる畳み込みネットワークは特殊化された種類のフィードフォワードネットワークである。フィードフォワードネットワークはリカレントネットワークに至るための概念的な足がかり[stepping stone]である。これは多くの自然言語アプリケーションに力を与える。

フィードフォワードニューラルネットワークは、多数の様々な関数とともに構成することで一般に表現されるので、ネットワークと呼ばれる。そのモデルはどの関数がともに構成されるかを述べる有向非巡回グラフ[directed acyclic graph]と関連付けられる。例えば、$f(\boldsymbol{x}) = f^{(3)}(f^{(2)}(f^{(1)}(\boldsymbol{x})))$を形成するために、鎖状に接続される3つの関数$f^{(1)}$、$f^{(2)}$、$f^{(3)}$があるかもしれない。これらの鎖構造は最も一般的に使われるニューラルネットワークの構造である。この場合、$f^{(1)}$はネットワークの第一層[first layer]と呼ばれ、$f^{(2)}$は第二層と呼ばれ、以下同文。その鎖の全体の長さはモデルの深さ[depth]を与える。「深層学習」という名前はこの用語法により生じる。フィードフォワードネットワークの最後の層は出力層[output layer]と呼ばれる。ニューラルネットワークの訓練中では、$f(\boldsymbol{x})$を$f^*(\boldsymbol{x})$と一致させる。訓練データは異なる訓練点で計算される$f^*(\boldsymbol{x})$のノイジーで近似的なexamplesを提供する。各example$\boldsymbol{x}$にはラベル$y \approx f^*(\boldsymbol{x})$が伴う。訓練examplesは出力層が各点$\boldsymbol{x}$でしなければならないことを直接指定する。すなわち、$y$に近い値を生成しなければならないということである。他の層の振る舞いは訓練データによって直接指定されない。学習アルゴリズムは望ましい出力を生成するためにこれらの層の使い方を決定しなければならないが、訓練データはそれぞれ別個の層がすべきことを語らない。代わりに、学習アルゴリズムは$f^*$の近似を最もうまく実装するためにこれらの層の使い方を決めなければならない。訓練データはこれらの層のそれぞれに対して望ましい出力を示さないので、これらは隠れ層[hidden layers]と呼ばれる。
最後に、これらのネットワークは、これらが恐らく神経科学に触発されるので、ニューラルと呼ばれる。ネットワークの各隠れ層は一般にベクトル値的である。これらの隠れ層の次元はモデルの幅[width]を定める。ベクトルの各要素はニューロンに類似した役割を担うと解釈できるだろう。この層を単一のベクトルからベクトルへの関数を表現するとみなすのではなく、並列にそれぞれがベクトルからスカラへの関数を表現するように振る舞う多くのユニット[units]から成るとみなすこともできる。各ユニットは多くの他のユニットから入力を受け取り、自身の活性化の値を計算するという意味でニューロンに似ている。ベクトル値的な表現の多数の層を用いるというアイデアは神経科学から着想を得ている[be drawn from]。これらの表現を計算するのに使われる関数$f^{(i)}(\boldsymbol{x})$の選択もまた生物学的なニューロンが計算する関数についての神経学的な見解によって大まかに導かれる。しかしながら、近代的なニューラルネットワーク研究は多くの数学および工学の分野によって導かれ、ニューラルネットワークの目標は脳を完璧にモデル化することではない。脳の関数のモデルとしてではなく、脳について知っていることからいくつかの洞察を時折得て、統計的な汎化を達成するために設計された関数近似の機械としてフィードフォワードネットワークをみなすことは最も適当である。
フィードフォワードネットワークを理解する1つの方法は、線形モデルから始めて、これらの制限を克服する方法を考えることである。ロジスティック回帰や線形回帰のような線形モデルは、閉形式で、または、凸最適化に、のいずれかで効率的かつ確実にフィットさせることができるので、魅力的である。線形モデルは、モデル容量が一次関数に制限されるので、そのモデルが2つの入力変数の間の相互作用を理解できない、という明らかな欠陥も持つ。
線形モデルを$\boldsymbol{x}$の非線形関数を表現するよう拡張するためには、$\boldsymbol{x}$自体ではなく変換した入力$\phi(\boldsymbol{x})$に線形モデルを適用することができる。ここで、$\phi$は非線形な変換である。等価的に、我々は、$\phi$マッピングを暗黙的に適用することに基づいた非線形な学習アルゴリズムを得るために、[@sec:5.7.2]で述べられるカーネルトリックを適用できる。我々は$\phi$を、$\boldsymbol{x}$を述べる特徴の集合をもたらす、または、$\boldsymbol{x}$に対する新しい表現をもたらすとみなすことができる。
故に、疑問となるのはマッピング$\phi$を選択する方法である。

1. 1つの選択肢は、RBFカーネルに基づくカーネルマシンで暗黙的に用いられる無限次元の$\phi$のような、非常に汎用的な$\phi$を用いることである。$\phi(\boldsymbol{x})$が十分に高次元であるならば、我々は常に訓練セットにフィットするのに十分な容量を持つが、テストセットへの汎化はしばしばpoorなままである。非常に汎用的な特徴マッピングは通常、局所的な平滑さの原則にのみ基づき、発展的な問題を解くための十分な事前情報をエンコードしない。
2. もう1つの選択肢は$\phi$を手作業で設計することである。深層学習の到来までは、これが支配的なアプローチであった。音声認識やコンピュータビジョンのような異なる分野に特化した専門家によって、分野間をほとんど移ったりせずに、別個のタスクごとに何十年の労力を必要とする。
3. 深層学習の戦略は$\phi$を学習することである。このアプローチでは、モデル$y = f(\boldsymbol{x}; \boldsymbol{\theta}, \boldsymbol{w}) = \phi(\boldsymbol{x}; \boldsymbol{\theta})^\top \boldsymbol{w}$を持つ。我々はいま、関数の広範囲のクラスから$\phi$を学習するのに使うパラメータ$\boldsymbol{\theta}$、および、$\phi(\boldsymbol{x})$から望ましい出力へマッピングするパラメータ$\boldsymbol{w}$を持つ。これは隠れ層を定義する$\phi$を持つ深層フィードフォワードネットワークの例である。このアプローチは3つの中で唯一、訓練問題の凸性を断念するが、その益は害を上回る。このアプローチでは、$\phi(\boldsymbol{x}; \boldsymbol{\theta})$として表現をパラメータ化し、良い表現に対応する$\boldsymbol{\theta}$をもとめるために最適化アルゴリズムを用いる。望むならば、このアプローチは高度に汎用的にする、すなわち、非常に広範囲な仲間$\phi(\boldsymbol{x}; \boldsymbol{\theta})$を用いることでそれを行うことによって1番目のアプローチの利点を獲得できる。深層学習は二番目のアプローチの利点を獲得することもできる。人間の専門家はうまく処理するであろうと期待する仲間$\phi(\boldsymbol{x}; \boldsymbol{\theta})$を設計することによって汎化を助けるための知識をエンコードできる。この利点は人間の設計者が、正確に正しい関すを求めるのではなく、正しい一般的な関数の仲間を求める必要があるだけであるということである。

特徴を学習することによってモデルを改良するためのこの一般的な原則はこの章で述べられるフィードフォワードネットワーク以上に拡張される。これは本書を通して述べられるすべての種類のモデルに適用される深層学習の繰り返されるテーマである。フィードフォワードネットワークはフィードバック接続を欠いた$\boldsymbol{x}$から$\boldsymbol{y}$への決定論的なマッピングの学習に対してこの原則の応用である。後に示される他のモデルは確率的なマッピング、フィードバックを伴う関数、および、単一のベクトル上の確率分布の学習に対してこれらの原則を適用する。
我々は本章をフィードフォワードネットワークの単純な例から始める。次に、フィードフォワードネットワークを配備するために必要な設計上の決定のそれぞれを扱う。第一に、フィードフォワードネットワークを訓練することは線形モデルに対して必要なものと同じ設計上の決定の多く、すなわち、オプティマイザ、コスト関数、出力ユニットの形式を選択することを行う必要がある。我々はこれらの勾配ベースの学習の基礎を再調査し、続けて、フィードフォワードネットワークに固有の設計上の決定をのいくつかと突き合わせる。フィードフォワードネットワークが隠れ層の概念を導入したことで、我々は隠れ層の値を計算するのに使われるであろう活性化関数[activation functions]を選ぶ必要がある。また、ネットワークがどれだけの層を含むべきか、それらの層が互いにどのように接続すべきか、各層にどれだけのユニットがあるべきか、を含めて、ネットワークのアーキテクチャも設計しなければならない。深層ニューラルネットワークにおける学習は複雑な関数の勾配を計算する必要がある。我々は、これらの勾配を効率的に計算するために使うことができる、逆伝播[back-propagation]アルゴリズムとその近代的な一般化を示す。最後に、いくつかの歴史的な視点で閉める。

## 例：XORの学習

フィードフォワードネットワークのアイデアをより具体的にするため、我々は非常に単純なタスクに関する完全に機能するフィードフォワードネットワークの例、すなわち、XOR関数の学習から始める。
XOR（排他的論理和）関数は2つのバイナリ値$x_1$と$x_2$に関する操作である。これらのバイナリ値の1つだけが$1$に等しいとき、XOR関数は$1$を返す。そうでなければ、$0$を返す。XOR関数は学習したい目的関数$y = f^*(\boldsymbol{x})$をもたらす。我々のモデルは関数$y = f(\boldsymbol{x}; \boldsymbol{\theta})$をもたらし、我々の学習アルゴリズムは$f^*$にできるだけ似た$f$を作るためにパラメータ$\boldsymbol{\theta}$を適合させる。
この単純な例では、統計的な一般化について考えさせられることはないだろう。我々はネットワークが4つの点$\mathbb{X} = {[0, 0]^\top, [0, 1]^\top, [1, 0]^\top, \text{ and } [1, 1]^\top}$に関して正確に処理することを欲する。我々はこれらの点の4つすべてでネットワークを訓練するだろう。唯一の課題は訓練セットをフィットさせることのみである。
我々はこの問題を回帰問題として扱い、平均二乗誤差の損失関数を用いることができる。我々はこの例に対する計算をできるだけ単純化しようとしてこの損失関数を選んだ。実践的なアプリケーションでは、MSEは通常ではバイナリデータのモデル化に対して適切なコスト関数ではない。より適切なアプローチは[@6.2.2.2]で述べられる。
訓練セット全体で計算を行うとすると、MSEの損失関数は以下となる。

$$
J(\boldsymbol{\theta}) = \frac{1}{4} \sum_{\boldsymbol{x} \in \mathbb{X}} (f^*(\boldsymbol{x}) - f(\boldsymbol{x}; \boldsymbol{\theta}))^2
$$

すると、我々はモデルの形式$f(\boldsymbol{x}; \boldsymbol{\theta})$を選択しなければならない。$\boldsymbol{w}$と$b$から成る$\boldsymbol{\theta}$を持つ線形モデルを選択するとしよう。我々のモデルは以下であると定義される。

$$
f(\boldsymbol{x}; \boldsymbol{w}, b) = \boldsymbol{x}^\top \boldsymbol{w} + b
$$

我々は正規方程式を用いて$\boldsymbol{w}$と$b$に関する閉形式で$J(\boldsymbol{\theta})$を最小化できる。
正規方程式を解くと、$\boldsymbol{w} = \boldsymbol{0}$と$b = \frac{1}{2}$を得る。この線形モデルはいたるところで$0.5$を出力するだけである。なぜこんなことが起こるのだろう？[@fig:6.1]はなぜ線形モデルがXOR関数を表現できないかを示す。この問題を解決する1つの方法は線形モデルが解を表現できるような異なる特徴空間を学習するモデルを用いることである。

![表現を学習することでXOR問題を解く。プロット上に表示される太字の数字は学習した関数が各点で出力しなければならない値を示す。（左）元の値に直接適用した線形モデルはXOR関数を実装できない。$x_1 = 0$のとき、モデルの出力は$x_2$が増加するに従って増加しなければならない。$x_1 = 1$のとき、モデルの出力は$x_2$が増加するに従って減少しなければならない。線形モデルは固定の係数$w_2$を$x_2$に適用しなければならない。従って、その線形モデルは$x_2$に関する係数を変化させるために$x_1$の値を用いることができず、この問題を解くことができない。（右）ニューラルネットワークによって抽出された特徴で表現される変換した空間では、線形モデルはその問題を解くことができる。我々の解法の例では、$1$を出力しなければならない2つの点は特徴空間において単一の点に潰されてしまっている。別の言い方をすれば、その非線形な特徴は$\boldsymbol{x} = [1, 0]^\top$と$\boldsymbol{x} = [0, 1]^\top$の両方を特徴空間における単一の点$\boldsymbol{h} = [1, 0]^\top$にマッピングさせた。その線形モデルは$h_1$における増加と$h_2$における減少として関数を記述できる。この例では、特徴空間を学習することに対する動機は訓練セットにフィットできるようにモデル容量をより大きくすることのみである。より現実的なアプリケーションでは、学習した表現もまたモデルが汎化するのに役立ち得る。](fig/6-1.png){#fig:6.1}

具体的に言うと、我々は2つの隠れユニットを含む1つの隠れ層を持つ単純なフィードフォワードネットワークを導入するだろう。このモデルの図は[@fig:6.2]を参照のこと。このフィードフォワードネットワークは関数$f^{(1)}(\boldsymbol{x}; \boldsymbol{W}, \boldsymbol{c})$によって計算される隠れユニットのベクトル$\boldsymbol{h}$を持つ。そして、これらの隠れユニットの値は第二層に対する入力として使われる。第二層はネットワークの出力層である。出力層は依然として単なる線形回帰モデルであるが、いまや$\boldsymbol{x}$ではなく$\boldsymbol{h}$に適用されている。ネットワークはともに連鎖する2つの関数$\boldsymbol{h} = f^{(1)}(\boldsymbol{x}; \boldsymbol{W}, \boldsymbol{c})$と$f^{(2)}(\boldsymbol{h}; \boldsymbol{w}, b)$を含み、完全なモデルは$f(\boldsymbol{x}; \boldsymbol{W}, \boldsymbol{c}, \boldsymbol{w}, b) = f^{(2)}(f^{(1)}(\boldsymbol{x}))$となる。

![2つの異なるスタイルで描かれるフィードフォワードネットワークの例。具体的に、これはXORの例を解くのに使われるフィードフォワードネットワークである。これは2つのユニットを含む単一の隠れ層を持つ。（左）このスタイルでは、すべてのユニットをグラフにおけるノードとして描く。このスタイルは明示的で曖昧さがないが、この例より大きなネットワークに対しては、場所を取りすぎる可能性がある。（右）このスタイルでは、層の活性化を表現するベクトル全体ごとにグラフにおけるノードを描く。このスタイルは更にコンパクトである。時折、我々はこのグラフの辺に2つの層の間の関係を記述するパラメータの名前で注釈を付ける。ここでは、行列$\boldsymbol{W}$が$\boldsymbol{x}$から$\boldsymbol{h}$へのマッピングを記述し、ベクトル$\boldsymbol{w}$が$\boldsymbol{h}$から$y$へのマッピングを記述することを示す。我々は一般に、この種の図をラベル付けするとき、各層に関連付けられる切片パラメータを省略する。](fig/6-2.png){#fig:6.2}

$f^{(1)}$が計算すべき関数とは何だろうか？線形モデルはこれまで我々の役に立ってきたので、$f^{(1)}$を同様に線形にしたくなるかもしれない。残念ながら、$f^{(1)}$が線形であったならば、全体としてのフィードフォワードネットワークはその入力の一次関数をそのままにしただろう。今のところは切片項を無視して、$f^{(1)}(\boldsymbol{x}) = \boldsymbol{W}^\top \boldsymbol{x}$および$f^{(2)}(\boldsymbol{h}) = \boldsymbol{h}^\top \boldsymbol{w}$であるとする。故に、$f(\boldsymbol{x}) = \boldsymbol{x}^\top \boldsymbol{W} \boldsymbol{w}$である。我々は$\boldsymbol{w}' = \boldsymbol{W} \boldsymbol{w}$であるところの$f(\boldsymbol{x}) = \boldsymbol{x}^\top \boldsymbol{w}'$としてこの関数を表現できるだろう。
明らかに、我々は特徴を記述するための非線形な関数を用いなければならない。ほとんどのニューラルネットワークは学習したパラメータによって制御され、活性化関数と呼ばれる固定の非線形関数へと続くアフィン変換を用いてこれを行う。$\boldsymbol{h} = g(\boldsymbol{W}^\top \boldsymbol{x} + \boldsymbol{c})$を定義することによって、ここではその戦略を用いる。ここで、$\boldsymbol{W}$は線形変換の重みをもたらし、$\boldsymbol{c}$はバイアスをもたらす。以前に、線形回帰モデルを記述するため、入力ベクトルから出力スカラへのアフィン変換を記述するための重みのベクトルとスカラのバイアスのパラメータを用いた。いま、我々はベクトル$\boldsymbol{x}$からベクトル$\boldsymbol{h}$へのアフィン変換を記述するので、バイアスパラメータのベクトル全体が必要である。活性化関数$g$は一般に$h_i = g(\boldsymbol{x}^\top \boldsymbol{W}_{:,i} + c_i)$を用いて要素ごとに適用される関数となるように選ばれる。近代的なニューラルネットワークでは、既定のオススメは、[@fig:6.3]に図示される、$g(z) = \max{0, z}$によって定義されるrectified linear unitまたはReLU[@Jarrett2009; @Nair2010; @Glorot2011a]を用いることである。

![***](fig/6-3.png){#fig:6.3}

我々は以下として完全なネットワークを指定できる。

$$
***
$$
