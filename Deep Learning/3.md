# 確率論と情報理論

この章では、我々は確率論と情報理論を説明する。
確率論は不確かな命題を表現するための枠組みである。これは新しい不確かな命題を導出するための公理と同様に不確かさを定量化する方法をもたらす。人工知能アプリケーションにおいて、我々は2つの主要な方法で確率論を用いる。1つ目として、確率の法則はどのようにAIシステムが推論すべきかを教えてくれる。なので、我々は確率論を用いて導出された様々な式を計算または近似するためにアルゴリズムを設計する。2つ目として、我々は提案されたAIシステムの振る舞いを理論的に解析するために確率と統計を用いる事ができる。
確率論は科学や工学の多くの分野の基盤的なツールである。我々は、主にソフトウェア工学をバックグラウンドとし、確率論にあまり触れていない読者が本書の内容を理解できることを保証するためにこの章を提供する。
確率論は不確かな命題を作り、不確かさの中で推論することを可能にするが、情報理論は確率分布における不確かさの量を定量化することを可能にする。
あなたが確率論と情報理論にすでに親しみがある場合、機械学習に対する構造化された確率モデルを説明するのに使われるグラフを説明する[@sec:3.14]を除いてこの章を省略して構わまい。あなたがこれらの題材を以前にまったく経験したことがないならば、この章は深層学習の研究プロジェクトを成功裏に成し遂げるのに十分であるはずであるが、我々は、[@Jaynes2003]のような、追加の資料を調べることを提案する。

## なぜ確率なのか？

計算機科学の多くの分野は全体的に決定論的で確かなものをほぼ扱っている。プログラマは通常、CPUが各機械語を完璧に実行するであろうことを安全に仮定できる。ハードウェアの誤動作は起こるが、ほとんどのソフトウェアアプリケーションがそれらに対処するように設計される必要がないほどに稀である。多くの計算機科学者やソフトウェアエンジニアが比較的クリーンで確定的な環境で研究するとすれば、機械学習が確率論をかなり活用していることに驚くかもしれない。
機械学習は常に不確かな量と時折統計的（非決定論的）な量を扱わなければならない。不確かさや確率性は多くの源から発生し得る。研究者は少なくとも1980年代から確率を用いた不確かさの定量化に対する説得力のある議論を行ってきた。ここに示される言説の多くは[@Pearl1988]からまとめたり、触発されたりしている。
ほぼすべての活動は不確かさの中で推論を行う能力を必要とする。事実、定義により真である数学的な命題を超えて、完全に真である任意の命題や発生すると完全に保証される任意の事象を考えることは困難である。
取り得る不確かさの源は3つある。

1. モデル化されたシステムにおける生来の確率性。例えば、ほとんどの量子力学の解釈の亜原子粒子の力学を確率的であるとして説明する。我々は、カードが無作為な順序に真にシャッフルされる架空のカードゲームのような、無作為な力学を持つと仮定する理論的なシナリオを作ることもできる。
2. 不完全な観測可能性。決定論的なシステムであっても、そのシステムの振る舞いを操るすべての変数を観測できないとき、確率的になる可能性がある。例えば、モンティホール問題において、ゲーム番組の参加者は3つの扉から選ぶよう尋ねられ、選んだ扉の奥にある賞品を勝ち取る。2つの扉はヤギに当たるが、3つ目の扉は車に当たる。参加者の選択がもたらす結果は決定論的であるが、参加者視点から見れば、結果は不確かである。
3. 不完全なモデリング。観測した方法のいくつかを破棄しなければならないモデルを用いるとき、その破棄された情報は結果としてモデルの予測における不確かさとなる。例えば、周囲にあるすべての物体の位置を厳密に観測できるロボットを作るとする。ロボットがこれらの物体の未来の位置を予測するときに空間を離散化する場合、この離散化は即座にロボットを物体の正確な位置について不確かにさせる。つまり、各物体はそれが占めると観測された離散セル内の何処かにある可能性があるだろう。

多くの場合、その真の規則が決定論的であり、モデリングシステムが複雑な規則に適応できる可能性を持つ場合でさえ、複雑だが確かな規則よりも単純だが不確かな規則を用いるほうがより実践的である。例えば、単純な規則「ほとんどの鳥は飛ぶ」は発展させやすい[cheep to develop]、広く役に立つが、「飛ぶことをまだ習っていない非常に幼い鳥、飛ぶ能力を失った病気や怪我を負った鳥、ヒクイドリ、ダチョウ、キーウィを含むのべない種類の鳥、…などを除いて、鳥は飛ぶ」のような形式の規則は発展させたり、整備したり、対話したりすることが高価であり、これだけの手間をかけても、依然として脆く、間違いやすい。
我々が不確かさに関して表現したり推論したりする方法を必要とすることは明確なはずであるが、確率論が人工知能アプリケーションに対して我々が欲するツールのすべてをもたらすことができることは一瞥して明らかではない。確率論はもともと事象の頻度を解析するために開発された。どうやって確率論がポーカーにおいてあるカードを引くような事象を研究するのに使うことができるかは理解しやすい。これらの種類の事象はしばしば繰り返し行うことができる。結果が発生する確率$p$を持つとすると、これは、その実験（例えば、カードを1枚引く）を無限に多い回数だけ繰り返した場合、その繰り返しの$p$の割合だけその結果になるであろうことを意味する。この種の推論は繰り返し行うことができない命題に即座に応用できるようには見えない。医者が患者を診る場合、その患者が40%の確率でインフルエンザに罹っているとすると、これは非常に異なる何かを意味する。つまり、我々は無限に多くの患者の複製を作ることはできないし、異なる患者の複製が同じ症状を示しながらも様々な基礎疾患を持つと理解する理由はまったくない。医者が患者を診察するケースでは、患者がインフルエンザであるという完全な確かさを示す1と患者がインフルエンザでないという完全な確かさを示す0によって、degree of belief[直観的信頼度]を表現するために確率を用いる。前者の種類の確率は、どの事象が起こるかを示す割合に直接的に関連付けられて、frequentist probability[頻度論者的確率]として知られ、一方、後者は、確かさの定質的な度合いに関連付けられて、ベイズ確率[Bayesian probalibity]として知られる。
我々が持つべき不確かについて推論する共通の感覚を期待するいくつかの特性をリスト化するならば、これらの特性を満たす唯一の方法はベイズ確率をfrequentist probabilitiesと同じくらい厳密に振る舞うとして扱うことである。例えば、あるカードの集合があるとしてポーカーに勝つであろう確率を計算したい場合、ある症状を持つとして患者が疾患を持つ確率を計算するときと厳密に同じ数式を用いる。共通感覚の仮定の小集合が、同じ定理が両方の種類の確率を制御しなければならない、ということを暗示する理由についての詳細は[@Ramsey1926]を参照のこと。
確率は不確かさを取り扱うための論理の拡張として理解できる。論理は、いくつかの他の命題の集合が真か偽であると仮定するとして、どの命題が真か偽であると暗示するかを決定するための形式的な規則の集合をもたらす。確率論は、他の命題の可能性を考慮して、真となる命題の可能性を決定するための形式的な規則の集合を提供する。

## 確率変数

確率変数[random variable]は無作為に異なる値を取ることができる変数である。我々は一般に確率変数それ自体を小文字のプレーンな書体で表記し、その取り得る値を小文字の筆記体で表記する。例えば、$x_1$や$x_2$は共に確率変数$\mathbf{x}$が取り得る可能性のある値である。ベクトル値変数では、確率変数を$\mathbf{x}$と記述し、その値のひとつを$\boldsymbol{x}$と記述するだろう。それ自体では、確率変数は単に取りうる状態の説明でしかない。これらの状態のそれぞれがどれだけの可能性を持つかを指定する確率分布と組み合わせなければならない。
確率変数は離散的でも連続的でもあって良い。離散的な確率変数は有限または加算無限な状態数を持つものである。これらの状態は整数である必要はないことに注意する。つまり、これらはいずれかの数値的な値を持つとはみなされない名前付き状態であるとすることもできる。連続的な確率変数は実数に関連する。

## 確率分布

確率分布[probability distribution]は確率変数または確率変数の集合がその取り得る状態のそれぞれをどの程度の確率で取るかについての説明である。確率分布を説明する方法はその変数が離散的か連続的かのどちらであるかに依存する。

### 離散的変数と確率質量関数

離散的な変数上の確率分布は確率質量関数[probability mass function; PMF]を用いて説明できるだろう。我々は一般に確率質量関数を大文字の$P$で表記する。しばしば、我々はそれぞれの確率変数を異なる確率質量関数に関連付けるので、読者は関数の名前ではなく確率変数の同一性に基づいてどのPMFを用いるかを推察しなければならない。つまり、$P(\mathbf{x})$は通常、$P(\mathbf{y})$と同じではない。
確率質量関数は確率変数の状態からその状態を取る確率変数の確率にマッピングする。$\mathbf{x} = x$である確率は、$\mathbf{x} = x$が確実であることを示す確率1と$\mathbf{x} = x$が不可能である確率0によって、$P(\mathbf{x})$と表記される。時折どのPMFを用いるかを明確にするため、我々は確率変数の名前を、$P(\mathbf{x} = x)$のように、明示的に書き記す。時折、$\mathbf{x} \sim P(\mathbf{x})$のように、はじめに変数を定義して、あとでどの分布に従うかを指定する表記法$\sim$を用いる。
確率質量関数は同時に多くの変数に作用し得る。そのような多くの変数上での確率分布は同時確率分布[joint probability distribution]として知られる。$P(\mathbf{x} = x, \mathbf{y} = y)$は同時に$\mathbf{x} = x$かつ$\mathbf{y} = y$である確率を表記する。我々は省略して$P(x, y)$とも記述するだろう。
確率変数$\mathbf{x}$上のPMFとなるため、関数$P$は以下の特性を満たさなければならない。

- $P$の領域は$\mathbf{x}$の取り得るすべての状態の集合でなければならない。
- $\forall_x \in \mathbf{x}, 0 \le P(x) \le 1$である。不可能な事象は確率0を持ち、状態はそれより小さな確率を取り得ない。同様に、起こることが保証される事象は確率1を持ち、状態はそれ以上の発生確率を取り得ない。
- $\sum_{x \in \mathbf{x}} P(x) = 1$である。我々はこの特性を正規化されている[normalized]と呼称する。この特性がないと、発生する多くの事象のひとつの確率を計算することで1より大きい確率が得られてしまうかもしれない。

例えば、$k$個の異なる状態を持つ離散的な確率変数$\mathbf{x}$が1つあるとする。我々は、すべての$i$に対してPMFを以下のように設定することで、各状態を均等な確率にする一様分布[uniform distribution]を$\mathbf{x}$上に配置する事ができる。

$$
P(\mathbf{x} = x_i) = \frac{1}{k}
$$

我々はこれが確率質量関数のための必要条件に合致することを確認できる。値$\frac{1}{k}$は、$k$が正の整数であるので、正である。以下であることも確かめられる。

$$
\sum_i P(\mathbf{x} = x_i) = \sum_i \frac{1}{k} = \frac{k}{k} = 1
$$

すなわち、この分布は適切に正規化されている。

### 連続的変数と確率密度関数

連続的な確率変数で行うとき、我々は確率質量関数ではなく確率密度関数[probability density function; PDF]を用いて確率分布を説明する。確率密度関数であるために、関数$p$は以下の特性を満たさなければならない。

- $p$の領域は$\mathbf{x}$のすべての取りうる状態の集合でなければならない。
- $\forall x \in \mathbf{x}, p(x) \ge 0$である。$p(x) \le 1$である必要がないことに注意する。
- $\int p(x)dx = 1$である。

確率密度関数$p(x)$は特定の状態の確率を直接的に求めない。そのかわりに、ボリューム$\delta x$を持つ無限小領域の中に乗る確率は$p(x) \delta x$で求められる。
我々は点の集合の実際の確率質量を求めるためにその密度関数を積分できる。具体的には、$x$がある集合$\mathbb{S}$に含まれる確率はその集合の上での$p(x)$の積分によって求められる。単変量の例[univariate example]では、$x$が区間$[a, b]$に含まれる確率は$\int_{[a, b]} p(x)dx$で求められる。
連続的な確率変数の上での特定の確率密度に対応するPDFの例では、実数の区間における一様分布とみなす。我々はこれを関数$u(x; a, b)$で行うことができる。ここで、$a$と$b$は、$b > a$となる、その区間の端点であり、"$;$"の表記法は「それによって「パラメータ化される」ことを意味する。つまり、$x$を関数の引数とみなす一方で、$a$と$b$はその関数を定義するパラメータである。区間の外に確率質量が存在しないことを保証するため、すべての$x \notin [a, b]$に対して$u(x; a, b) = 0$であるとする。$[a, b]$の内部では、$u(x; a, b) = \frac{1}{b-a}$である。我々は$\mathbf{x} \sim U(a, b)$と記述することで$x$が$[a, b]$上の一様乱数に従うことをしばしば表記する。

## 周辺確率

時折、我々は変数の集合上の確率分布を知っていて、それらの部分集合上の確率分布を知りたくなる時がある。その部分集合上の確率分布は周辺確率分布[marginal probability distribution]として知られる。
例えば、離散的な確率変数$\mathbf{x}$と$\mathbf{y}$があり、$P(\mathbf{x}, \mathbf{y})$が既知であるとする。和の法則[sum rule]によって$P(\mathbf{x})$を求めることができる。

$$
\forall x \in \mathbf{x}, P(\mathbf{x} = x) = sum_y P(\mathbf{x}$ = x, $\mathbf{y} = y)
$$

「周辺確率」という名前は紙の上で周辺確率を計算する手順に由来する。$P(\mathbf{x}, \mathbf{y})$の値が格子状に、横に$x$の値を取り、縦に$y$の値を取って書かれるとき、その格子の1行を合計し、その後、その行の右側の余白に$P(x)$を書くことは自然なことである。
連続的な変数では、総和の代わりに積分を用いる必要がある。

$$
p(x) = \int p(x, y) dy
$$

## 条件付き確率

多くの場合、ある他の事象が発生したときのある事象の確率に関心がある。これは条件付き確率[conditional probability]と呼ばれる。我々は$\mathbf{x} = x$としたときの$\mathbf{y} = y$の条件付き確率を$P(\mathbf{y} = y | \mathbf{x} = x)$と表記する。この条件付き確率は以下の式で計算できる。

$$
P(\mathbf{y} = y | \mathbf{x} = x) = \frac{P(\mathbf{y} = y, \mathbf{x} = x)}{P(\mathbf{x} = x)}
$$

この条件付き確率は$P(\mathbf{x} = x) \ge 0$であるときにのみ定義される。我々は一切起こらない事象を条件とする条件付き確率を計算できない。
重要なことは、ある行動が行われる場合に起こるであろうことの計算と条件付き確率を混同しないことである。人々がドイツ語を話すとしたときにある人がドイツ出身である条件付き確率は極めて高いが、無作為に選ばれた人がドイツ語を話すと教わったとしても彼らの生まれた国は変化しない。行動の結論を計算することはintervention queryを作ると呼ばれる。intervention queriesは、本書では深掘りしないcausal modelingの領域である。

## 条件付き確率の連鎖律

多数の確率変数上の同時確率分布は単独の変数上の条件付き分布に分解できるだろう。

$$
P(\mathbf{x}^{(1)}, \dots, \mathbf{x}^{(n)}) = P(\mathbf{x}^{(1)}) \prod_{i=2}^n P(\mathbf{x}^{(i)} | \mathbf{x}^{(1)}, \dots, \mathbf{x}^{(i-1)})
$$

この結果は確率の連鎖律[chain rule]とか積の法則[product rule]として知られる。これは[@eq:3.5]における条件付き確率の定義により即座に従う。

例えば、定義を2回適用すると、以下を得る。

$$
P(a, b, c) = P(a | b, c) P(b, c) \\
P(b, c) = P(b | c) P(c) \\
P(a, b, c) = P(a | b, c) P(b | c) P(c)
$$

## 独立と条件付き独立

2つの確率変数$\mathbf{x}$と$\mathbf{y}$は、これらの確率分布が、1つは$\mathbf{x}$のみを伴い、1つは$\mathbf{y}$のみを伴うような、2つの因数の積として説明できる場合、独立[independent]である。

$$
\forall x \in \mathbf{x}, y \in \mathbf{y}, p(\mathbf{x} = x, \mathbf{y} = y | \mathbf{z} = z) = p(\mathbf{x} = x | \mathbf{z} = z) p(\mathbf{y} = y | \mathbf{z} = z)
$$

我々はコンパクトな表記法で独立と条件付き独立を表記できる。すなわち、$\mathbf{x} \perp \mathbf{y}$は$\mathbf{x}$と$\mathbf{y}$が独立であることを意味し、$\mathbf{x} \perp \mathbf{y} | \mathbf{z}$は$\mathbf{x}$と$\mathbf{y}$が$\mathbf{z}$を仮定したときに条件付き独立であることを意味する。

## 期待値、分散、共分散

確率分布$P(\mathbf{x})$に関するある関数$f(x)$の期待値[expectation or expected value]とは$x$が$P$によって描かれるときに$f$が取る平均値である。離散的な変数では、これは総和で計算できる。

$$
\mathbb{E}_{\mathbf{x} \sim P} \left[ f(x) \right] = \sum_x P(x) f(x)
$$

一方、連続的な変数では、積分で計算される。

$$
\mathbb{E}_{\mathbf{x} \sim p} \left[ f(x) \right] = \int p(x) f(x) dx
$$

分布の同一性がその文脈から明らかであるとき、我々は、$\mathbb{E}_{\mathbf{x}} [f(x)]$にあるように、期待値がその上にある確率変数の名前を単に記すことができるだろう。期待値がどの確率変数の上にあるかが明らかであるならば、我々は、$\mathbb{E}[f(x)]$にあるように、下付き文字全体を省略することができるだろう。デフォルトでは、我々は$\mathbb{E}[\cdot]$が括弧内のすべての確率変数の値の上で平均すると仮定できる。同様に、曖昧さが存在しないとき、角括弧を省略できるだろう。
例えば以下のように、$\alpha$と$\beta$が$x$に依存しないとき、期待値が線形である。

$$
\mathbb{E}_{\mathbf{x}} [\alpha f(x) + \beta g(x)] = \alpha \mathbb{E}_{\mathbf{x}} [f(x)] + \beta \mathbb{E}_{\mathbf{x}} [g(x)]
$$

分散[varianvce]は、その確率分布から様々な$x$の値をサンプルすることによって、確率変数$\mathbf{x}$の関数の値がどれだけ変化するかについての値をもたらす。

$$
\text{Var} \left( f(x) \right) = \mathbb{E} \left[ (f(x) - \mathbb{E}[f(x)])^2 \right]
$$

分散が低いとき、$f(x)$の値は分散の期待値の近くに集まる。分散の平方根は標準偏差[standard deviation]として知られる。
共分散[covariance]は、それらの変数の大きさと同様に、2つの値がどれだけお互いに線形に関連しているかのある感覚をもたらす。

$$
\text{Cov}(f(x), g(y)) = \mathbb{E}[(f(x) - \mathbb{E}[f(x)]) (g(y) - \mathbb{E}[g(y)])]
$$

共分散の絶対値が大きいことは、その値が大きく変化することと、個々の平均がかけ離れていることを同時に意味する。共分散の符号が正である場合、両方の変数は同時に比較的高い値を取る傾向にある。共分散の符号が負である場合、片方の変数が比較的高い値を取り、それと同時にもう片方が比較的低い値を取る傾向にある。相関[correlation]のようなその他の値は、別個の変数の大きさに影響されるのではなく、変数がどれだけ関連するかのみを計測するために各変数の寄与を正規化する。
共分散と従属の考え[notion]は関連しているが、明らかに別の概念である。これらは、独立である2つの変数がゼロの共分散を持ち、非ゼロの共分散を持つ2つの変数が従属であるので、関連している。ゼロの共分散を持つ2つの変数に対して、それらの間では線形従属であってはならない。独立は非線形な関連性も除外するので、独立はゼロの共分散よりも強力な必要条件である。2つの変数が従属であるがゼロの共分散を持つことは可能である。例えば、区間$[-1, 1]$上の一様乱数から実数$x$をまずサンプルするとしよう。その次に確率変数$s$をサンプルする。確率$\frac{1}{2}$では、$s$の値を$1$になるように選ぶ。そうでなければ、$s$を$-1$になるように選ぶ。すると、$y = sx$と代入することで確率変数$y$を作り出すことができる。明らかに、$x$は$y$の大きさを完全に決定するので、$x$と$y$は独立ではない。しかし、$\text{Cov}(x,y) = 0$である。
random vector $\boldsymbol{x} \in \mathbb{R}^n$の共分散行列[covariance matrix]は以下ような$n \times n$行列である。

$$
\text{Cov}(\boldsymbol{\mathbf{x}})_{i,j} = \text{Cov}(\mathbf{x}_i, \mathbf{x}_j)
$$

共分散の対角成分は分散を与える。

$$
\text{Cov}(\mathbf{x}_i, \mathbf{x}_i) = \text{Var}(\mathbf{x}_i)
$$

## 一般的な確率分布

いくつかの単純な確率分布は機械学習において多くの状況でゆうようである。

### ベルヌーイ分布

ベルヌーイ分布[Bernoulli distribution]は単一の二値の確率変数の上の分布である。これは、$1$に等しい確率変数の確率をもたらす、単一のパラメータ$\phi \in [0, 1]$によって制御される。

$$
P(\mathbf{x} = 1) = \phi
$$

$$
P(\mathbf{x} = 0) = 1 - \phi
$$

$$
P(\mathbf{x} = x) = \phi^x (1 - \phi)^{1 - x}
$$

$$
\mathbb{E}_{\mathbf{x}} [\mathbf{x}] = \phi 
$$

$$
\mathbb{Var}_{\mathbf{x}}(\mathbf{x}) = \phi (1 - \phi)
$$

### Multinoulli分布

multinoulli分布またはcategorical分布は$k$個の異なる状態を持つ単一の離散変数の上の分布である。ここでの$k$は有限である[^1]。multinoulli分布はベクトル$\boldsymbol{p} \in [0, 1]^{k - 1}$によってパラメータ化される。ここで、$p_i$は$i$番目の状態の確率をもたらす。最後の$k$番目の状態の確率は$1 - \boldsymbol{1}^\top \boldsymbol{p}$で求められる。$\boldsymbol{1}^\top \boldsymbol{p} \le 1$に制限しなければならないことに注意する。multinoulli分布はしばしば対象の分類の上での分布と言うのに使われる。なので、我々は通常、状態の1が数値の1を持つと仮定しない。2以降も同様である。この理由により、我々は通常、multinoulli分布に従う確率変数の期待値および分散を計算する必要はない。

[^1]: "multinoulli"はGustavo Lacerdaによって最近になって作られ、@Murphy2012によって広まった用語である。multinoulli分布は多項分布[multinomial distribution]の特別な場合である。多項分布は、$n$個のサンプルがmultinoulli分布から描かれるとき、$k$個の分類のそれぞれが何回現れるかを表す${0, \dots, n}^k$におけるベクトル上の分布である。多くのテキストは、$n = 1$の場合のみを指していることを明確にしないままmultinoulli分布を指すために"multinomial"の語を用いている。

ベルヌーイ分布とmultinoulli分布はこれらの領域上の任意の分布を述べるのに十分である。これらは、特に強力であるという理由からではなく、むしろ領域が単純であるという理由から、これらの領域上の任意の分布を記述できる。つまり、これらはすべての状態を列挙することが実現可能であるような離散変数をモデル化する。連続変数を扱うとき、数えられないほど多くの状態が存在する。なので、少数のパラメータで記述される任意の分布はその分布に厳格な制限を課さなければならない。

### ガウス分布

最も一般的に用いられる実数上の分布は正規分布[normal distribution]であり、ガウス分布[Gaussian distribution]としても知られる。

$$
\mathcal{N}(x; \mu, \sigma^2) = \sqrt{\frac{1}{2 \pi \sigma^2}} \exp \left( -\frac{1}{2\sigma^2}(x - \mu)^2 \right)
$$

正規分布の密度関数のプロットは[@fig:3.1]を参照のこと。

![正規分布。正規分布$\mathcal{N}(x; \mu, \sigma^2)$は、$\mu$により与えられる中央ピークの$x$座標と$\sigma$により制御されるピークの幅を持つ、古典的な「釣鐘」型を示す。この例では、$\mu = 0$と$\sigma = 1$を持つ標準正規分布[standard normal distribution]を図示する。](fig/3-1.png){#fig:3.1}


2つのパラメータ$\mu \in \mathbb{R}$と$\sigma \in (0, \infty)$は正規分布を制御する。パラメータ$\mu$は中央のピークの座標を与える。これは分布の平均でもある。つまり、$\mathbb{E}[\mathbf{x}] = \mu$である。分布の標準偏差は$\sigma$によって求められ、分散は$\sigma^2$によって求められる。
PDFを計算するとき、$\sigma$を逆二乗する必要がある。様々なパラメータの値でPDFを頻繁に計算する必要があるとき、分布をパラメータ化するより効率的な方法は、分布の精度[precision]または逆分散を制御するためにパラメータ$\beta \in (0, \infty)$を用いることである。

$$
\mathcal{N}(x; \mu, \beta^{-1}) = \sqrt{\frac{\beta}{2 \pi}} \exp \left( -\frac{1}{2} \beta (x - \mu)^2 \right)
$$

正規分布は多くのアプリケーションに対して賢い選択である。実数上の分布がどんな形状を取るべきかについての事前知識がない場合、正規分布は2つの主な理由により良いデフォルトの選択肢である。
1つ目として、モデル化したい多くの分布は正規分布に本当に近い。中心極限定理[central limit theorem]は、多数の独立した確率変数の総和がほとんど正規分布的であることを示す。これは、実践において、その系がより構造的な振る舞いを持つ部分に分解できるとしても、多くの複雑系が正規分布的な雑音でうまくモデル化できることを意味する。
2つ目として、同じ分散を持つすべての取り得る確率分布の中から、正規分布は実数上での最大の不確かさの量をエンコードする。故に、我々は正規分布をモデルに最低限の事前知識を挿入するようなものとみなすことができる。このアイデアを十分に発展させて正しく述べるには、より多くの数学的ツールを必要とする。そして、それは[@sec:19.4.2]に譲る。
正規分布は$\mathbb{R}^n$に一般化する。その場合、これは多変量正規分布[multivariate normal distribution]として知られる。これは正定値対称行列$\Sigma$でパラメータ化することができるだろう。

$$
\mathcal{N}(\boldsymbol{x}; \boldsymbol{\mu}, \boldsymbol{\Sigma}) = \sqrt{\frac{1}{(2\pi)^n \det(\Sigma)}} \exp \left( -\frac{1}{2}(\boldsymbol{x} - \boldsymbol{\mu})^\top \Sigma^{-1}(\boldsymbol{x} - \boldsymbol{\mu}) \right)
$$

パラメータ$\boldsymbol{\mu}$は依然として分布の平均を与えるが、今回はベクトル値的である。パラメータ$\boldsymbol{\Sigma}$は分布の共分散行列を与える。単変量の場合と同様に、多数の異なるパラメータの値で数回だけPDFを計算したいとき、PDFを計算するために$\boldsymbol{\Sigma}$の逆行列を必要とするので、その共分散は分布をパラメータ化する計算上効率的な方法ではない。代わりに、我々は精度行列[precision matrix]$\beta$を用いることができる。

$$
\mathcal{N}(\boldsymbol{x}; \boldsymbol{\mu}, \boldsymbol{\beta}^{-1}) = \sqrt{\frac{\det(\beta)}{(2\pi)^n}} \exp \left( -\frac{1}{2}(\boldsymbol{x} - \boldsymbol{\mu})^\top \beta(\boldsymbol{x} - \boldsymbol{\mu}) \right)
$$

我々はしばしば共分散行列を対角行列に修正する。更に単純なバージョンは等方[isotropic]ガウス分布である。これの共分散行列は単位行列のスカラ倍である。

### 指数分布とラプラス分布

深層学習の文脈では、我々はしばしば$x = 0$でシャープな点を持つ確率分布を持つことを欲する。これを達成するためには、指数分布[exponential distribution]を用いることができる。

$$
p(x; \lambda) = \lambda \boldsymbol{1}_{x \ge 0} \exp(-\lambda x)
$$

指数分布はすべての$x$の負の値に確率0を割り当てるために指示関数[indicator function]$\boldsymbol{1}_{x \ge 0}$を用いる。
任意の点$\mu$に確率質量の鋭いピークを配置することができる、密接に関係している確率分布はラプラス分布[Laplace distribution]である。

$$
\text{Laplace}(x; \mu, \gamma) = \frac{1}{2\gamma} \exp \left( -\frac{|x - \mu|}{\gamma} \right)
$$

### ディラック分布と経験分布

いくつかの場合、確率分布におけるすべての質量が単一の点の周りに集まることを特定したい。これはディラックのデルタ関数[Dirac delta function]$\delta(x)$を用いるPDFを定義することで達成できる。

$$
p(x) = \delta(x - \mu)
$$

ディラックのデルタ関数は、0地点以外をすべてゼロとするが、積分すると1になるように定義される。ディラックのデルタ関数は、各値$x$を実数値の出力に関連付ける普通の関数ではなく、積分されたときの特性に関して定義される超関数[generalized function]と呼ばれる異なる種類の数学的対象である。我々はディラックのデルタ関数をゼロ以外のすべての点でいっそう低密度になる一連の関数の極限点であるとみなせる。
$p(x)$を$-\mu$だけずらした$\delta$であると定義することで、$x = \mu$に確率密度の無限に狭く無限に高いピークを得る。
ディラックのデルタ分布の一般的な使い方は経験分布[empirical distribution]の構成要素として使うことである。

$$
p^\hat(\boldsymbol{x}) = \frac{1}{m} \sum_{i = 1}^m \delta(\boldsymbol{x} - \boldsymbol{x}^{(i)})
$$

これは、$m$個の点$\boldsymbol{x}^{(1)}, \dots, \boldsymbol{x}^{(m)}$のそれぞれに確率質量$\frac{1}{m}$として、与えられたデータセットやサンプルの集合を形成する。ディラックのデルタ分布は連続変数の上での経験分布を定義するためだけに必要である。離散変数では、状況はより単純である。つまり、経験分布は、訓練セットにある値のempirical frequencyに等しいようなそれぞれの取り得る入力値に関連する確率を持つmultinoulli分布として概念化できる。
我々は訓練examplesのデータセットから形成される経験分布をこのデータセットでモデルを訓練するときにサンプルされる分布を指定することみなせる。経験分布に対するもうひとつの重要な視点は、それが訓練データの可能性を最大化する確率密度であるということである（[@sec:5.5]を参照）。

### 分布の混合

他の更に単純な確率分布を組み合わせることで確率分布を定義することもまた一般的である。分布を組み合わせる一般的な方法のひとつは混合分布[mixture distribution]を構築することである。混合分布はいくつかの成分分布[component distributions]から作られる。各試行で、どの成分分布がサンプルを生成すべきかの選択はmultinoulli分布からcomponent identityをサンプルすることで決定される。

$$
P(\mathbf{x}) = \sum_i P(c = i) P(\mathbf{x} | c = i)
$$

ここで、$P(c)$はcomponent identities上のmultinoulli分布である。
我々はすでに混合分布の例のひとつを見てきている。つまり、実数値の変数上の経験分布は訓練exampleごとに1つのディラック成分を持つ混合分布である。
混合モデルはよりリッチな分布を生成するために確率分布を組み合わせるための単純な戦略のひとつである。[@sec:16]では、我々は単純な確率分布から複雑な確率分布を作る術をより詳細に調査する。
混合モデルは後に最も重要になるであろう概念、すなわち、潜在変数[latent variable]を簡単に垣間見ることができる。潜在変数は直接には観察できない確率変数である。混合モデルのcomponent identity変数$c$は1つのexampleをもたらす。潜在変数はその同時分布を介する$\mathbf{x}$に関連され得るだろう。この場合、$P(\mathbf{x}, c) = P(\mathbf{x} | c) P(c)$である。潜在変数上の分布$P(c)$と潜在変数を可視の変数に関連させる分布$P(\mathbf{x} | c)$は、潜在変数に関連させずに$P(\mathbf{x})$を記述することができるとしても、分布$P(\mathbf{x})$の形状を決定する。潜在変数は[@sec:16.5]にてさらに触れる。
非常に強力で一般的な混合モデルの種類は、成分$p(\boldsymbol{\mathbf{x}} | c = i)$がガウシアンである混合ガウスモデル[Gaussian mixture model]である。各成分は平均$\boldsymbol{\mu}^{(i)}$と共分散$\boldsymbol{\Sigma}^{(i)}$を個別にパラメータ化している。いくつかの混合モデルはさらなる制約を持つことができる。例えば、共分散は制約$\boldsymbol{\Sigma}^{(i)} = \boldsymbol{\Sigma}, \forall i$を介して成分の間で共有させる事ができる。単一のガウス分布と同様に、ガウス分布の混合モデルは各成分の共分散行列を対角か等方に制限する。
平均と共分散に加えて、ガウス混合モデルは各成分$i$に与えられる事前確率[prior probability]$\alpha_i = P(c = i)$を指定する。「事前」の語は$\boldsymbol{\mathbf{x}}$を観測する前に$c$についてのモデルのbeliefを説明することを指している。対して、$P(c | \boldsymbol{x})$は、$\boldsymbol{\mathbf{x}}$の観測後に計算されるので、事後確率[posterior probability]である。混合ガウス分布は、任意のなめらかな密度が十分な成分を持つ混合ガウス分布によって任意の特定の非ゼロの誤差量で近似できるという意味で、密度の普遍的近似[universal approximator]である。
[@fig:3.2]は混合ガウス分布によるサンプルを示す。

![混合ガウス分布によるサンプル。この例では、3つの成分がある。左から右に、1番目の成分は等方共分散行列を持ち、各方向に同じ量の分散を持つことを意味する。2番目の成分は対角共分散行列を持ち、それぞれの軸に平行な方向に沿って別個に分散を制御できることを意味する。3つ目の成分は最大階数を持つ[full-rank]共分散行列を持ち、任意の方向の基底に沿って別個に分散を制御することができる。](fig/3-2.png){#fig:3.2}

## 一般的な関数の有用な特性

確率分布で、特に深層学習モデルで使われる確率分布で、作業を行っていると、しばしば、ある関数たちが現れる。
これらの関数のひとつはlogistic sigmoidである。

$$
\sigma(x) = \frac{1}{1 + \exp(-x)}
$$

logistic sigmoidは、その範囲が$(0, 1)$であるので、ベルヌーイ分布の$phi$パラメータを生み出す。これは、$\phi$パラメータに対する有効な値の範囲内に置かれる。sigmoid関数のグラフについては[@fig:3.3]を参照のこと。sigmoid関数はその引数が非常に大きな正の値または非常に大きな負の値であるときに飽和[saturate]する。これは、この関数が非常に平坦で入力における小さな変化に鈍感であることを意味している。
もうひとつの一般に遭遇する関数はsoftplus関数である[@Dugas2001]。

![logistic sigmoid関数](fig/3-3.png){#fig:3.3}

$$
\zeta(x) = \log(1 + \exp(x))
$$

softplus関数は、その範囲が$(0, \infty)$であるので、正規分布の$\Beta$または$\sigma$パラメータを生み出すのに有用となり得る。これはsigmoidを伴う数式を操作するときにも普通に発生する。softplus関数の名前は以下の滑らかなバージョンとか"ソフト"なバージョンであるという事実に由来する。

$$
x^+ = \max(0, x)
$$

softplus関数のグラフについては[@fig:3.4]を参照のこと。

![softplus関数](fig/3-4.png){#fig:3.4}

以下の特性は暗記したくなるほどにすべてが有用である。

$$
$$
