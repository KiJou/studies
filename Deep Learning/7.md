# 深層学習のための正則化

機械学習における中心的問題はどのようにして訓練データだけでなく新しい入力に関してもうまく働くであろうアルゴリズムを作るかである。機械学習で使われる多くの戦略は、おそらく訓練誤差の増加という犠牲を払って、テスト誤差を減らすために明示的に設計されている。これらの戦略はまとめて正則化として知られている。深層学習の実践者は非常に多くの形式の正則化を利用できる。実際、より効果的な正則化戦略の開発はこの分野における主要な研究成果のひとつとなっている。
[@sec:5]では汎化、アンダーフィッティング、オーバーフィッティング、バイアス、分散、正則化の基本概念を紹介した。あなたが未だこれらの概念に親しんでいないならば、本章を読み進める前にその章を参照してほしい。
本章では、深層モデルや深層モデルを形成するための構成部品として用いられるかもしれないモデルに焦点を当てて、より詳細に正則化を述べる。
本章のいくつかの節は機械学習における標準的な概念を扱う。あなたが既にこれらの概念に親しんでいるならば、関連する節を読み飛ばしてもらって一向に構わない。しかし、本章のほとんどはニューラルネットワークの特定のケースへのこれらの基本概念の拡張と関係している。
[@sec:5.2.2]では、我々は「訓練誤差ではなく汎化誤差を減らすよう意図された学習アルゴリズムに施すいずれかの修正」として正則化を定義した。正則化戦略は多数存在する。あるものは、パラメータの値に制限を加えるような、追加の制約を機械学習モデルにもたらす。あるものはパラメータの値のsoft constraintに対応すると考えることができる追加の項を目的関数に加える。慎重に選ばれれば、これらの追加の制約や罰則はテストセットにおいて改善されたパフォーマンスを引き起こし得る。ある時には、これらの制約や罰則は特定の種類の事前知識をエンコードするために設計される。またある時には、これらの制約や罰則は汎化を促進させるためにより単純なモデルのクラスに対する一般的な選好を表現するために設計される。時折、罰則や制約はunderdetermined problemをdeterminedにするのに必要である。アンサンブル法として知られる他の形式の正則化は訓練データを説明する複数の仮説を組み合わせる。
深層学習の文脈では、ほとんどの正則化戦略は推定器を正則化することに基づいている。推定器の正則化はバイアスの増加を分散の低減とトレードすることで行われる。効果的なregularizerは、分散を大幅に低減しつつバイアスを過度に増やさない、有利なトレード[profitable trade]を行うものである。[@sec:5]で汎化とオーバーフィッティングを考察したとき、我々は3つの状況に焦点を当てた。これは、訓練されるモデル族が（１）真のデータ生成過程を除外した --- アンダーフィットすることとバイアスを含めることに対応する --- か、（２）真のデータ生成過程に一致したか、（３）生成過程だけでなく他の多くの取り得る生成過程を含めた --- バイアスより分散の方が推定値の誤差に占める割合が大きいオーバーフィッティング状態である --- かのいずれかである。正則化の目標はモデルを３番目の状態から２番目の状態にすることである。
実践では、過度に複雑なモデル族は対象の関数や真のデータ生成過程、または、どちらかの近しい近似であっても必ず含むというわけではない。我々は真のデータ生成過程にアクセスすることはほぼできず、そのために、推定されるモデル族がその生成過程を含むかどうかを確信できることは一切ない。しかしながら、深層学習アルゴリズムのほとんどのアプリケーションは真のデータ生成過程がほぼ確実にモデル族の外側にある領域にある。深層学習アルゴリズムは一般に、真の生成過程が本質的に宇宙全体のシミュレーションを伴う、画像、音声シーケンス、文章のような極めて複雑な領域に適用される。ある程度までは、我々は常に四角いペグ（データ生成過程）を丸い穴（我々のモデル族）に合わせようと試みている。
これが意味することは、モデルの複雑さを制御することが正しいパラメータ数を持つ正しい大きさのモデルを見つけるという単純な問題ではない、ということである。代わりに、我々は（汎化誤差を最小化するという意味において）最適にフィットするモデルが適切に正則化された大きなモデルであることをおそらく見つけ --- そして実際に、実践的な深層学習のシナリオにおいて、ほとんどいつも見つけ --- るだろう。
我々はそのような大きく深い正則化されたモデルを生成する方法に対するいくつかの戦略を再調査する。

## パラメータのノルムの罰則

正則化は深層学習の出現に先立って数十年の間使われてきた。線形回帰やロジスティック回帰のような線形モデルは単純で素直で効果的な正則化戦略を可能にする。多くの正則化アプローチは、目的関数$J$にパラメータノルムの罰則$\Omega(\boldsymbol{\theta})$を加えることによって、ニューラルネットワーク、線形回帰、ロジスティック回帰のようなモデルの能力を制限することに基づいている。我々は正則化された目的関数を$\tilde{J}$で表記する。

$$
\tilde{J}(\boldsymbol{\theta}; \boldsymbol{X}, \boldsymbol{y}) = J(\boldsymbol{\theta}; \boldsymbol{X}, \boldsymbol{y}) + \alpha \Omega(\boldsymbol{\theta})
$$

ここで、$\alpha \in [0, \infty)$は、標準の目的関数$J$に関連して、ノルムの罰則項$\Omega$の相対的寄与を重み付けするハイパーパラメータである。$\alpha$を$0$に設定することは正則化しないということになる。より大きな$\alpha$の値はより大きな正則化に対応する。
我々の訓練アルゴリズムが正規化された目的関数$\tilde{J}$を最小化するとき、訓練データに関する元の目的$J$とパラメータ$\boldsymbol{\theta}$の大きさのある測度（または、パラメータのある部分集合）の両方を減らすだろう。パラメータノルム$\Omega$に対する選択が異なれば、結果として優先される解は異なり得る。本節では、我々はモデルのパラメータに関する罰則として使われるときの様々なノルムの効果を考察する。
異なるノルムの正則化の振る舞いを掘り下げる前に、我々は、ニューラルネットワークに対して、一般に各層でアフィン変換の重みだけに罰則を課し、バイアスを非正則化のままにするパラメータノルムの罰則$\Omega$を用いることを選択することに留意する。バイアスは一般に正確にフィットさせるのに重みほど多くのデータを必要としない。各重みは2つの変数がどのように相互作用するかを明示する。重みをうまくフィットさせることは多種多様な状況で両方の変数を観察することを必要とする。各バイアスは単一の変数のみを制御する。これはバイアスを非正則化のままとすることによってそこまでの分散を引き起こさないことを意味する。また、バイアスパラメータを正則化することは大幅なアンダーフィッティングをもたらし得る。従って、我々はノルムの罰則に影響を受けるべきすべての重みを示すためにベクトル$\boldsymbol{w}$を用い、その一方で、ベクトル$\boldsymbol{\theta}$は、$\boldsymbol{w}$と非正則化パラメータを含めた、すべてのパラメータを表記する。
ニューラルネットワークの文脈では、時折、ネットワークの層ごとに異なる$\alpha$係数を持つ別個の罰則を用いることが望ましい。複数のハイパーパラメータの正しい値を探すのは効果となり得るので、探索空間の大きさを減らすためだけにすべての層で同じweight decayを用いることは依然として合理的である。

### $L^2$パラメータ正則化

我々は既に、[@sec:5.2.2]において、最も単純で最も一般的な種類のパラメータノルムの罰則を見てきた。すなわち、weight decayとして一般的に知られる$L^2$パラメータノルム罰則である。この正則化戦略は正則化項$\Omega(\boldsymbol{\theta}) = \fac{1}{2} \| \boldsymbol{w} \|_2^2$を目的関数に加えることで重みを原点[^1]に近づける。他の学術コミュニティでは、$L^2$正則化はリッジ回帰[ridge regression]とかTikhonovの正則化としても知られる。

[^1]: より一般的に言えば、我々は空間のいずれかの特定の点の近くになるようパラメータを正規化し、驚くことに、依然として正則化の効果を得ることできるだろうが、より良い結果は、正しい値が正または負であるべきかを知らないときに理にかなう既定値であるゼロを伴う、真の点により近い値に対して得られるだろう。ゼロに向かってモデルパラメータを正則化することはかなり一般的であるので、我々は説明の中でこの特殊なケースに焦点を当てるだろう。

我々は正則化された目的関数の勾配を研究することでweight decayの正則化の振る舞いへの洞察を得られる。その提示を単純化するため、我々はバイアスパラメータがない、すなわち、$\boldsymbol{\theta}$が単に$\boldsymbol{w}$であると仮定する。そのようなモデルは以下の総目的関数を持つ。

$$
\tilde{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y}) = \frac{\alpha}{2} \boldsymbol{w}^\top \boldsymbol{w} + J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})
$$

これは以下のような対応するパラメータの勾配を持つ。

$$
\nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y}) = \alpha \boldsymbol{w} + \nabla_{\boldsymbol{w}} J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})
$$

重みを更新するために単一の勾配ステップをとるには、以下のようにこの更新を行う。

$$
\boldsymbol{w} \leftarrow \boldsymbol{w} - \epsilon(\alpha \boldsymbol{w} + \nabla_{\boldsymbol{w}} J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y}))
$$

別の方法で書くと、この更新は以下となる。

$$
\boldsymbol{w} \leftarrow (1 - \epsilon \alpha) \boldsymbol{w} - \epsilon \nabla_{\boldsymbol{w}} J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})
$$

我々は、通常の勾配更新を行う前に、weight decay項の追加が各ステップで定数のファクタによって重みベクトルを倍々に縮小するように、学習規則を修正したと見ることができる。これは単一のステップに起こることを述べている。では、訓練の全過程では何が起こっているのだろう？
我々は最小の非正規化訓練コスト$\boldsymbol{w}^* = \argmin_{\boldsymbol{w}} J(\boldsymbol{w})$を得る重みの値の近傍において目的関数への二次近似を作ることによって解析をかなり単純化するだろう。平均二乗誤差で線形回帰モデルをフィットさせる場合のように、目的関数が真の二次関数であるならば、その近似は完璧である。近似$\hat{J}$は以下で与えられる。

$$
\hat{J}(\boldsymbol{\theta}) = J(\boldsymbol{w}^*) + \frac{1}{2} (\boldsymbol{w} - \boldsymbol{w}^*)^\top \boldsymbol{H}(\boldsymbol{w} - \boldsymbol{w}^*)
$$

ここで、$\boldsymbol{H}$は$\boldsymbol{w}^*$で計算される$\boldsymbol{w}$に関する$J$のヘッセ行列である。$\boldsymbol{w}^*$が勾配を消失させる最小であると定義されるので、この二次近似には一次項が存在しない。同様に、$\boldsymbol{w}^*$が$J$の最小の場所であるので、$\boldsymbol{H}$が半正定値であると結論付けることができる。
$\hat{J}$の最小はその勾配

$$
\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w}) = \boldsymbol{H}(\boldsymbol{w} - \boldsymbol{w}^*)
$$

が$\boldsymbol{0}$に等しいところで発生する。
weight decayの効果を研究するため、我々は[@eq:7.7]をweight decayの勾配を加えることによって修正する。すると、$\hat{J}$の正則化バージョンの最小に対して解くことができる。我々は最小の場所を表現するために変数$\tilde{\boldsymbol{w}}$を用いる。

$$
\alpha \tilde{\boldsymbol{w}} + \boldsymbol{H}(\tilde{\boldsymbol{w}} - \boldsymbol{w}^*) = 0
$$

$$
(\boldsymbol{H} + \alpha \boldsymbol{I}) \tilde{\boldsymbol{w}} = \boldsymbol{H} \boldsymbol{w}^*
$$

$$
\tilde{\boldsymbol{w}} = (\boldsymbol{H} + \alpha \boldsymbol{I})^{-1} \boldsymbol{H} \boldsymbol{w}^*
$$

$\alpha$が$0$に近づくにつれて、正則化された解$\tilde{\boldsymbol{w}}$は$\boldsymbol{w}^*$に近づく。しかし、$\alpha$が増えるたびに何が起こるか？$\boldsymbol{H}$は実対称であるので、我々はこれを、$\boldsymbol{H} = \boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^\top$のように、対角行列$\boldsymbol{\Lambda}$と固有ベクトルの正規直交基底$\boldsymbol{Q}$に分解する。[@eq:7.10]へ分解を適用すると、以下を得る。

$$
\tilde{\boldsymbol{w}} = (\boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^\top + \alpha \boldsymbol{I})^{-1} \boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^\top \boldsymbol{w}^*
$$

$$
= \left[ \boldsymbol{Q} (\boldsymbol{\Lambda} + \alpha \boldsymbol{I}) \boldsymbol{Q}^\top \right]^{-1} \boldsymbol{Q} \boldsymbol{\Lambda} \boldsymbol{Q}^\top \boldsymbol{w}^*
$$

$$
= \boldsymbol{Q} (\boldsymbol{\Lambda} + \alpha \boldsymbol{I})^{-1} \boldsymbol{\Lambda} \boldsymbol{Q}^\top \boldsymbol{w}^*
$$

我々は、weight decayの効果が$\boldsymbol{H}$の固有ベクトルによって定義される軸に沿って$\boldsymbol{w}^*$を再スケールすることである、ということを理解している。具体的には、$\boldsymbol{H}$の$i$番目の固有ベクトルに並行である$\boldsymbol{w}^*$の成分は$\frac{\lambda_i}{\lambda_i + \alpha}$のファクタによって再スケールされる。（[@fig:2.3]で最初に説明されるこの種類のスケーリングがどのように機能するかを確認することをオススメする）。
$\boldsymbol{H}$の固有値が比較的大きいところ、例えば、$\lambda_i \gg \alpha$であるところの方向に沿うと、正則化の影響は比較的小さい。未だ$\lambda_i \ll \alpha$を持つ成分はほぼゼロの大きさを持つよう縮小されるだろう。この効果は[@fig:7.1]に図示される。

![最適な$\boldsymbol{w}$の値に関する$L^2$（または、weight decay）正則化の効果の図。実践の楕円は正規化されていない目的の等値の等高線を表現する。破線の円は$L^2$ regularizerの等値の等高線を表現する。点$\tilde{\boldsymbol{w}}$では、これらの競合する目的は均衡に達する。1次元目では、$J$のヘシアンの固有値は小さい。目的関数は$\boldsymbol{w}^*$から水平に離れるときにそこまで増加しない。目的関数はこの方向に沿って強い選好を表現しないので、regularizerはこの軸での強い影響を持つ。regularizerは$w_1$をゼロに近づける。2次元目では、目的関数は$\boldsymbol{w}^*$から離れる動きに非常に敏感である。対応する固有値は大きく、高い曲率を示す。結果として、weight decayは比較的少なく$w_2$の位置に影響を与える。](fig/7-1.png){#fig:7.1}

パラメータが目的関数を減らすのに大幅に貢献する方向のみが比較的そのままに保持される。目的関数を減らすのに貢献しない方向において、ヘシアンの小さな固有値は、この方向での動きが勾配を大幅に増やさないであろうことを教えてくれる。そのような重要でない方向に対応する重みベクトルの成分は訓練全体で正則化を用いることを通して減衰される[decayed away]。
これまで、我々は抽象的で一般的な二次のコスト関数の最適化に関する影響の観点でweight decayを考察してきた。これらの効果は特に機械学習とどのように関連するのだろう？我々は線形回帰を研究することで見つけ出すことができる。このモデルは、真のコスト関数が二次であり、それ故に、これまでに使ってきたのと同種の解析を受ける余地がある。再びその解析を適用すると、我々は同じ結果の特殊なケースを得ることができるだろうが、その解は訓練データの観点で表現されている。線形回帰に対して、コスト関数は二乗誤差の総和である。

$$
(\boldsymbol{X} \boldsymbol{w} - \boldsymbol{y})^\top (\boldsymbol{X} \boldsymbol{w} - \boldsymbol{y})
$$

$L^2$正則化を追加するとき、目的関数は以下のように変化する。

$$
(\boldsymbol{X} \boldsymbol{w} - \boldsymbol{y})^\top (\boldsymbol{X} \boldsymbol{w} - \boldsymbol{y}) + \frac{1}{2} \alpha \boldsymbol{w}^\top \boldsymbol{w}
$$

これは

$$
\boldsymbol{w} = (\boldsymbol{X}^\top \boldsymbol{X})^{-1} \boldsymbol{X}^\top \boldsymbol{y}
$$

から

$$
\boldsymbol{w} = (\boldsymbol{X}^\top \boldsymbol{X})^{-1} \boldsymbol{X}^\top \boldsymbol{y}
$$

へ解に対する正規方程式を変化させる。[@eq:7.18]における行列$\boldsymbol{X} ^\top \boldsymbol{X}$は共分散行列$\frac{1}{m} \boldsymbol{X} ^\top \boldsymbol{X}$に比例する。$L^2$正則化を用いることはこの行列を[@eq:7.17]における$(\boldsymbol{X}^\top \boldsymbol{X} + \alpha \boldsymbol{I})^{-1}$で置き換える。新しい行列は元の行列と同じであるが、対角に$\alpha$の加算を伴う。この行列の対角成分は各入力の特徴の分散に対応する。我々は、$L^2$正則化が学習アルゴリズムをより高い分散を持つと入力$\boldsymbol{X}$を「知覚」するようにすることを理解できる。これは、この追加される分散と比較して低い出力の対象を伴う共分散を持つ特徴に関する重みを縮小させる。

### $L^1$正則化

$L^2$ weight decayはweight decayの最も一般的な形式であるが、モデルパラメータのサイズに罰則を課す方法が他に存在する。もうひとつの選択肢は$L^1$正則化を用いることである。
公式的に言えば、モデルパラメータ$\boldsymbol{w}$に関する$L^1$正則化は以下のように定義される。

$$
\Omega(\boldsymbol{\theta}) = \| \boldsymbol{w} \|_1 = \sum_i |w_i|
$$

すなわち、個々のパラメータの絶対値の総和として定義される[^2]。ここで、我々は$L^2$正則化の解析で研究したようなバイアスパラメータを持たない単純な線形回帰モデルに関する$L^1$正則化の効果を考察するだろう。特に、我々は正則化の$L^1$と$L^2$の形式の間の差異を描くことに関心がある。$L^2$ weight decayと同様に、$L^1$ weight decayは正のハイパーパラメータ$\alpha$を用いて罰則$\Omega$をスケールすることによって正則化の強さを制御する。故に、正則化された目的関数$\tilde{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})$は以下によって与えられる。

$$
\tilde{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y}) = \alpha \| \boldsymbol{w} \|_1 + J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})
$$

これは、以下のような対応する勾配（実際には、劣勾配）を持つ。

$$
\nabla_{\boldsymbol{w}} \tilde{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y}) = \alpha \text{sign}(\boldsymbol{w}) + \nabla_{\boldsymbol{w}} J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})
$$

ここで、$\text{sign}(\boldsymbol{w})$は単に要素ごとに適用される$\boldsymbol{w}$の符号である。

[^2]: $L^2$正則化と同様に、我々はゼロでない値に向かってではなく、代わりに、あるパラメータの値$\boldsymbol{w}^{(o)}$に向かってパラメータを正則化出来るだろう。この場合、$L^1$正則化は項$\Omega(\boldsymbol{\theta}) = \| \boldsymbol{w} - \boldsymbol{w}^{(o)} \|_1 = \sum_i | w_i - w_i^{(o)} |$を導入するだろう。

[@eq:7.20]を詳しく調べる事によって、$L^1$正則化の効果が$L^2$正則化の効果とかなり異なることを即座に理解できる。具体的には、勾配への正則化の寄与がもはや各$w_i$で線形にスケールしないことを理解できる。その代わりとして、$\text{sign}(w_i)$に等しい符号を持つ定数のファクタとなる。勾配のこの形式の１つの結論は、$L^2$正則化に対して行ったような$J(\boldsymbol{X}, \boldsymbol{y}; \boldsymbol{w})$の二次近似へのきれいな代数的な解を必ずしも理解する必要はないであろう、ということである。
我々の単純な線形モデルはテイラー級数を介して表現できる二次のコスト関数を持つ。言い換えれば、これがより洗練されたモデルのコスト関数を近似する、端を切り捨てたテイラー級数であると想像できるだろう。この設定における勾配は以下によって与えられる。

$$
\nabla_{\boldsymbol{w}} \hat{J}(\boldsymbol{w}) = \boldsymbol{H}(\boldsymbol{w} - \boldsymbol{w}^*)
$$

ここで、再び、$\boldsymbol{H}$は$\boldsymbol{w}^*$で計算される$\boldsymbol{w}$に関する$J$のヘッセ行列である。
$L^1$罰則は完全に一般的なヘシアンの場合にキレイな代数式を認めないので、ヘシアンが対角である、つまり、それぞれ$H_{i,i} > 0$となる$\boldsymbol{H} = \text{diag}([H_{1,1}, \dots, H_{n,n}$であるといったかなり単純化する仮定も作る。この仮定は線形回帰問題が入力の特徴の間のすべての相関を取り除くために前処理されている場合に成り立つ。これは、PCAを用いて達成されるかもしれない。
$L^1$正規化される目的関数の二次近似はパラメータ上の総和に分解される。

$$
\hat{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y}) = J(\boldsymbol{w}^*; \boldsymbol{X}, \boldsymbol{y}) + \sum_i \left[ \frac{1}{2} H_{i,i} (\boldsymbol{w}_i - \boldsymbol{w}_i^*)^2 + \alpha |w_i| \right]
$$

この近似的なコスト関数の最小化の問題は、以下の形式を伴って、（次元$i$ごとに）解析解を持つ。

$$
w_i = \text{sign}(w_i^*) \max \left{ |w_i^*| - \frarc{\alpha}{H_{i,i}}, 0 \right}
$$

すべての$i$に対して$w_i^* > 0$となる状況を考える。起こり得る結果として2つの場合が存在する。

1. $w_i^* \le \frac{\alpha}{H_{i,i}}$となる場合。ここでは、正規化された目的の下での$w_i$の最適値は単に$w_i = 0$である。これは、正規化された目的$\tilde{J}(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})$への$J(\boldsymbol{w}; \boldsymbol{X}, \boldsymbol{y})$の寄与が、方向$i$において、$w_i$の値をゼロに押し出す$L^1$正則化によって圧倒されるので、発生する。
2. $w_i^* > \frac{\alpha}{H_{i,i}}$となる場合。この場合、正則化は$w_i$の最適値をゼロに動かさないが、代わりに、$\frac{\alpha}{H_{i,i}}$に等しい距離によってその方向にずらす。

$w_i^* < 0$のときに似た処理が発生するが、$L^1$罰則は$w_i$を$\frac{\alpha}{H_{i, i}}$によってより小さな負にする、または、$0$にする。
$L^2$正則化と比較して、$L^1$正則化は結果としてより疎[sparse]である解となる。この文脈におけるスパース性はいくつかのパラメータがゼロの最適値を持つという事実を指している。$L^1$正則化のスパース性は$L^2$正則化で発生する振る舞いとは質的に異なる。[@eq:7.13]は$L^2$正則化に対して解$\tilde{w}$を与えた。$L^1$正則化の解析に導入した対角正定値のヘシアン$\boldsymbol{H}$の仮定を用いるその式を再訪するならば、我々は$\tilde{w}_i = \frac{H_{i,i}}{H_{i,i} + \alpha} w_i^*$を求める。$w_i^*$が非ゼロであったならば、$\tilde{w}_i$は非ゼロのままである。これは、$L^2$正則化がパラメータを疎にしないが、$L^1$正則化が十分に大きな$\alpha$ではそうさせるかもしれない、ということを実証する。$L^1$正則化に課されるスパース性の特性は特徴選択[feature selection]のメカニズムとして広範囲に用いられてきた。特徴選択はどの利用可能な特徴の部分集合が使われるべきかを選択することによって機械学習問題を単純化する。特に、良く知られたLASSO[@Tibshirani1995]（least absolute shrinkage and selection operator）モデルは$L^1$罰則を線形モデルと最小二乗のコスト関数で統合する。$L^1$罰則は重みの部分集合をゼロとなるようにし、対応する特徴が安全に破棄されても良いことを示唆する。
[@sec:5.6.1]では、我々は多くの正則化戦略がMAPベイズ推定として解釈できること、具体的には、$L^2$正則化が重みに関するガウシアン事前確率を持つMAPベイズ推定と等価であることを確認した。$L^1$正則化では、コスト関数を正則化するのに使われる罰則$\alpha \Omega(\boldsymbol{w}) = \alpha \sum_i |w_i|$は、事前確率が$\boldsymbol{w} \in \mathbb{R}^n$上の等方的ラプラス分布[@eq:3.26]であるとき、MAPベイズ推定によって最大化される対数事前確率項と等価である。

$$
\log p(\boldsymbol{w}) = \sum_i \log \text{Laplace}(w_i; 0, \frac{1}{\alpha}) = -\alpha \| \boldsymbol{w} \|_1 + n \log \alpha - n \log 2
$$

$\boldsymbol{w}$に関する最大化を介した学習の視点から、我々は$\log \alpha - \log 2$の項を、$\boldsymbol{w}$に依存しないという理由から、無視できる。

## 制約付き最適化としてのノルム罰則

パラメータノルム罰則によって正則化されるコスト関数を考える。

$$
\tilde{J}(\boldsymbol{\theta}; \boldsymbol{X}, \boldsymbol{y}) = J(\boldsymbol{\theta}; \boldsymbol{X}, \boldsymbol{y}) + \alpha \Omega(\boldsymbol{\theta})
$$

元の目的関数と罰則の集合から成る、一般化したラグランジュ関数を構築することで制約に従って関数を最小化できる、ということを[@sec:4.4]から再掲する。各罰則はKarush-Kuhn-Tuckerｆ（KKT）乗数と呼ばれる係数と制約を満たすかどうかを表現する関数の間の積である。$\Omega(\boldsymbol{\theta})$をある定数$k$より小さくなるよう制約を課すことを欲した場合、以下のような一般化したラグランジュ関数を構築できただろう。

$$
\mathcal{L}(\boldsymbol{\theta}, \alpha; \boldsymbol{X}, \boldsymbol{y}) = J(\boldsymbol{\theta}; \boldsymbol{X}, \boldsymbol{y}) + \alpha(\Omega(\boldsymbol{\theta}) - k)
$$

その制約付き問題への解は以下によって与えられる。

$$
\boldsymbol{\theta}^* = \argmin_{\boldsymbol{\theta}} \max_{\alpha, \alpha \ge 0} \mathcal{L}(\boldsymbol{\theta}, \alpha)
$$

[@sec:4.4]で述べた通り、この問題を解くには$\boldsymbol{\theta}$と$\alpha$の両方を弄る必要がある。[@sec:4.5]は$L^2$制約を伴う線形回帰のうまくいく例を提供する。多くの様々な手順が取り得る --- いくつかは勾配降下法を用いるかもしれないし、またいくつかは勾配がゼロのところでの解析解を用いるかもしれない --- が、すべての手順において、$\alpha$は$\Omega(\boldsymbol{\theta}) > k$であるならどこでも増加しなければならないし、$\Omega(\boldsymbol{\theta}) < k$であるならどこでも減少しなければならない。すべての取り得る$\alpha$は$\Omega(\boldsymbol{\theta})$が縮小するよう促す。最適な値$\alpha^*$は$\Omega(\boldsymbol{\theta})$が縮小するよう促すが、$\Omega(\boldsymbol{\theta})$を$k$より小さくするほど強力ではない。
制約の効果へのいくつかの洞察を得るため、我々は$\alpha^*$を固定して、単なる$\boldsymbol{\theta}$の関数としてこの問題を見ることができる。

$$
\boldsymbol{\theta}^* = \argmin_{\boldsymbol{\theta}} \mathcal{L}(\boldsymbol{\theta}, \alpha^*) = \argmin_{\boldsymbol{\theta}} J(\boldsymbol{\theta}; \boldsymbol{X}, \boldsymbol{y}) + \alpha^* \Omega(\boldsymbol{\theta})
$$

これは$\tilde{J}$の最適化の正則化された訓練問題とまったく同じである。故に、我々はパラメータノルム罰則を重みに関する制約を課すこととして考えることができる。$\Omega$が$L^2$ノルムであれば、重みは$L^2$の玉の中にあるよう制限される。$\Omega$が$L^1$ノルムであれば、重みは制限された$L^1$ノルムの領域の中にあるよう制限される。通常では、$\alpha^*$の値は$k$の値を直接教えてくれないので、我々は係数$\alpha^*$でweight decayを用いる事によって課される制約領域の大きさを知らない。原則として、$k$に対して解くことはできるが、$k$と$\alpha^*$の間の関係は$J$の形式に依存する。我々は制約領域の厳密な大きさを知らないが、一方で、制約領域を拡大または縮小するために$\alpha$を増加または現象させることによって大まかに制御することができる。より大きい$\alpha$はより小さな制約領域となるだろう。より小さな$\alpha$はより大きな制約領域となるだろう。
時折、我々は罰則ではなく明示的な制約を用いることを望むかもしれない。[@sec:4.4]で述べた通り、我々は$J(\boldsymbol{\theta})$上で下り坂に一歩踏み出し、$\Omega(\boldsymbol{\theta}) < k$を満たす最も近い点に$\boldsymbol{\theta}$を投影し直すために確率的勾配降下法のようなアルゴリズムを修正できる。これは、どんな$k$の値が適切であるかのアイデアを持ち、この$k$に対応する$\alpha$の値を探すのに時間をかけたくない場合、有用となり得る。
罰則で制約を強いるのではなく明示的な制約と再投影を用いるもうひとつの理由は、罰則が非凸最適化の手順を小さな$\boldsymbol{\theta}$に対応する極小値にはまり込ませてしまうことである。ニューラルネットワークを訓練するとき、これは通常ではいくつかの「死んだユニット」とともに訓練するニューラルネットワークとして現れる。これらは、そこに出入りする重みがすべて非常に小さいので、ネットワークによって学習される関数の振る舞いにほとんど寄与しないユニットである。重みのノルムに関する罰則で訓練するとき、これらのconfigurationsは、たとえ重みをより大きくすることによって$J$を大幅に減らすことができるとしても、局所的に最適となり得る。再投影によって実装される明示的制約は、重みが原点に近づくことを促さないので、これらのケースでさらにうまく機能し得る。再投影によって実装される明示的制約は重みが大きくなり、制約領域を離れようとするときにのみ影響を持つ。
最後に、再投影による明示的制約は、最適化手順に関するある安定性を課すので、有用となり得る。高い学習率を用いるとき、大きな重みが大きな勾配を誘発する正のフィードバックループに遭遇する可能性がある。故に、これは重みの大きな更新を誘発する。これらの更新が重みの大きさを一貫して増加させるならば、$\boldsymbol{\theta}$は数値的なオーバーフローが起きるまで原点から急速には離れる。再投影による明示的制約はこのフィードバックループが際限なしに重みの絶対値を増加し続けることを防ぐ。@Hinton2012cは、いくらかの安定性を維持しつつパラメータ空間の急速な探索を可能にするために高い学習率と組み合わせられた制約を用いることを推奨する。
特に、@Hinton2012cは@Srebro2005によって導入された、重み行列全体のFrobeniusノルムを制限するのではなく、ニューラルネットの層の重み行列の各劣のノルムを制限する、という戦略を推奨する。別個に各列のノルムを制限することはいずれかの1つの隠れユニットが非常に大きな重みを持つことを防ぐ。この制約をラグランジュ関数における罰則に変換した場合、$L^2$ weight decayと似ているが、各隠れユニットの重みに対して個別のKKT乗数を持つだろう。これらのKKT乗数のそれぞれは各隠れユニットを制約に従わせるために別個で動的に更新されるだろう。実践では列ノルムの制限は再投影による明示的制約として常に実装される。

## 正則化と制約不足[under-constrained]な問題

いくつかの場合、正則化は機械学習問題が適切に定義されるのに必須である。線形回帰やPCAを含む多くの機械学習における線形モデルは行列$\boldsymbol{X}^\top \boldsymbol{X}$の逆に依存する。これは$\boldsymbol{X}^\top \boldsymbol{X}$が特異であるときにできない。この行列は、データ生成分布がある方向で本当に分散を持たないときならいつでも、または、入力の特徴（$\boldsymbol{X}の列$）より少ないexamples（$\boldsymbol{X}$の行）が存在するという理由からある方向において分散が観察されないときに特異となり得る。この場合、多くの形式の正則化は代わりに$\boldsymbol{X}^\top \boldsymbol{X} + \alpha \boldsymbol{I}$の逆に対応する。この正則化された行列は可逆であることが保証される。
これらの線形問題は関連する行列が可逆であるときに閉形式の解を持つ。閉形式の解を持たない問題では劣決定されることもあり得る。ひとつの例はクラスが線形に分離可能である問題に適用されるロジスティック回帰である。重みベクトル$\boldsymbol{w}$が完璧な分類を達成できるならば、$2\boldsymbol{w}$もまた完璧な分類とより高い尤度を達成するだろう。確率的勾配降下法のような反復的な最適化手順は$\boldsymbol{w}$の大きさを絶えず増加させ、理論的には、決して止まらないだろう。実践では、勾配降下法の数値的な実装は最終的に数値的オーバーフローを引き起こすのに十分に大きな重みに達するだろう。この時点では、その挙動はプログラマが実数でない値を扱うと決めていたかどうかに依存するだろう。
ほとんどの形式の正則化は劣決定問題に適用される反復的手法の収束を保証できる。例えば、weight decayは勾配降下法に、尤度の傾きがweight decayの係数と等しいときに重みの大きさを増加させるのを止めさせるだろう。
劣決定問題を解くために正則化を用いるというアイデアは機械学習を超えて広がる。同じアイデアはいくつかの基本的な線形代数の問題で有用である。
[@sec:2.9]で見た通り、我々はMoore-Penroseの擬似逆行列を用いて劣決定の一次方程式を解くことができる。行列$\boldsymbol{X}$の擬似逆行列$\boldsymbol{X}^+$のある定義は以下であることを思い出したい。

$$
\boldsymbol{X}^+ = \lim_{\alpha \searrow 0} (\boldsymbol{X}^\top \boldsymbol{X} + \alpha \boldsymbol{I})^{-1} \boldsymbol{X}^\top
$$

我々はいま[@eq:7.29]をweight decayを持つ線形回帰を行うこととして認識できる。具体的には、[@eq:7.29]は正則化係数をゼロに縮小するときの[@eq:7.17]の極限である。故に、我々はその擬似逆行列を正則化を用いて劣決定問題を安定化することと解釈できる。

## データセットの増強[dataset augmentation]

機械学習モデルをより良く汎化させる最良の方法はより多くのデータで訓練することである。もちろん、実践では、持てるデータ量には限界がある。この問題を迂回する1つの方法は偽のデータを作り、それを訓練セットに加えることである。いくつかの機械学習タスクでは、新しい偽データを作ることは理に適って単純明快である。
このアプローチは分類に対するのが最も容易である。分類器は複雑で高次元の入力$\boldsymbol{x}$を取り、単一のカテゴリ識別子$y$にまとめる必要がある。これは分類器が特免する主なタスクが多種多様な変換に不変であることを意味する。我々は単に訓練セットにおける入力を$\boldsymbol{x}$に変換することによって新しい$(\boldsymbol{x}, y)$のペアを容易に生成できる。
このアプローチは他の多くのタスクに容易に適用可能とはならない。例えば、すでに密度推定問題を解いていなければ、密度推定タスクに対する新しい偽データを生成することは難しい。
dataset augmentationは特定の分類問題、すなわち、物体認識に対して特に効果的な技術となっている。画像は高次元であり、その多くが容易にシミュレートできる膨大な種類のバラツキの要因を含む。各方向に数ピクセルだけ訓練画像を平行移動するような演算はしばしば、モデルがすでに[@sec:9]で述べられる畳み込みやプーリングの技術を用いることによって部分的な平行移動に不変であるよう設計されている場合でさえ、汎化を大きく改善し得る。画像の回転や画像のスケーリングのような他の多くの演算もまたかなり効果的であると証明されている。
正しいクラスを変化させるであろう変換を適用しないよう注意しなければならない。例えば、光学的な文字認識タスクは"b"と"d"の差や"6"と"9"の差を認識する必要があり、そのために、左右の反転や180°の回転はこれらのタスクに対してデータセットを増強する適切な方法ではない。
分類器をそれに不変にしたいが、処理するのが容易でない変換も存在する。例えば、面外の回転は入力ピクセルの単純な幾何演算として実装できない。
dataset augmentationは同様に音声認識タスクに対して効果的である[@Jaitly2013]。
入力におけるノイズをニューラルネットワークに注入すること[@Sietsma1991]もまたdata augmentationのいち形式として理解できる。多くの分類に対して、そして、いくつかの認識タスクに対してさえも、タスクは依然として、小さなランダムノイズが入力に付加されていても、解くことができるはずである。とは言っても、ニューラルネットワークはノイズに対して非常にロバストでないことが証明されている[@Tang2010]。ニューラルネットワークのロバスト性を改善する1つの方法は単純にこれらの入力に適用されるランダムノイズとともに訓練することである。入力ノイズ注入は、denoising autoencoder [@Vincent2008]のような、いくつかの教師なし学習アルゴリズムの一部である。ノイズ注入は、ノイズが隠れ層に適用されるときにも機能する。これは、複数の抽象化レベルでdataset augmentationを行うこととして理解できる。@Poole2014は、ノイズの大きさが注意深く調整されることを条件に、このアプローチを高効率にすることができることを最近になって示した。[@sec:7.12]で述べられるであろう強力な正則化戦略であるdropoutはノイズを乗算することによって新しい入力を構築する工程として理解できる。
機械学習のベンチマーク結果を比較するとき、dataset augmentationの効果を計算に入れることは重要である。しばしば、手製のdataset augmentationスキームは機械学習技術の汎化誤差を劇的に減らし得る。ある機械学習アルゴリズムのパフォーマンスを別のものと比較するため、制御された実験を行う必要がある。機械学習アルゴリズムAと機械学習アルゴリズムBを比較するとき、両方のアルゴリズムが同じ手製のdataset augmentationスキームを用いて評価されることを確実にする。アルゴリズムAはdataset augmentationなしではうまく行われず、アルゴリズムBは入力の膨大な合成的変換と組み合わせられるときにうまく行うとする。そのような場合、機械学習アルゴリズムBの使用ではなく、合成的変換が改善されたパフォーマンスを引き起こした可能性が高い。時折、実験が適切に制御されているかどうか決めることは主観的な判断を必要とする。例えば、入力にノイズを注入する機械学習アルゴリズムはdataset augmentationのいち形式を処理している。通常、（入力にガウシアンノイズを加えるような）一般的に適用できる演算は機械学習アルゴリズムの一部と考えられ、一方で、（画像の無作為なクロッピングのような）ある応用領域に特有である演算は別個の前処理ステップであると考えられる。

## ノイズ堅牢性

[@sec:7.4]はdataset augmentation戦略として入力に適用されるノイズの使用を動機付けている。いくつかのモデルにとって、モデルの入力での微小分散を持つノイズの付加は重みのノルムに関する罰則を課すことと等価である[@Bishop1995a; @Bishop1995b]。一般的なケースにおいて、ノイズの注入が、特にノイズが隠れユニットに付加されるとき、パラメータを単に縮小するよりもかなり強力となり得ることを覚えておくことは重要である。隠れユニットに適用されるノイズはそれ自体を個別に考察するに値するなんとも重要なトピックである。[@sec:7.12]で述べられるdropoutアルゴリズムはそのアプローチの主な発展形である。
ノイズがモデルの正則化のために使われているもうひとつの方法は重みにそれを付加することによるものである。この技術はリカレントニューラルネットワークの文脈で主に使われている[@Jim1996; @Graves2011]。これは重みでのベイズ推定の確率的な実装として解釈できる。学習のベイズ的な扱いは、モデルの重みが不確かであり、この不確かさを反映する確率分布を介して表現可能であると見なすだろう。重みにノイズを付加することはこの不確かさを反映する実践的で確率的な方法である。
重みに適用されるノイズは、学習される関数の安定性を促すような、より伝統的な形式の正則化と（いくつかの仮定の下で）等価であると解釈することもできる。モデルの推定値$\hat{y}(\boldsymbol{x})$と真の値$y$の間の最小二乗のコスト関数を用いて特徴の集合$\boldsymbol{x}$をスカラにマッピングする関数$\hat{y}(\boldsymbol{x})$を訓練したいとする回帰の設定を考える。

$$
J = \mathbb{E}_{p(x, y)} \left[ (\hat{y}(\boldsymbol{x}) - y)^2 \right]
$$

その訓練セットは$m$個のラベル付きexamples${(\boldsymbol{x}^{(1)}, y^{(1)}), \dots, (\boldsymbol{x}^{(m)}, y^{(m)})}$から成る。
我々は、各入力表現とともに、ネットワークの重みの無作為な摂動$\epsilon_{\boldsymbol{W}} \sim \mathcal{N}(\boldsymbol{\epsilon}; \boldsymbol{0}, \eta \boldsymbol{I})$もまた含むと仮定する。標準的な$l$層のMLPがあると想像しよう。我々は摂動したモデルを$\hat{y}_{\boldsymbol{\epsilon W}}(\boldsymbol{x})$と表記する。ノイズの注入に関わらず、我々は依然としてネットワークの出力の二乗誤差を最小化することに関心がある。故に、目的関数は以下となる。

$$
\tilde{J}_{\boldsymbol{W}} = \mathbb{E}_{p(\boldsymbol{x}, y, \boldsymbol{\epsilon W})} \left[(\hat{y}_{\boldsymbol{\epsilon W}}(\boldsymbol{x}) - y)^2 \right]
$$

$$
= \mathbb{E}_{p(\boldsymbol{x}, y, \boldsymbol{\epsilon W})} \left[\hat{y}_{\boldsymbol{\epsilon W}}^2(\boldsymbol{x}) - 2 y \hat{y}_{\boldsymbol{\epsilon W}}^2(\boldsymbol{x}) + y^2 \right]
$$

小さな$\eta$では、（共分散$\eta \boldsymbol{I}$を持つ）付加された重みノイズを伴う$J$の最小化は追加の正則化項$\eta \mathbb{E}_{p(\boldsymbol{x}, y)} [ \| \nabla_{\boldsymbol{W}} \hat{y}(\boldsymbol{x}) \|^2 ]$を持つ$J$の最小化と等価である。この形式の正則化はパラメータを重みの小さな摂動が出力に関する比較的小さな影響を持つところのパラメータ空間の領域に進むよう促す。別の言い方をすれば、これはモデルが重みにおける小さなバラツキに比較的鈍感であるところの領域にモデルを押し進め、単なる極小ではなく、平坦な領域に囲まれる極小となる点を見つける[@Hochreiter1995]。（たとえば、$\hat{y}(\boldsymbol{x}) = \boldsymbol{w}^\top \boldsymbol{x} + b$となる）線形回帰の単純化したケースでは、この正則化項は$\eta \mathbb{E}_{p(\boldsymbol{x})} [ \| \boldsymbol{x} \|^2 ]$にcollapseする。これは、パラメータの関数ではなく、それ故に、モデルパラメータに関する$\tilde{J}_{\boldsymbol{W}}$の勾配に貢献しない。

### 出力対象でのノイズの注入

ほとんどのデータセットは$y$個のラベルにおいて数個の間違いがある。$y$が間違っているときに$\log p(y | \boldsymbol{x})$を最大化することは有害となり得る。これを防ぐ1つの方法はラベルに関するノイズを明示的にモデル化することである。例えば、我々は、ある小さな定数$\epsilon$に対して、訓練セットのラベル$y$が確率$1 - \epsilon$で正しいと仮定でき、そうでなければ、他の取り得るラベルのいずれかが正しいかもれないだろう。この仮定は、ノイズのサンプルを明示的に描くことによってではなく、コスト関数に解析的に組み入れることが容易である。例えば、label smoothingは、ハードな0と1の分類の対象を個々に$\frac{\epsilon}{k - 1}$と$1 - \epsilon$の対象に置き換えることによって、$k$個の出力値を持つsoftmaxに基づいてモデルを正則化する。故に、標準の交差エントロピーの損失はこれらのソフトな対象で使われるかもしれない。softmax分類器とハードな対象を持つ最大尤度学習は実際には一切収束しないかもしれない --- softmaxはぴったり0かぴったり1の確率をまったく予測できず、そのために、ますます大きな重みを学習し続け、より極端な予測を永遠に行うだろう。このシナリオがweight decayのような他の正則化戦略を用いることを妨げる可能性がある。label smoothingは正確な分類を促すことなしにハードな確率の追跡を防止するという利点を持つ。この戦略は1980年代から用いられていて、モダンなニューラルネットワークにおいてひときわ目立つ特徴となり続けている。

## 半教師あり学習

半教師あり学習のパラダイムにおいて、$P(\boldsymbol{\mathbf{x}})$由来のラベルなしexamplesと$P(\boldsymbol{\mathbf{x}}, \boldsymbol{\mathbf{y}})$由来のラベルありexamplesの両方は$P(\boldsymbol{\mathbf{y}} | \boldsymbol{\mathbf{x}})$を推定するか、$\boldsymbol{\mathbf{x}}$から$\boldsymbol{\mathbf{y}}$を予測するのに使われる。
深層学習の文脈では、半教師あり学習は通常では表現$\boldsymbol{h} = f(\boldsymbol{x})$の学習を指す。その目標は表現を学習することであり、すなわち、同じクラスからのexamplesは似た表現を持つ。教師なし学習は表現空間でexamplesをグループ化する方法のための有用な手がかりを提供し得る。入力空間においてタイトに集まるexamplesは似た表現にマッピングされるべきである。新しい空間における線形の分類器は多くの場合でより良い汎化を達成するかもしれない[@Belkin2002; @Chapelle2003]。このアプローチの長年に渡る変種は（投影されたデータに関する）分類器を適用する前の前処理ステップとしての主成分分析のアプリケーションである。
モデルにおける別個の教師なしおよび教師あり要素を持つ代わりに、$P(\boldsymbol{\mathbf{x}})$または$P(\boldsymbol{\mathbf{x}}, \boldsymbol{\mathbf{y}})$のどちらかの生成モデルが$P(\boldsymbol{\mathbf{y}} | \boldsymbol{\mathbf{x}})$の識別モデルとパラメータを共有するモデルを構築できる。故に、教師あり基準$-\log P(\boldsymbol{\mathbf{y}} | \boldsymbol{\mathbf{x}})$を（$-\log P(\mathbf{x})$または$-\log P(\boldsymbol{\mathbf{x}}, \boldsymbol{\mathbf{y}})$のような）教師なしまたは生成の基準とトレードオフできる。故に、生成基準は教師あり学習問題への解についての事前学習の信念の特定の形式を表現する[@Lasserre2006]。つまりは、$P(\boldsymbol{\mathbf{x}})$の構造は、共有されたパラメータ化によって捕捉される方法で$P(\boldsymbol{\mathbf{y}} | \boldsymbol{\mathbf{x}})$の構造と接続する。どれだけの生成基準が総基準に含まれているかを制御することによって、純粋に生成または純粋に識別の基準とよりも良いトレードオフを見つけることができる[@Lasserre2006; @Larochelle2008]。
@Salakhutdinov2008は回帰で用いられるカーネルマシンのカーネル関数を学習ための手法を述べる。ここでは、$P(\boldsymbol{\mathbf{x}})$をモデル化するためのラベルなしexamplesの使い方が$P(\boldsymbol{\mathbf{y}} | \boldsymbol{\mathbf{x}})$をかなり大幅に改善する。
半教師あり学習についてのさらなる情報は@Chapelle2006を参照のこと。

## マルチタスク学習

マルチタスク学習[@Caruana1993]はいくつかのタスクから生じる（パラメータに課されるソフトな制約として見ることができる）examplesをプーリングすることによって汎化を改善する方法である。追加の訓練examplesがうまく汎化する値に向かってモデルのパラメータにさらなる圧力をかけるのと同じ方法において、モデルの一部がタスク間で共有されるとき、（共有が正当化されると仮定して）そのモデルの一部は良い値に向かってさらに制限され、しばしばより良い汎化を生み出す。
[@fig:7.2]はマルチタスク学習の非常に一般的な形式を図示する。ここでは、（$\boldsymbol{\mathbf{x}}$を与えられたときの$\boldsymbol{\mathbf{y}}^{(i)}$を予測する）様々な教師ありタスクが、ある中間レベル表現$\boldsymbol{h}^{(shared)}$と同様に、同じ入力$\boldsymbol{\mathbf{x}}$を共有して、ファクタの共通プールを捕捉する。そのモデルは一般に２種類の部分と関連するパラメータに分けられる。

1. （良い汎化を達成するためにこれらのタスクのexamplesから恩恵を受けるだけの）タスク特有のパラメータ。これらは[@fig:7.2]におけるニューラルネットワークの上の方の層である。
2. （タスクすべてのプールされたデータから恩恵を受ける）すべてのタスク間で共有される汎用パラメータ。これらは[@fig:7.2]におけるニューラルネットワークの下の方の層である。

![マルチタスク学習は深層学習フレームワークにおけるいくつかの方法でcastでき、この図はタスクが共通の入力を共有するが、異なる対象の確率変数を伴うところの一般的な状況を図示する。（教師ありかつフィードフォワードである、または、下向きの矢印を持つ生成的の構成要素を含むかどうかの）深層ネットワークの低層はそのようなタスク間で共有され得る一方、（$\boldsymbol{h}^{(1)}$と$\boldsymbol{h}^{(2)}$に出入りする重みと個々に関連する）タスク特有のパラメータは共有された表現$\boldsymbol{h}^{(shared)}$を生成するこれらの上部で学習され得る。その下地となる仮定は入力$\boldsymbol{\mathbf{x}}$におけるバラツキを説明するファクタの共通プールが存在する一方で、各タスクがこれらのファクタの部分集合と関連しているということである。この例では、トップレベルの隠れユニット$\boldsymbol{h}^{(1)}$と$\boldsymbol{h}^{(2)}$が（$\boldsymbol{\mathbf{y}}^{(1)}$と$\boldsymbol{\mathbf{y}}^{(2)}$をそれぞれ予測する）各タスクに特殊化される一方で、ある中間レベルの表現$\boldsymbol{h}^{(shared)}$がすべてのタスク間で共有されることを加えて仮定する。教師なし学習の文脈において、これはトップレベルのファクタのいくつかが出力タスク（$\boldsymbol{h}^{(3)}$）のどれとも関連しないことを確実する。つまり、入力のバラツキのいくつかを説明するファクタは存在するが、$\boldsymbol{\mathbf{y}}^{(1)}$とも$\boldsymbol{\mathbf{y}}^{(2)}$とも関係ない。](fig/7-2.png){#fig:7.2}

改善された汎化および汎化誤差境界[@Baxter1995]は共有されたパラメータのために達成され得る。このために、（単一タスクのモデルのシナリオと比較したとき、共有されたパラメータに対するexamples数の増加に比例して）統計的な強度が大幅に改善され得る。もちろん、これは異なるタスクの間の統計的な関係についてのいくつかの仮定が有効である場合に限り発生し、タスクのいくつかの解だで共有される何かがあることを意味する。
深層学習の視点から、下地となる事前確率の信念は以下である。*異なるタスクに関連するデータにおいて観察されるバラツキを説明するファクタの内、いくつかは2つ以上のタスク間で共有される。*

## 早期終了[Early Stopping]

タスクをオーバーフィットするのに十分な表現上の容量を持つ大きなモデルを訓練するとき、我々はしばしば、訓練誤差が時間とともに徐々に減少するが、検証セット誤差が再び上昇し始めることに気付く。確実に起こるこの挙動の例は[@fig:7.3]を参照のこと。

![時間とともに負の対数尤度の損失がどのように変化するかを示す学習曲線（データセット、または、epochsに対する訓練の反復数として示される）。この例では、我々はMNISTに関するmaxoutネットワークを訓練する。目的の訓練が時間とともに一貫して減少するが、検証セットの平均損失が最終的に再び増加し始め、非対称なU型曲線を形成することを見てほしい。](fig/7-3.png){#fig:7.3}

これは我々が最低の検証セット誤差を持つ時点でのパラメータ設定に戻すことによってより良い検証セット誤差（そして、それ故に、できればより良いテストセット誤差）を持つモデルを得ることができることを意味する。検証セットに関する誤差が改善するたび、我々は最後のパラメータではなくこれらのパラメータを返す。そのアルゴリズムはパラメータが事前に指定したある反復回数で最良を記録した検証誤差よりも改善できなかったときに終了する。この手順は[@lst:7.1]でより公式的に明示される。
この戦略は早期終了[early stopping]として知られる。これはおそらく深層学習において最も一般的に使われる形式の正則化である。その人気は有効性と単純さの両方に起因する。
早期終了について考える1つの方法は***
